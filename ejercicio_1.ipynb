{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_dir = '2024-II/Aprendizaje/Tarea4/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "base_dir = '2024-II/Aprendizaje/Tarea4/data_tarea/'\n",
    "train_dir = base_dir + 'train'\n",
    "test_dir = base_dir + 'test'\n",
    "# p = 'C:\\Users\\l-e-o\\Downloads\\imagedb\\data_tarea\\train\\coast\\features'\n",
    "import os\n",
    "print(os.path.exists(train_dir))\n",
    "print(os.path.exists(test_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leer features de los archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def load_data(dir_path):\n",
    "    all_features = {}\n",
    "    all_labels = {}\n",
    "\n",
    "    for folder in os.listdir(dir_path):\n",
    "        features_path = os.path.join(dir_path, folder, 'features')\n",
    "        for file in os.listdir(features_path):\n",
    "            file_path = os.path.join(features_path, file)\n",
    "            feautures = np.load(file_path)\n",
    "            all_features[file_path] = feautures\n",
    "            all_labels[file_path] = folder\n",
    "\n",
    "    print(len(all_features))\n",
    "\n",
    "    first_key = next(iter(all_features))\n",
    "    print(all_features[first_key].shape)\n",
    "\n",
    "    return all_features, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500\n",
      "(657, 128)\n",
      "2985\n",
      "(656, 128)\n"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = load_data(train_dir)\n",
    "# Get the first 10 items\n",
    "first_10_items = dict(list(train_features.items())[:10])\n",
    "test_features, test_labels = load_data(test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crear matriz de todos los valores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_matrix(features):\n",
    "    # Crear una lista de todas las matrices de características\n",
    "    list_of_matrices = list(features.values())\n",
    "\n",
    "    # Concatenar todas las matrices en una sola matriz grande\n",
    "    big_matrix = np.vstack(list_of_matrices)\n",
    "\n",
    "    print(big_matrix.shape)  # Imprimir la forma de la matriz 2D combinada\n",
    "\n",
    "    return big_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1032780, 128)\n",
      "(2071105, 128)\n"
     ]
    }
   ],
   "source": [
    "train_matrix = create_matrix(train_features)\n",
    "test_matrix = create_matrix(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algoritmo KMeans con librería hnswlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# %pip install hnswlib\n",
    "import hnswlib\n",
    "\n",
    "\n",
    "class KMeansHNSW:\n",
    "\n",
    "    def __init__(self, n_clusters: int, epsilon: float = 1e-4, max_iter: int = 3):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.epsilon = epsilon\n",
    "        self.max_iter = max_iter\n",
    "\n",
    "    def build_index(self, centroids):\n",
    "        self.dim = centroids.shape[1]\n",
    "        self.num_elements = centroids.shape[0]\n",
    "        self.p = hnswlib.Index(space='l2', dim=self.dim)\n",
    "        self.p.init_index(max_elements=self.num_elements, ef_construction=200, M=16)\n",
    "        self.p.add_items(centroids)\n",
    "\n",
    "    def initialize_centroids(self, data: np.ndarray):\n",
    "        indices = random.sample(range(data.shape[0]), self.n_clusters)\n",
    "        self.centroids = data[indices, :]\n",
    "\n",
    "    def fit(self, data: np.ndarray):\n",
    "        self.initialize_centroids(data)\n",
    "        self.build_index(self.centroids)\n",
    "\n",
    "        # Buscar el centroide más cercano para cada punto\n",
    "        labels, distances = self.p.knn_query(data, k=1)  # k=1 para encontrar el vecino más cercano\n",
    "        \n",
    "        # Convert labels from float to int\n",
    "        labels = labels.astype(int)\n",
    "\n",
    "        # Anadir labels a la matriz de datos\n",
    "        data = np.hstack((data, labels))\n",
    "\n",
    "        # loop hasta que converja o se alcance el número máximo de iteraciones\n",
    "        for _ in range(self.max_iter):\n",
    "\n",
    "            # recalcular los centroides\n",
    "            new_centroids = np.array([data[data[:, -1] == i, :-1].mean(axis=0) for i in range(self.n_clusters)])\n",
    "\n",
    "            # checar convergencia\n",
    "            if np.linalg.norm(new_centroids - self.centroids) < self.epsilon:\n",
    "                break\n",
    "\n",
    "            self.centroids = new_centroids\n",
    "            self.build_index(self.centroids)\n",
    "\n",
    "            # Buscar el centroide más cercano para cada punto\n",
    "            labels, distances = self.p.knn_query(data, k=1)  # k=1 para encontrar el vecino más cercano\n",
    "            \n",
    "            # Convert labels from float to int\n",
    "            labels = labels.astype(int)\n",
    "\n",
    "            # Update labels columna en la matriz de datos\n",
    "            data[:, -1] = labels.ravel()\n",
    "        \n",
    "    def predict(self, data: np.ndarray):\n",
    "        labels, distances = self.p.knn_query(data, k=1)\n",
    "        return labels.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizar el Método del Codo para encontrar el número de centroides (Después me di cuenta que tiene que ser 10mil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# %pip install matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def calculate_inertia(data, kmeans_model):\n",
    "    \"\"\"\n",
    "    Calculate the inertia (sum of squared distances of samples to their closest cluster center).\n",
    "    \n",
    "    Parameters:\n",
    "    data (ndarray): The input data for clustering.\n",
    "    kmeans_model (KMeans): The KMeans model after fitting the data.\n",
    "    \n",
    "    Returns:\n",
    "    float: The inertia of the fitted KMeans model.\n",
    "    \"\"\"\n",
    "    clusters = kmeans_model.predict(data)\n",
    "    inertia = 0\n",
    "    for i, center in enumerate(kmeans_model.centroids):\n",
    "        inertia += np.sum((data[clusters == i] - center) ** 2)\n",
    "    return inertia\n",
    "\n",
    "\n",
    "def elbow_method(data, start_k, max_k, step=100):\n",
    "    \"\"\"\n",
    "    Implement the elbow method to determine the optimal number of clusters for KMeans.\n",
    "    \n",
    "    Parameters:\n",
    "    data (ndarray): The input data for clustering.\n",
    "    max_k (int): The maximum number of clusters to consider.\n",
    "    \n",
    "    Returns:\n",
    "    None: This function plots the elbow graph.\n",
    "    \"\"\"\n",
    "    inertias = []\n",
    "    for k in range(start_k, max_k + 1, step):\n",
    "        print(\"n_clusters:\", k)\n",
    "        kmeans = KMeansHNSW(n_clusters=k)\n",
    "        kmeans.fit(data)\n",
    "        inertia = calculate_inertia(data, kmeans)\n",
    "        inertias.append(inertia)\n",
    "    return inertias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_clusters: 1\n",
      "n_clusters: 101\n",
      "n_clusters: 201\n",
      "n_clusters: 301\n",
      "n_clusters: 401\n",
      "n_clusters: 501\n",
      "n_clusters: 601\n",
      "n_clusters: 701\n",
      "n_clusters: 801\n",
      "n_clusters: 901\n"
     ]
    }
   ],
   "source": [
    "max_k = 1000\n",
    "step = 100\n",
    "inertias = elbow_method(train_matrix, 1, max_k=1000, step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAskAAAHWCAYAAACFXRQ+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAABm/0lEQVR4nO3deXxM9/4/8Ndkm0SSyUYSIZGgiKUoFSFoKxUETW0XuaXWammlVFFfSxe13S60ytVfL25b2nJxFaVpQkNERDSWkBSN2LK0IhlBIsvn98e5c2SSCdnPTPJ6Ph7nMTPnfOac95nj3r4cn/P5qIQQAkREREREJDNTugAiIiIiImPDkExEREREVApDMhERERFRKQzJRERERESlMCQTEREREZXCkExEREREVApDMhERERFRKQzJRERERESlMCQTEREREZXCkExEilGpVFi6dKn8eenSpVCpVPjrr7+UK8pIeXt7Y8iQIbV+nMOHD0OlUuHw4cO1fixTo+RvU9Fj839DRDWHIZmIatTmzZuhUqnKXY4fP650iVXm7e0NlUqFwMBAg9u//PJL+TxPnjxZ6f2fP38eS5cuxZUrV6pZae171HWeP39+ndRw9epVTJ8+Hd7e3lCr1XB1dUVISAiio6Ortd8vvvgCmzdvrpkiichkWShdABHVT++99x58fHzKrG/durUC1dQca2trHDp0COnp6XB3d9fb9u2338La2hp5eXlV2vf58+fx7rvv4plnnoG3t3cNVFv7DF3njh071vpxo6OjMXjwYADAlClT0L59e6Snp2Pz5s3o06cP1qxZg9dff71K+/7iiy/QuHFjvPzyy3rr+/bti/v378PKyqq65RORCWBIJqJaMWjQIHTv3l3pMmpc7969ERcXh++//x6zZs2S11+/fh1HjhzBiy++iP/85z8KVli3aus63717F7a2tga33b59GyNHjoSNjQ2io6PRqlUredvs2bMRFBSEsLAwdOvWDb169aqxmszMzGBtbV1j+yMi48buFkRkdP766y+MHj0aGo0GLi4umDVrVpm7s4WFhXj//ffRqlUrqNVqeHt745133kF+fr7cZvbs2XBxcYEQQl73+uuvQ6VSYe3atfK6jIwMqFQqrF+//rG1WVtbY/jw4di6dave+m3btsHJyQlBQUEGv5eUlISRI0fC2dkZ1tbW6N69O/bs2SNv37x5M0aNGgUAePbZZ+WuC6X7oB49ehQ9evSAtbU1WrZsiX//+99ljvXHH39g1KhRcHZ2RqNGjdCzZ0/s27evTLvr168jJCQEtra2cHV1xZtvvqn3+9WEyMhI9OnTB7a2tnB0dMQLL7yACxcu6LXR9aM9f/48xo0bBycnJwQEBJS7z3/+859IT0/H6tWr9QIyANjY2GDLli1QqVR477335PW67iFRUVF45ZVX4OLiAo1Gg/Hjx+P27dtyO29vbyQmJuLXX3+Vr8EzzzwDwHC/4GeeeQYdO3bEmTNn0K9fPzRq1AitW7fGjh07AAC//vor/Pz8YGNjg7Zt2+KXX37Rqzc1NRWvvfYa2rZtCxsbG7i4uGDUqFE12uUmNTUVrVu3RseOHZGRkVFj+yWq7xiSiahW5OTk4K+//tJbbt26VaHvjh49Gnl5eVi+fDkGDx6MtWvXYtq0aXptpkyZgsWLF+Opp57CJ598gn79+mH58uUYM2aM3KZPnz7IyspCYmKivO7IkSMwMzPDkSNH9NYB0j+nV8S4ceNw4sQJXL58WV63detWjBw5EpaWlmXaJyYmomfPnrhw4QLmz5+Pjz76CLa2tggJCcGuXbvkY7/xxhsAgHfeeQdff/01vv76a/j6+sr7uXTpEkaOHInnn38eH330EZycnPDyyy/rnV9GRgZ69eqFgwcP4rXXXsOyZcuQl5eHYcOGyccCgPv376N///44ePAgZs6ciYULF+LIkSN4++23K/Qb6Bi6zjq//PILgoKCkJmZiaVLl2L27Nk4duwYevfubTAEjho1Cvfu3cOHH36IqVOnlnvMH3/8EdbW1hg9erTB7T4+PggICEBkZCTu37+vt23mzJm4cOECli5divHjx+Pbb79FSEiI/BepTz/9FM2bN0e7du3ka7Bw4cJH/ga3b9/GkCFD4Ofnh1WrVkGtVmPMmDH4/vvvMWbMGAwePBgrVqzA3bt3MXLkSNy5c0f+blxcHI4dO4YxY8Zg7dq1mD59OiIiIvDMM8/g3r17jzxuRVy+fBl9+/aFvb09Dh8+DDc3t2rvk6jBEERENWjTpk0CgMFFrVbrtQUglixZIn9esmSJACCGDRum1+61114TAMTp06eFEEIkJCQIAGLKlCl67d566y0BQERGRgohhMjMzBQAxBdffCGEECI7O1uYmZmJUaNGCTc3N/l7b7zxhnB2dhbFxcWPPLcWLVqI4OBgUVhYKNzd3cX7778vhBDi/PnzAoD49ddf5fOPi4uTv9e/f3/RqVMnkZeXJ68rLi4WvXr1Ek888YS8bvv27QKAOHTokMFjAxBRUVHyuszMTKFWq8WcOXPkdWFhYQKAOHLkiLzuzp07wsfHR3h7e4uioiIhhBCffvqpACB++OEHud3du3dF69aty62hpEddZ50uXboIV1dXcevWLXnd6dOnhZmZmRg/fry8Tnfdx44d+8hj6jg6OorOnTs/ss0bb7whAIgzZ87o1dutWzfx4MEDud2qVasEAPHf//5XXtehQwfRr1+/Mvs8dOhQmd+mX79+AoDYunWrvC4pKUkAEGZmZuL48ePy+oMHDwoAYtOmTfK6e/fulTlOTEyMACD+/e9/P/LYhuh+yz///FNcuHBBeHh4iKefflpkZWU98ntEVBbvJBNRrVi3bh3Cw8P1lp9++qlC350xY4beZ90DWPv379d7nT17tl67OXPmAIDctaBJkyZo164doqKiAEgPe5mbm2Pu3LnIyMjAxYsXAUh3kgMCAqBSqSpUn7m5OUaPHo1t27YBkB7Y8/T0RJ8+fcq0zcrKQmRkJEaPHo07d+7o3VUPCgrCxYsXcePGjQodt3379nrHaNKkCdq2bYs//vhDXrd//3706NFDr7uCnZ0dpk2bhitXruD8+fNyu6ZNm2LkyJFyu0aNGpW5Y/84hq4zAKSlpSEhIQEvv/wynJ2d5fZPPvkknn/+efkaljR9+vQKHfPOnTuwt7d/ZBvddq1Wq7d+2rRpenf7X331VVhYWBisp6Ls7Oz0/gWjbdu2cHR0hK+vL/z8/OT1uvclr5eNjY38vqCgALdu3ULr1q3h6OiIU6dOVbmmc+fOoV+/fvD29sYvv/wCJyenKu+LqKHig3tEVCt69OhR5Qe6nnjiCb3PrVq1gpmZmfxP9KmpqTAzMyszUoa7uzscHR2Rmpoqr+vTp48cgI4cOYLu3buje/fucHZ2xpEjR+Dm5obTp09j3Lhxlapx3LhxWLt2LU6fPo2tW7dizJgxBkP2pUuXIITAokWLsGjRIoP7yszMRLNmzR57TC8vrzLrnJyc9PrUpqam6gUzHV23jdTUVHTs2FHup1q65rZt2z62jpLKu866a2Bof76+vjh48GCZh/MMjYZiiL29vV6XBUN020uH6dJ/tuzs7NC0adNq9QFu3rx5md/RwcEBnp6eZdYB0Lte9+/fx/Lly7Fp0ybcuHFDr/98Tk5OlWsaOnQo3NzccPDgQdjZ2VV5P0QNGUMyERm98u7wVuTOb0BAAL788kv88ccfOHLkCPr06QOVSoWAgAAcOXIEHh4eKC4uNngX+FH8/PzQqlUrhIWFISUlpdyQXVxcDAB46623yn2or6LD4pmbmxtcXzJYmbKSd1UfxdfXF7/99hvy8/OhVqsNtjlz5gwsLS3LhOLaUN51qcj1ev3117Fp0yaEhYXB398fDg4OUKlUGDNmjPxnpypGjBiBLVu24Ntvv8Urr7xS5f0QNWQMyURkdC5evKh3V/HSpUsoLi6Wxw5u0aIFiouLcfHiRb0H2zIyMpCdnY0WLVrI63ThNzw8HHFxcfJEF3379sX69evh4eEBW1tbdOvWrdJ1jh07Fh988AF8fX3RpUsXg21atmwJALC0tCx3EhKdinb3eJQWLVogOTm5zPqkpCR5u+713LlzEELoHdfQd6taR3n7S0pKQuPGjcsd4u1xhgwZgpiYGGzfvh1///vfy2y/cuUKjhw5gsDAwDLB++LFi3j22Wflz7m5uUhLS5PHXAZq5jpU1I4dOzBhwgR89NFH8rq8vDxkZ2dXa7+rV6+GhYUFXnvtNdjb21f6X0qIiKNbEJERWrdund7nzz77DIA0Ji8AOdB8+umneu0+/vhjAEBwcLC8zsfHB82aNcMnn3yCgoIC9O7dG4AUni9fvowdO3agZ8+esLCo/D2DKVOmYMmSJXoBpzRXV1c888wz+Oc//4m0tLQy2//880/5vS40VicgDR48GCdOnEBMTIy87u7du9i4cSO8vb3Rvn17ud3NmzflocoA4N69e9i4cWOVj11S06ZN0aVLF2zZskXvfM6dO4eff/5ZL5RW1iuvvAJXV1fMnTtXr38vIAXMiRMnQgiBxYsXl/nuxo0bUVBQIH9ev349CgsL5T9bgHQdqhtSK8rc3LzMvwR89tlnKCoqqtZ+VSoVNm7ciJEjR2LChAl6ww0SUcXwTjIR1YqffvpJvntZUq9eveS7q+VJSUnBsGHDMHDgQMTExOCbb77BuHHj0LlzZwBA586dMWHCBGzcuBHZ2dno168fTpw4gS1btiAkJETvTiEgBeLvvvsOnTp1kh9geuqpp2Bra4vff/+9ynfZWrRogaVLlz623bp16xAQEIBOnTph6tSpaNmyJTIyMhATE4Pr16/j9OnTAIAuXbrA3NwcK1euRE5ODtRqNZ577jm4urpWuKb58+dj27ZtGDRoEN544w04Oztjy5YtSElJwX/+8x+YmUn3RqZOnYrPP/8c48ePR3x8PJo2bYqvv/4ajRo1qtJvYcjq1asxaNAg+Pv7Y/Lkybh//z4+++wzODg4VOh3K4+Liwt27NiB4OBgPPXUU2Vm3Lt06RLWrFljcCKRBw8eoH///hg9ejSSk5PxxRdfICAgAMOGDZPbdOvWDevXr8cHH3yA1q1bw9XVFc8991yV632UIUOG4Ouvv4aDgwPat2+PmJgY/PLLL3Bxcan2vs3MzPDNN98gJCQEo0ePxv79+2vtPIjqJQVH1iCieuhRQ4Oh1PBXKGcIuPPnz4uRI0cKe3t74eTkJGbOnCnu37+vd5yCggLx7rvvCh8fH2FpaSk8PT3FggUL9IZZ01m3bp0AIF599VW99YGBgQKAiIiIqNC56YaAq8j5lxwCTgghLl++LMaPHy/c3d2FpaWlaNasmRgyZIjYsWOHXrsvv/xStGzZUpibm+sN+VXesfv161dmuLLLly+LkSNHCkdHR2FtbS169Ogh9u7dW+a7qampYtiwYaJRo0aicePGYtasWeLAgQOVGgKu9HmW9ssvv4jevXsLGxsbodFoxNChQ8X58+f12pQctqwyUlJSxNSpU4WXl5ewtLQUjRs3FsOGDdMb/q50vb/++quYNm2acHJyEnZ2diI0NFRviDohhEhPTxfBwcHC3t5eAJB/3/KGgOvQoUOZ45V3vQCIGTNmyJ9v374tJk6cKBo3bizs7OxEUFCQSEpKEi1atBATJkyQ21VlCDide/fuiX79+gk7Ozu9IemI6NFUQtSTJz6IiIjKsXnzZkycOBFxcXH1crp0Iqp57JNMRERERFQKQzIRERERUSkMyUREREREpbBPMhERERFRKbyTTERERERUCkMyEREREVEpnEykhhQXF+PmzZuwt7ev0ylNiYiIiKhihBC4c+cOPDw85MmVysOQXENu3rwJT09PpcsgIiIiose4du0amjdv/sg2iobkqKgorF69GvHx8UhLS8OuXbsQEhJisO306dPxz3/+E5988gnCwsLk9VlZWXj99dfx448/wszMDCNGjMCaNWtgZ2cntzlz5gxmzJiBuLg4NGnSBK+//jrefvttvf1v374dixYtwpUrV/DEE09g5cqVGDx4cIXPxd7eHoD0o2s0mor/CERERERUJ7RaLTw9PeXc9iiKhuS7d++ic+fOmDRpEoYPH15uu127duH48ePw8PAosy00NBRpaWkIDw9HQUEBJk6ciGnTpmHr1q0ApB9jwIABCAwMxIYNG3D27FlMmjQJjo6OmDZtGgDg2LFjGDt2LJYvX44hQ4Zg69atCAkJwalTp9CxY8cKnYuui4VGo2FIJiIiIjJiFekaazRDwKlUKoN3km/cuAE/Pz8cPHgQwcHBCAsLk+8kX7hwAe3bt9ebZvTAgQMYPHgwrl+/Dg8PD6xfvx4LFy5Eeno6rKysAADz58/H7t27kZSUBAD429/+hrt372Lv3r3ycXv27IkuXbpgw4YNFapfq9XCwcEBOTk5DMlERERERqgyec2oR7coLi7GSy+9hLlz56JDhw5ltsfExMDR0VEOyAAQGBgIMzMzxMbGym369u0rB2QACAoKQnJyMm7fvi23CQwM1Nt3UFAQYmJiyq0tPz8fWq1WbyEiIiKi+sGoQ/LKlSthYWGBN954w+D29PR0uLq66q2zsLCAs7Mz0tPT5TZubm56bXSfH9dGt92Q5cuXw8HBQV740B4RERFR/WG0ITk+Ph5r1qzB5s2bjXJItQULFiAnJ0derl27pnRJRERERFRDjDYkHzlyBJmZmfDy8oKFhQUsLCyQmpqKOXPmwNvbGwDg7u6OzMxMve8VFhYiKysL7u7ucpuMjAy9NrrPj2uj226IWq2WH9Ljw3pERERE9YvRhuSXXnoJZ86cQUJCgrx4eHhg7ty5OHjwIADA398f2dnZiI+Pl78XGRmJ4uJi+Pn5yW2ioqJQUFAgtwkPD0fbtm3h5OQkt4mIiNA7fnh4OPz9/Wv7NImIiIjICCk6BFxubi4uXbokf05JSUFCQgKcnZ3h5eUFFxcXvfaWlpZwd3dH27ZtAQC+vr4YOHAgpk6dig0bNqCgoAAzZ87EmDFj5OHixo0bh3fffReTJ0/GvHnzcO7cOaxZswaffPKJvN9Zs2ahX79++OijjxAcHIzvvvsOJ0+exMaNG+vgVyAiIiIiY6PoneSTJ0+ia9eu6Nq1KwBg9uzZ6Nq1KxYvXlzhfXz77bdo164d+vfvj8GDByMgIEAv3Do4OODnn39GSkoKunXrhjlz5mDx4sXyGMkA0KtXL2zduhUbN25E586dsWPHDuzevbvCYyQTERERUf1iNOMkmzqOk0xERERk3CqT1xTtbkFVU1QEHDkCpKUBTZsCffoA5uZKV0VERERUfzAkm5idO4FZs4Dr1x+ua94cWLMGeMTM3kRERERUCUY7ugWVtXMnMHKkfkAGgBs3pPU7dypTFxEREVF9w5BsIoqKpDvIhnqQ69aFhUntiIiIiKh6GJJNxJEjZe8glyQEcO2a1I6IiIiIqoch2USkpdVsOyIiIiIqH0OyiWjatGbbEREREVH5GJJNRJ8+0igWKpXh7SoV4OkptSMiIiKi6mFINhHm5tIwb0D5QfnTTzleMhEREVFNYEg2IcOHAzt2AM2a6a+3t5fWc5xkIiIioprBkGxihg8HrlwBDh0Cpk2T1j35JAMyERERUU1iSDZB5ubAM88Ab70lfY6LA/LyFC2JiIiIqF5hSDZhrVsDrq7AgwdAfLzS1RARERHVHwzJJkylAnr3lt4fPapsLURERET1CUOyiQsIkF4ZkomIiIhqDkOyidOF5OhooLhY2VqIiIiI6guGZBPXtStgYwPcvg0kJSldDREREVH9wJBs4iwtgZ49pffsckFERERUMxiS6wH2SyYiIiKqWQzJ9QBDMhEREVHNYkiuB3r2BMzMgJQU4MYNpashIiIiMn0MyfWARiNNTQ1Io1wQERERUfUwJNcT7HJBREREVHMYkuuJkuMlExEREVH1MCTXE7rpqRMSgDt3FC2FiIiIyOQxJNcTzZsD3t7SrHvHjytdDREREZFpY0iuR9gvmYiIiKhmMCTXIwzJRERERDWDIbke0fVLPn4cKChQthYiIiIiU8aQXI+0bw84OgL37kkP8BERERFR1TAk1yNmZg/vJnMoOCIiIqKqY0iuZ9gvmYiIiKj6GJLrmZIhWQhlayEiIiIyVQzJ9Uz37oCVFZCRAVy+rHQ1RERERKaJIbmesbYGnn5aes8uF0RERERVw5BcD+ke3mNIJiIiIqoahuR6iA/vEREREVWPoiE5KioKQ4cOhYeHB1QqFXbv3q23fenSpWjXrh1sbW3h5OSEwMBAxMbG6rXJyspCaGgoNBoNHB0dMXnyZOTm5uq1OXPmDPr06QNra2t4enpi1apVZWrZvn072rVrB2tra3Tq1An79++v8fOtK716Sa/JycCffypbCxEREZEpUjQk3717F507d8a6desMbm/Tpg0+//xznD17FkePHoW3tzcGDBiAP0skv9DQUCQmJiI8PBx79+5FVFQUpk2bJm/XarUYMGAAWrRogfj4eKxevRpLly7Fxo0b5TbHjh3D2LFjMXnyZPz2228ICQlBSEgIzp07V3snX4tcXKSJRQDg2DFlayEiIiIyRSohjGOgMJVKhV27diEkJKTcNlqtFg4ODvjll1/Qv39/XLhwAe3bt0dcXBy6d+8OADhw4AAGDx6M69evw8PDA+vXr8fChQuRnp4OKysrAMD8+fOxe/duJCUlAQD+9re/4e7du9i7d698rJ49e6JLly7YsGFDherX1ZaTkwONRlPFX6HmvPIKsHEj8NZbwOrVSldDREREpLzK5DWT6ZP84MEDbNy4EQ4ODujcuTMAICYmBo6OjnJABoDAwECYmZnJ3TJiYmLQt29fOSADQFBQEJKTk3H79m25TWBgoN7xgoKCEBMTU249+fn50Gq1eosxYb9kIiIioqoz+pC8d+9e2NnZwdraGp988gnCw8PRuHFjAEB6ejpcXV312ltYWMDZ2Rnp6elyGzc3N702us+Pa6Pbbsjy5cvh4OAgL56entU70RqmC8nx8cC9e8rWQkRERGRqjD4kP/vss0hISMCxY8cwcOBAjB49GpmZmUqXhQULFiAnJ0derl27pnRJery9gaZNgYICIC5O6WqIiIiITIvRh2RbW1u0bt0aPXv2xFdffQULCwt89dVXAAB3d/cygbmwsBBZWVlwd3eX22RkZOi10X1+XBvddkPUajU0Go3eYkxUKna5ICIiIqoqow/JpRUXFyM/Px8A4O/vj+zsbMTHx8vbIyMjUVxcDD8/P7lNVFQUCgoK5Dbh4eFo27YtnJyc5DYRERF6xwkPD4e/v39tn06tYkgmIiIiqhpFQ3Jubi4SEhKQkJAAAEhJSUFCQgKuXr2Ku3fv4p133sHx48eRmpqK+Ph4TJo0CTdu3MCoUaMAAL6+vhg4cCCmTp2KEydOIDo6GjNnzsSYMWPg4eEBABg3bhysrKwwefJkJCYm4vvvv8eaNWswe/ZsuY5Zs2bhwIED+Oijj5CUlISlS5fi5MmTmDlzZp3/JjVJF5JjYoCiImVrISIiIjIpQkGHDh0SAMosEyZMEPfv3xcvvvii8PDwEFZWVqJp06Zi2LBh4sSJE3r7uHXrlhg7dqyws7MTGo1GTJw4Udy5c0evzenTp0VAQIBQq9WiWbNmYsWKFWVq+eGHH0SbNm2ElZWV6NChg9i3b1+lziUnJ0cAEDk5OZX/IWpJQYEQdnZCAEKcPq10NURERETKqkxeM5pxkk2dsY2TrDNgABAeDqxbB7z2mtLVEBERESmnXo6TTFXDfslERERElceQXM/17i29MiQTERERVRxDcj3n5weYmwPXrgFXrypdDREREZFpYEiu5+zsgK5dpfe8m0xERERUMQzJDYCuX3J0tLJ1EBEREZkKhuQGgA/vEREREVUOQ3IDoHt47+xZIDtb0VKIiIiITAJDcgPg7g60bg0IIc2+R0RERESPxpDcQHAoOCIiIqKKY0huINgvmYiIiKjiGJIbCF1IPnECePBA2VqIiIiIjB1DcgPRti3g4gLk5QGnTildDREREZFxY0huIFQqdrkgIiIiqiiG5AaEIZmIiIioYhiSG5CSIVkIZWshIiIiMmYMyQ3IU08B1tbArVtAcrLS1RAREREZL4bkBsTKCujRQ3rPLhdERERE5WNIbmDYL5mIiIjo8RiSGxhdSI6OVrYOIiIiImPGkNzA+PtLw8FdugSkpytdDREREZFxYkhuYBwdgU6dpPe8m0xERERkGENyA8R+yURERESPxpDcADEkExERET0aQ3ID1Lu39Prbb0BurrK1EBERERkjhuQGyMsL8PQEioqA2FilqyEiIiIyPgzJDRSHgiMiIiIqH0NyA8V+yURERETlY0huoHQhOSYGKCxUthYiIiIiY8OQ3EB16AA4OEgP7p05o3Q1RERERMaFIbmBMjcHevWS3rPLBREREZE+huQGTDcUHEMyERERkT6G5Aas5MN7QihbCxEREZExYUhuwJ5+GrC0BNLSgCtXlK6GiIiIyHgwJDdgjRoB3bpJ79nlgoiIiOghhuQGjuMlExEREZXFkNzAMSQTERERlcWQ3MDphoE7fx64dUvZWoiIiIiMBUNyA9ekCdC2rfT+2DFlayEiIiIyFoqG5KioKAwdOhQeHh5QqVTYvXu3vK2goADz5s1Dp06dYGtrCw8PD4wfPx43b97U20dWVhZCQ0Oh0Wjg6OiIyZMnIzc3V6/NmTNn0KdPH1hbW8PT0xOrVq0qU8v27dvRrl07WFtbo1OnTti/f3+tnLMxYpcLIiIiIn2KhuS7d++ic+fOWLduXZlt9+7dw6lTp7Bo0SKcOnUKO3fuRHJyMoYNG6bXLjQ0FImJiQgPD8fevXsRFRWFadOmydu1Wi0GDBiAFi1aID4+HqtXr8bSpUuxceNGuc2xY8cwduxYTJ48Gb/99htCQkIQEhKCc+fO1d7JGxFdSI6OVrYOIiIiImOhEsI4ppFQqVTYtWsXQkJCym0TFxeHHj16IDU1FV5eXrhw4QLat2+PuLg4dO/eHQBw4MABDB48GNevX4eHhwfWr1+PhQsXIj09HVZWVgCA+fPnY/fu3UhKSgIA/O1vf8Pdu3exd+9e+Vg9e/ZEly5dsGHDhgrVr9Vq4eDggJycHGg0mir+Csq4dAl44gnAygrIyQGsrZWuiIiIiKjmVSavmVSf5JycHKhUKjg6OgIAYmJi4OjoKAdkAAgMDISZmRliY2PlNn379pUDMgAEBQUhOTkZt2/fltsEBgbqHSsoKAgxMTHl1pKfnw+tVqu3mKpWrQA3N+DBA+DkSaWrISIiIlKeyYTkvLw8zJs3D2PHjpWTf3p6OlxdXfXaWVhYwNnZGenp6XIbNzc3vTa6z49ro9tuyPLly+Hg4CAvnp6e1TtBBalU7JdMREREVJJJhOSCggKMHj0aQgisX79e6XIAAAsWLEBOTo68XLt2TemSqoUhmYiIiOghC6ULeBxdQE5NTUVkZKRe/xF3d3dkZmbqtS8sLERWVhbc3d3lNhkZGXptdJ8f10a33RC1Wg21Wl31EzMyvXtLr9HRQHExYGYSf30iIiIiqh1GHYV0AfnixYv45Zdf4OLiorfd398f2dnZiI+Pl9dFRkaiuLgYfn5+cpuoqCgUFBTIbcLDw9G2bVs4OTnJbSIiIvT2HR4eDn9//9o6NaPTpQvQqBGQnS1NLEJERETUkCkaknNzc5GQkICEhAQAQEpKChISEnD16lUUFBRg5MiROHnyJL799lsUFRUhPT0d6enpePDgAQDA19cXAwcOxNSpU3HixAlER0dj5syZGDNmDDw8PAAA48aNg5WVFSZPnozExER8//33WLNmDWbPni3XMWvWLBw4cAAfffQRkpKSsHTpUpw8eRIzZ86s899EKZaWQM+e0nt2uSAiIqIGTyjo0KFDAkCZZcKECSIlJcXgNgDi0KFD8j5u3bolxo4dK+zs7IRGoxETJ04Ud+7c0TvO6dOnRUBAgFCr1aJZs2ZixYoVZWr54YcfRJs2bYSVlZXo0KGD2LdvX6XOJScnRwAQOTk5VfotjMHixUIAQvz970pXQkRERFTzKpPXjGacZFNnyuMk64SHAwMGAN7eQEqK0tUQERER1ax6O04y1a6ePaUH9q5cAa5fV7oaIiIiIuUwJJPM3l56gA/gFNVERETUsDEkkx7dUHB8eI+IiIgaMoZk0sNJRYiIiIgYkqkU3Z3kM2cArVbZWoiIiIiUwpBMepo1A3x8pFn3jh9XuhoiIiIiZTAkUxnsckFEREQNHUMylcGQTERERA0dQzKVoQvJx48DBQXK1kJERESkBIZkKqNdO8DZGbh/H/jtN6WrISIiIqp7DMlUhpkZ0KuX9J5dLoiIiKghYkgmg9gvmYiIiBoyhmQySBeSo6MBIZSthYiIiKiuMSSTQd27A2o1kJkJXLqkdDVEREREdYshmQxSq4Gnn5bes8sFERERNTQMyVQu9ksmIiKihoohmcrFkExEREQNFUMylcvfX3r9/XepbzIRERFRQ8GQTOVydgY6dJDeR0crWwsRERFRXWJIpkcqORQcERERUUPBkEyPxH7JRERE1BAxJNMj6UJyfDxw756ytRARERHVFYZkeqQWLYBmzYDCQuDECaWrISIiIqobDMn0SCoVu1wQERFRw8OQTI/Vu7f0ypBMREREDQVDMj2W7k7ysWNAUZGytRARERHVBYZkeqxOnQB7e+DOHeDcOaWrISIiIqp9DMn0WBYWD2ffY5cLIiIiaggYkqlC+PAeERERNSQMyVQhupB85AgghLK1EBEREdU2hmSqkB49pG4XN24AV68qXQ0RERFR7WJIpgqxtQW6dpXes8sFERER1XcMyVRh7JdMREREDQVDMlWYLiRHRytbBxEREVFtY0imCtPNvHfuHHD7trK1EBEREdUmhmSqMDc34IknpNEtYmKUroaIiIio9jAkU6WwXzIRERE1BAzJVCkMyURERNQQKBqSo6KiMHToUHh4eEClUmH37t1623fu3IkBAwbAxcUFKpUKCQkJZfaRl5eHGTNmwMXFBXZ2dhgxYgQyMjL02ly9ehXBwcFo1KgRXF1dMXfuXBQWFuq1OXz4MJ566imo1Wq0bt0amzdvruGzrR90/ZJPnADy85WthYiIiKi2KBqS7969i86dO2PdunXlbg8ICMDKlSvL3cebb76JH3/8Edu3b8evv/6KmzdvYvjw4fL2oqIiBAcH48GDBzh27Bi2bNmCzZs3Y/HixXKblJQUBAcH49lnn0VCQgLCwsIwZcoUHDx4sOZOtp5o0wZo3FgKyPHxSldDREREVDtUQhjHJMMqlQq7du1CSEhImW1XrlyBj48PfvvtN3Tp0kVen5OTgyZNmmDr1q0YOXIkACApKQm+vr6IiYlBz5498dNPP2HIkCG4efMm3NzcAAAbNmzAvHnz8Oeff8LKygrz5s3Dvn37cO7cOXnfY8aMQXZ2Ng4cOGCw3vz8fOSXuJWq1Wrh6emJnJwcaDSaGvhFjNeLLwK7dwOrVgFz5ypdDREREVHFaLVaODg4VCivmXSf5Pj4eBQUFCAwMFBe165dO3h5eSHmf8MvxMTEoFOnTnJABoCgoCBotVokJibKbUruQ9cm5hFDOCxfvhwODg7y4unpWZOnZtTYL5mIiIjqO5MOyenp6bCysoKjo6Peejc3N6Snp8ttSgZk3Xbdtke10Wq1uH//vsFjL1iwADk5OfJy7dq1mjglk1ByUpHiYmVrISIiIqoNFkoXYKrUajXUarXSZSiia1fAxga4dQtITgZ8fZWuiIiIiKhmmfSdZHd3dzx48ADZ2dl66zMyMuDu7i63KT3ahe7z49poNBrY2NjUUvWmy8oK8POT3rPLBREREdVHJh2Su3XrBktLS0RERMjrkpOTcfXqVfj7+wMA/P39cfbsWWRmZsptwsPDodFo0L59e7lNyX3o2uj2QWWxXzIRERHVZ4p2t8jNzcWlS5fkzykpKUhISICzszO8vLyQlZWFq1ev4ubNmwCkAAxId37d3d3h4OCAyZMnY/bs2XB2doZGo8Hrr78Of39/9OzZEwAwYMAAtG/fHi+99BJWrVqF9PR0/N///R9mzJghd5eYPn06Pv/8c7z99tuYNGkSIiMj8cMPP2Dfvn11/IuYDt14yQzJREREVC8JBR06dEgAKLNMmDBBCCHEpk2bDG5fsmSJvI/79++L1157TTg5OYlGjRqJF198UaSlpekd58qVK2LQoEHCxsZGNG7cWMyZM0cUFBSUqaVLly7CyspKtGzZUmzatKlS55KTkyMAiJycnKr8FCYnO1sIlUoIQIibN5WuhoiIiOjxKpPXjGacZFNXmXH36osuXYDTp4Ht24H/DVNNREREZLQazDjJpCz2SyYiIqL6iiGZqowhmYiIiOorhmSqMl1I/u034M4dZWshIiIiqkkMyVRlzZsDLVpIs+7FxipdDREREVHNYUimauFQcERERFQfMSRTtbBfMhEREdVHDMlULbqQfPw4UFiobC1ERERENYUhmaqlQwfAwQG4e1caM5mIiIioPmBIpmoxM2O/ZCIiIqp/GJKp2tgvmYiIiOobhmSqtpIhmZOcExERUX3AkEzV1r07YGkJpKcDf/yhdDVERERE1ceQTNVmYyMFZYBdLoiIiKh+YEimGqHrchEdrWwdRERERDWBIZlqBB/eIyIiovqEIZlqRK9e0uuFC8BffylbCxEREVF1WVT1iydPnsQPP/yAq1ev4sGDB3rbdu7cWe3CyLQ0bgz4+koh+dgxYNgwpSsiIiIiqroq3Un+7rvv0KtXL1y4cAG7du1CQUEBEhMTERkZCQcHh5qukUwEu1wQERFRfVGlkPzhhx/ik08+wY8//ggrKyusWbMGSUlJGD16NLy8vGq6RjIRnHmPiIiI6osqheTLly8jODgYAGBlZYW7d+9CpVLhzTffxMaNG2u0QDIdujvJJ08C9+8rWwsRERFRdVQpJDs5OeHOnTsAgGbNmuHcuXMAgOzsbNy7d6/mqiOT0rIl4O4OFBRIQZmIiIjIVFUpJPft2xfh4eEAgFGjRmHWrFmYOnUqxo4di/79+9dogWQ6VCr2SyYiIqL6oUqjW3z++efIy8sDACxcuBCWlpY4duwYRowYgf/7v/+r0QLJtAQEADt2MCQTERGRaVMJIYTSRdQHWq0WDg4OyMnJgUajUbocxcTHS1NUOzgAWVmAGUfiJiIiIiNRmbxW4TvJWq1W3plWq31k24YcEhu6zp0BW1sgJwdITAQ6dVK6IiIiIqLKq3BIdnJyQlpaGlxdXeHo6AiVSlWmjRACKpUKRUVFNVokmQ4LC6BnTyAiQupywZBMREREpqjCITkyMhLOzs4AgEOHDtVaQWT6AgIehuRXX1W6GiIiIqLKq3BI7tevn/zex8cHnp6eZe4mCyFw7dq1mquOTJJuhIvoaGXrICIiIqqqKj1W5ePjgz///LPM+qysLPj4+FS7KDJtfn6AuTmQmgrw70xERERkiqoUknV9j0vLzc2FtbV1tYsi02ZvD3TpIr3n3WQiIiIyRZUaJ3n27NkAAJVKhUWLFqFRo0bytqKiIsTGxqKLLh1RgxYQIA0Hd/QoMGaM0tUQERERVU6lQvJvv/0GQLqTfPbsWVhZWcnbrKys0LlzZ7z11ls1WyGZpIAAYM0aTipCREREpqlSIVk3qsXEiROxdu1a2Nvb10pRZPp695Zez5yRxkx2cFC2HiIiIqLKqHSf5IKCAnz99ddITU2tjXqonmjaFGjZEhACiIlRuhoiIiKiyql0SLa0tISXlxcnDKHH4lBwREREZKqqNLrFwoUL8c477yArK6um66F6RBeS2S+ZiIiITE2l+iTrfP7557h06RI8PDzQokUL2Nra6m0/depUjRRHpk0XkmNjgQcPgBLPeRIREREZtSrdSQ4JCcFbb72FBQsWYNy4cXjhhRf0loqKiorC0KFD4eHhAZVKhd27d+ttF0Jg8eLFaNq0KWxsbBAYGIiLFy/qtcnKykJoaCg0Gg0cHR0xefJk5Obm6rU5c+YM+vTpA2tra3h6emLVqlVlatm+fTvatWsHa2trdOrUCfv376/4D0IGtWsHuLgA9+8D/xsYhYiIiMgkVOlO8pIlS2rk4Hfv3kXnzp0xadIkDB8+vMz2VatWYe3atdiyZQt8fHywaNEiBAUF4fz58/KkJaGhoUhLS0N4eDgKCgowceJETJs2DVu3bgUAaLVaDBgwAIGBgdiwYQPOnj2LSZMmwdHREdOmTQMAHDt2DGPHjsXy5csxZMgQbN26FSEhITh16hQ6duxYI+faEKlU0igXe/ZIXS78/JSuiIiIiKiCRBXdvn1bfPnll2L+/Pni1q1bQggh4uPjxfXr16u0PwBi165d8ufi4mLh7u4uVq9eLa/Lzs4WarVabNu2TQghxPnz5wUAERcXJ7f56aefhEqlEjdu3BBCCPHFF18IJycnkZ+fL7eZN2+eaNu2rfx59OjRIjg4WK8ePz8/8corr1S4/pycHAFA5OTkVPg7DcGqVUIAQoSEKF0JERERNXSVyWtV6m5x5swZtGnTBitXrsQ//vEPZGdnAwB27tyJBQsW1Eh4T0lJQXp6OgIDA+V1Dg4O8PPzQ8z/xhSLiYmBo6MjunfvLrcJDAyEmZkZYmNj5TZ9+/bVm/gkKCgIycnJuH37ttym5HF0bWIeMXZZfn4+tFqt3kJl6cZLjo6WhoMjIiIiMgVVCsmzZ8/Gyy+/jIsXL8rdHgBg8ODBiIqKqpHC0tPTAQBubm56693c3ORt6enpcHV11dtuYWEBZ2dnvTaG9lHyGOW10W03ZPny5XBwcJAXT0/Pyp5ig9CtG6BWA3/+CZTqTk5ERERktKoUkuPi4vDKK6+UWd+sWbNHBsv6ZMGCBcjJyZGXa9euKV2SUVKrgR49pPccCo6IiIhMRZVCslqtNti94Pfff0eTJk2qXRQAuLu7AwAyMjL01mdkZMjb3N3dkZmZqbe9sLAQWVlZem0M7aPkMcpro9tuiFqthkaj0VvIMI6XTERERKamSiF52LBheO+991BQUAAAUKlUuHr1KubNm4cRI0bUSGE+Pj5wd3dHRESEvE6r1SI2Nhb+/v4AAH9/f2RnZyM+Pl5uExkZieLiYvj9bygFf39/REVFybUCQHh4ONq2bQsnJye5Tcnj6NrojkPVw5BMREREpqZKIfmjjz5Cbm4uXF1dcf/+ffTr1w+tW7eGvb09li1bVuH95ObmIiEhAQkJCQCkh/USEhJw9epVqFQqhIWF4YMPPsCePXtw9uxZjB8/Hh4eHggJCQEA+Pr6YuDAgZg6dSpOnDiB6OhozJw5E2PGjIGHhwcAYNy4cbCyssLkyZORmJiI77//HmvWrMHs2bPlOmbNmoUDBw7go48+QlJSEpYuXYqTJ09i5syZVfl5qBR/f2k4uIsXgVI37ImIiIiMU3WG0Thy5IhYt26dWLlypQgPD6/09w8dOiQAlFkmTJgghJCGgVu0aJFwc3MTarVa9O/fXyQnJ+vt49atW2Ls2LHCzs5OaDQaMXHiRHHnzh29NqdPnxYBAQFCrVaLZs2aiRUrVpSp5YcffhBt2rQRVlZWokOHDmLfvn2VOhcOAfdonTpJQ8H95z9KV0JEREQNVWXymkoIDsxVE7RaLRwcHJCTk8P+yQa8+iqwYQPw5pvAxx8rXQ0RERE1RJXJa1WacQ8AIiIiEBERgczMTBQXF+tt+9e//lXV3VI9FRAgheToaKUrISIiInq8KoXkd999F++99x66d++Opk2bQqVS1XRdVM/oHt47dQq4exewtVW2HiIiIqJHqVJI3rBhAzZv3oyXXnqppuuhesrLC2jeHLh+HThxAnj2WaUrIiIiIipflUa3ePDgAXr16lXTtVA9plJxKDgiIiIyHVUKyVOmTMHWrVtruhaq5xiSiYiIyFRUqbtFXl4eNm7ciF9++QVPPvkkLC0t9bZ/zOELyABdSD52DCgsBCyq/NgoERERUe2qUkw5c+YMunTpAgA4d+5cTdZD9VjHjoBGA2i1wNmzQNeuSldEREREZFiVQvKhQ4dqug5qAMzNpdn3Dh6UulwwJBMREZGxqlRIHj58+GPbqFQq/Oc//6lyQVS/BQRIITk6Gnj9daWrISIiIjKsUiHZwcGhtuqgBkLXL/nIEUAIadQLIiIiImPDaalrCKelrph79wAHB+nBvZQUwNtb6YqIiIiooahMXqvSEHBEVdWoEdCtm/SeQ8ERERGRsWJIpjrH8ZKJiIjI2DEkU53r3Vt6ZUgmIiIiY8WQTHVOF5ITE4GsLGVrISIiIjKEIZnqnKsr0KaN9D4mRtlaiIiIiAxhSCZFsF8yERERGTOGZFIEQzIREREZM4ZkUoQuJJ84AeTlKVsLERERUWkMyaSI1q2lvskPHgDx8UpXQ0RERKSPIZkUoVJxKDgiIiIyXgzJpBj2SyYiIiJjxZBMitGF5GPHgOJiZWshIiIiKokhmRTTtStgYyNNKJKUpHQ1RERERA8xJJNiLC2Bnj2l9+xyQURERMaEIZkUxX7JREREZIwYkklRDMlERERkjBiSSVE9ewJmZkBKCnDjhtLVEBEREUkYkklRGg3w5JPS++hoZWshIiIi0mFIJsXpulwwJBMREZGxYEgmxbFfMhERERkbhmRSnG566oQE4M4dRUshIiIiAsCQTEageXPA21uade/4caWrISIiImJIJiPBLhdERERkTBiSySgwJBMREZExYUgmo6Drl3z8OFBQoGwtRERERAzJZBTatwccHYF794DTp5WuhoiIiBo6hmQyCmZmD+8ms8sFERERKc3oQ/KdO3cQFhaGFi1awMbGBr169UJcXJy8XQiBxYsXo2nTprCxsUFgYCAuXryot4+srCyEhoZCo9HA0dERkydPRm5url6bM2fOoE+fPrC2toanpydWrVpVJ+dHD7FfMhERERkLow/JU6ZMQXh4OL7++mucPXsWAwYMQGBgIG7cuAEAWLVqFdauXYsNGzYgNjYWtra2CAoKQl5enryP0NBQJCYmIjw8HHv37kVUVBSmTZsmb9dqtRgwYABatGiB+Ph4rF69GkuXLsXGjRvr/HwbspIhWQhlayEiIqKGTSWE8caR+/fvw97eHv/9738RHBwsr+/WrRsGDRqE999/Hx4eHpgzZw7eeustAEBOTg7c3NywefNmjBkzBhcuXED79u0RFxeH7t27AwAOHDiAwYMH4/r16/Dw8MD69euxcOFCpKenw8rKCgAwf/587N69G0lJSRWqVavVwsHBATk5OdBoNDX8SzQMeXmAgwPw4AFw8SLQurXSFREREVF9Upm8ZtR3kgsLC1FUVARra2u99TY2Njh69ChSUlKQnp6OwMBAeZuDgwP8/PwQExMDAIiJiYGjo6MckAEgMDAQZmZmiI2Nldv07dtXDsgAEBQUhOTkZNy+fdtgbfn5+dBqtXoLVY+1NfD009J7drkgIiIiJRl1SLa3t4e/vz/ef/993Lx5E0VFRfjmm28QExODtLQ0pKenAwDc3Nz0vufm5iZvS09Ph6urq952CwsLODs767UxtA/dNkOWL18OBwcHefH09Kz+CRMf3iMiIiKjYNQhGQC+/vprCCHQrFkzqNVqrF27FmPHjoWZmbKlL1iwADk5OfJy7do1ReupL3T9kqOjla2DiIiIGjajD8mtWrXCr7/+itzcXFy7dg0nTpxAQUEBWrZsCXd3dwBARkaG3ncyMjLkbe7u7sjMzNTbXlhYiKysLL02hvah22aIWq2GRqPRW6j6evWSXpOSgD//VLYWIiIiariMPiTr2NraomnTprh9+zYOHjyIF154AT4+PnB3d0dERITcTqvVIjY2Fv7+/gAAf39/ZGdnIz4+Xm4TGRmJ4uJi+Pn5yW2ioqJQUGKqt/DwcLRt2xZOTk51dIYEAC4u0sQiAHDsmLK1EBERUcNl9CH54MGDOHDgAFJSUhAeHo5nn30W7dq1w8SJE6FSqRAWFoYPPvgAe/bswdmzZzF+/Hh4eHggJCQEAODr64uBAwdi6tSpOHHiBKKjozFz5kyMGTMGHh4eAIBx48bBysoKkydPRmJiIr7//nusWbMGs2fPVvDMGy6Ol0xERERKs1C6gMfJycnBggULcP36dTg7O2PEiBFYtmwZLC0tAQBvv/027t69i2nTpiE7OxsBAQE4cOCA3ogY3377LWbOnIn+/fvDzMwMI0aMwNq1a+XtDg4O+PnnnzFjxgx069YNjRs3xuLFi/XGUqa6ExAAbNzIkExERETKMepxkk0Jx0muOSkpQMuWgKUlkJ0NNGqkdEVERERUH9SbcZKpYfL2Bpo2BQoKgBIzkBMRERHVGYZkMjoqFYeCIyIiImUxJJNR4sN7REREpCSGZDJKupB87BhQVKRsLURERNTwMCSTUXryScDODsjJARITla6GiIiIGhqGZDJKFhbA/+aDYZcLIiIiqnMMyWS02C+ZiIiIlMKQTEard2/plSGZiIiI6hpDMhktPz/A3By4dg24elXpaoiIiKghYUgmo2VnB3TtKr3neMlERERUlxiSyaixXzIREREpgSGZjBpDMhERESmBIZmMmu7hvbNngexsRUshIiKiBoQhmYyauzvQujUgBBATo3Q1RERE1FAwJJPRY5cLIiIiqmsMyWT0OF4yERER1TWGZDJ6ujvJJ04ADx4oWwsRERE1DAzJZPTatgVcXIC8PODUKaWrISIiooaAIZmMnkrFfslERERUtxiSySQwJBMREVFdYkgmk1AyJAuhbC1ERERU/zEkk0l46inA2hq4dQtITla6GiIiIqrvGJLJJFhZAT16SO/Z5YKIiIhqG0MymQxdl4voaGXrICIiovqPIZlMBh/eIyIiorrCkEwmw99fer10CVi/Hjh8GCgqUrQkIiIiqqcYkslkREYClpbS+9deA559FvD2BnbuVLQsIiIiqocYkskk7NwJjBwJFBTor79xQ1rPoExEREQ1iSGZjF5RETBrluHxkXXrwsLY9YKIiIhqDkMyGb0jR4Dr18vfLgRw7ZrUjoiIiKgmMCST0UtLq9l2RERERI/DkExGr2nTirXbtg24eLF2ayEiIqKGgSGZjF6fPkDz5oBK9eh2P/4ItG0LjBoFxMXVTW1ERERUPzEkk9EzNwfWrJHelw7KKpW0vP8+EBws9U/esUOawvq554CDBw0/8EdERET0KAzJZBKGD5fCb7Nm+uubN5fW/9//AXv3AmfPAuPHAxYWwKFDwMCBQNeuwNatQGGhMrUTERGR6VEJwftsNUGr1cLBwQE5OTnQaDRKl1NvFRVJo1ikpUl9lfv0ke40l3b1KvDpp8DGjcDdu9K6Fi2AOXOASZMAW9s6LZuIiIiMQGXyGkNyDWFINk5ZWdIU1mvWAH/+Ka1zcQFmzpSWxo2VrY+IiIjqTmXymlF3tygqKsKiRYvg4+MDGxsbtGrVCu+//z5K5nohBBYvXoymTZvCxsYGgYGBuFhqiIOsrCyEhoZCo9HA0dERkydPRm5url6bM2fOoE+fPrC2toanpydWrVpVJ+dItcvZGVi4EEhNlcJyq1bArVvAu+8CXl7A668DV64oXSUREREZG6MOyStXrsT69evx+eef48KFC1i5ciVWrVqFzz77TG6zatUqrF27Fhs2bEBsbCxsbW0RFBSEvLw8uU1oaCgSExMRHh6OvXv3IioqCtOmTZO3a7VaDBgwAC1atEB8fDxWr16NpUuXYuPGjXV6vlR7bGyA6dOB5GTg+++Bp54C7t8HPv8caN0aGDcOSEhQukoiIiIyFkbd3WLIkCFwc3PDV199Ja8bMWIEbGxs8M0330AIAQ8PD8yZMwdvvfUWACAnJwdubm7YvHkzxowZgwsXLqB9+/aIi4tD9+7dAQAHDhzA4MGDcf36dXh4eGD9+vVYuHAh0tPTYWVlBQCYP38+du/ejaSkpArVyu4WpkUIIDISWLUK+Pnnh+sHDADmzQOeffbxQ84RERGRaak33S169eqFiIgI/P777wCA06dP4+jRoxg0aBAAICUlBenp6QgMDJS/4+DgAD8/P8TExAAAYmJi4OjoKAdkAAgMDISZmRliY2PlNn379pUDMgAEBQUhOTkZt2/fNlhbfn4+tFqt3kKmQ6UC+veXhog7dQoYOxYwM5MCc//+0hBy27dLDwoSERFRw2PUIXn+/PkYM2YM2rVrB0tLS3Tt2hVhYWEIDQ0FAKSnpwMA3Nzc9L7n5uYmb0tPT4erq6vedgsLCzg7O+u1MbSPkscobfny5XBwcJAXT0/Pap4tKUU3RNylS8CMGVLXjJMngdGjpclJNmyQumYQERFRw2HUIfmHH37At99+i61bt+LUqVPYsmUL/vGPf2DLli1Kl4YFCxYgJydHXq5du6Z0SVRNPj5SH+XUVGDxYumhv8uXgVdfBby9gWXLgHL+YYGIiIjqGaMOyXPnzpXvJnfq1AkvvfQS3nzzTSxfvhwA4O7uDgDIyMjQ+15GRoa8zd3dHZmZmXrbCwsLkZWVpdfG0D5KHqM0tVoNjUajt1D90KSJNPrF1avS0HFeXkBmpjRhiZeXNNYy/05ERERUvxl1SL537x7MzPRLNDc3R3FxMQDAx8cH7u7uiIiIkLdrtVrExsbC398fAODv74/s7GzEx8fLbSIjI1FcXAw/Pz+5TVRUFAoKCuQ24eHhaNu2LZycnGrt/Mi42doCb7whdcP45hugUycgNxf4+GOgZUvg5ZeBxESlqyQiIqLaYNQheejQoVi2bBn27duHK1euYNeuXfj444/x4osvAgBUKhXCwsLwwQcfYM+ePTh79izGjx8PDw8PhISEAAB8fX0xcOBATJ06FSdOnEB0dDRmzpyJMWPGwMPDAwAwbtw4WFlZYfLkyUhMTMT333+PNWvWYPbs2UqdOhkRS0sgNBQ4fRr46SfgmWekKa63bAE6dgSGDpVmATTecWKIiIio0oQR02q1YtasWcLLy0tYW1uLli1bioULF4r8/Hy5TXFxsVi0aJFwc3MTarVa9O/fXyQnJ+vt59atW2Ls2LHCzs5OaDQaMXHiRHHnzh29NqdPnxYBAQFCrVaLZs2aiRUrVlSq1pycHAFA5OTkVP2EyWTExgoxYoQQKpUQUjwWwt9fiF27hCgqUro6IiIiMqQyec2ox0k2JRwnuWH6/Xfgo4+AzZuBBw+kde3aAXPnSnef1WpFyyMiIqIS6s04yUTGrk0b4J//lEbEWLAAcHAAkpKAyZOlfsurVwM5OUpXSURERJXFkExUA9zdgQ8/lEbE+Mc/gGbNgJs3gbfflkbEmD8fSEtTukoiIiKqKIZkohqk0UhDxP3xB/Cvf0ldL7RaYOVKaazlqVOB5GSlqyQiIqLHYUgmqgVWVsDEidIQcf/9L9Crl9Rn+f/9P8DXFxg+HPjfrOhERERkhBiSiWqRmRkwbBgQHQ0cPSoNFycEsGsX0LMn0K8fsH8/h48jIiIyNgzJRHWkd29gzx7p7vLLL0vjL0dFAcHBwJNPAl9/DZSYz4aIiIgUxJBMVMfatwc2bZL6Lc+ZA9jZAefOAePHA61aAZ9+Ks3sV1pREXD4MLBtm/RaVFTHhRMRETUgDMlECmneXBoJ4+pVaWQMNzfg2jXgzTelETEWLQIyM6W2O3dKD/49+ywwbpz06u0trSciIqKax8lEaggnE6HqyssD/v1vaWzlS5ekddbWUr/ln38u229ZpZJed+yQHgQkIiKiR+NkIkQmyNoamDZNmoxk+3age3cpOB88aPjBPt26sDB2vSAiIqppDMlERsbcHBg5EjhxAvj440e3FULqonHkSN3URkRE1FBYKF0AERmmUkkz+VXERx9Jd50DAqQHAYmIiKh6GJKJjFjTphVrt3evtFhYAD16AM89Jy3+/lI3DiIiIqocPrhXQ/jgHtWGoiJpFIsbNwz3S1apACcnacKSQ4eA1FT97Wq1NNufLjQ//bQ0PjMREVFDVJm8xpBcQxiSqbbs3Cn1UQb0g7Kh0S1SUqSwHBkpLWlp+vuytQX69HkYmrt0kfpAExERNQQMyQpgSKbatHMnMGsWcP36w3WentLEI+UN/yYEkJz8MDQfOgTcuqXfxtFRGmLuueeksZc7dJCm0iYiIqqPGJIVwJBMta2oSBrFIi1N6qvcp0/l7gIXFwNnzz4Mzb/+Cmi1+m2aNJHCsi40P/HEwzvWREREpo4hWQEMyWRqCguBU6cehuYjR4D79/XbNGv2sGvGs88CLVooUysREVFNYEhWAEMymboHD4DY2IehOSZGWldSy5b6obmiQ9QREREZA4ZkBTAkU31z7x5w7NjD0BwXV3ZmP1/fh6G5Xz/AxUWZWomIiCqCIVkBDMlU32m1UpcMXWhOSCg72kbnzg9Dc58+AP+nQERExoQhWQEMydTQ3LolPfynC83nz+tvNzcHund/GJp79QIaNVKmViIiIoAhWREMydTQpacDhw8/HKP58mX97VZWQM+eD0Ozn5+07nGqO6oHERGRDkOyAhiSifRdvao/sUnJMZ4BwMYGCAh4+BBgt27StNolGRofunlzYM2a8seHJiIiKg9DsgIYkonKJwRw6ZJ+aP7zT/029vb6E5tcugSMHl12Om5DMw0SERFVBEOyAhiSiSpOCCAx8WFoPnwYyM7Wb2NmJk2AYohKJd1RTklh1wsiIqo4hmQFMCQTVV1REXD69MO7zIcOAXl5j//ef/4DvPgiZwUkIqKKYUhWAEMyUc35+mtg/PiKtXVyAtq3l8Zs9vV9+N7TU7obTUREpFOZvGbxyK1ERArw9Kx429u3gehoaSmpUaOHwblkeG7VquwDgkRERKXxPxVEZHT69JH6HN+4UfbBPeBhn+Tz56Wh5s6fBy5cePh68aI0Y2B8vLSUZGkJtGmjH5x9fYG2bQFr67o5PyIiMn4MyURkdMzNpWHeRo6UAnHpmf0A4NNPATs7aZa/zp31v19QIIXnCxf0w3NSkhSeExOlpSQzM8DHp2x49vXlzIFERA0R+yTXEPZJJqp5hsZJ9vSUAnJVhn8rLpbGby4dns+fLzu6RknNmpUNz+3bA02aVL4GIiJSDh/cUwBDMlHtqIsZ94QAMjLKhucLF6TjlsfFxfBDg82b18yIG5xtkIioZjEkK4Ahmah+ys4uG5zPnweuXCn/O3Z2hh8abNmy4iGXsw0SEdU8hmQFMCQTNSz37gHJyWXD86VLQGGh4e+o1YYfGmzTRtqms3On1B+bsw0SEdUshmQFMCQTEQA8eKA/4oYuPCcllT9BipmZNDSdry/Qrh3w5ZfS0HaGcLZBIqKqY0hWAEMyET1KcTGQmlo2PF+4AOTkVH5/27ZJd5s55jMRUcUxJCuAIZmIqkIIID39YWDeswcID6/Yd83NpZE3vL2BFi2kRffe21saCaRkNw4iooauMnnN6Cdt9fb2hkqlKrPMmDEDAJCXl4cZM2bAxcUFdnZ2GDFiBDIyMvT2cfXqVQQHB6NRo0ZwdXXF3LlzUViq0+Dhw4fx1FNPQa1Wo3Xr1ti8eXNdnSIRNWAqlTRyRf/+wMyZwDvvVOx7FhbS6BdXrwJRUdJU3h98AEyZAjz/PPDEE4CNDeDhAfTqBYwdCyxYAGzYAPz0kxTI792r3XMjIjJlRv8PdXFxcSgqKpI/nzt3Ds8//zxGjRoFAHjzzTexb98+bN++HQ4ODpg5cyaGDx+O6P/NUVtUVITg4GC4u7vj2LFjSEtLw/jx42FpaYkPP/wQAJCSkoLg4GBMnz4d3377LSIiIjBlyhQ0bdoUQUFBdX/SRNRgVXS2wcuXgT//lLpwXLkivZZ8f+UKcP++NHxcWhoQE2P4eE2aGL4LrVvn4FBrp0pEZNRMrrtFWFgY9u7di4sXL0Kr1aJJkybYunUrRo4cCQBISkqCr68vYmJi0LNnT/z0008YMmQIbt68CTc3NwDAhg0bMG/ePPz555+wsrLCvHnzsG/fPpw7d04+zpgxY5CdnY0DBw5UqC52tyCimqIb3QIwPNtgRUa3EAL466+ywblkmNZqH1+Lo2PZ4FwyTDs718yY0KVxjGgiqg2VyWtGfye5pAcPHuCbb77B7NmzoVKpEB8fj4KCAgQGBspt2rVrBy8vLzkkx8TEoFOnTnJABoCgoCC8+uqrSExMRNeuXRETE6O3D12bsLCwcmvJz89Hfn6+/Flbkf/aEBFVwPDhUhA2NE5yRWcbVKmku8RNmgDduxtuk51d/l3o1FTg1i2pTXY2cPq04X3Y2j46RLu5VT5Ec4xoIjIGJhWSd+/ejezsbLz88ssAgPT0dFhZWcHR0VGvnZubG9LT0+U2JQOybrtu26PaaLVa3L9/HzY2NmVqWb58Od59992aOC0iojKGDwdeeKF276Y6OgJdukiLIbm55Qfo1FTpgcO7d6WHDs+fN7wPtRrw8jLclcPbW+ozXfKcyhsj+sYNaT3HiCaiumJSIfmrr77CoEGD4OHhoXQpWLBgAWbPni1/1mq18PT0VLAiIqpvzM2BZ55R7vh2dkCHDtJiSF6e9OBgeXejb94E8vOBixelxRALC2kUjhYtpNf//tdwX2whpDvSYWHSXx7Y9YKIapvJhOTU1FT88ssv2Llzp7zO3d0dDx48QHZ2tt7d5IyMDLi7u8ttTpw4obcv3egXJduUHhEjIyMDGo3G4F1kAFCr1VBzbCUiasCsraXZAtu0Mby9oEDqMlFen+hr16TZCVNSpOVxhJC+ExICdO0KuLpK3Tl0r25u0t3x2ugjTUQNj8mE5E2bNsHV1RXBwcHyum7dusHS0hIREREYMWIEACA5ORlXr16Fv78/AMDf3x/Lli1DZmYmXF1dAQDh4eHQaDRo37693Gb//v16xwsPD5f3QURElWdpCfj4SIshRUXS3WZdcP7vf4Ht2x+/3717paW8Y7q6Gg7Qpdc1biy1NyZ8YJHIeJjE6BbFxcXw8fHB2LFjsWLFCr1tr776Kvbv34/NmzdDo9Hg9ddfBwAcO3YMgDQEXJcuXeDh4YFVq1YhPT0dL730EqZMmaI3BFzHjh0xY8YMTJo0CZGRkXjjjTewb9++Cg8Bx9EtiIiq5/Bh4NlnH99uwgSgUSMgIwPIzHz4WpWZC11cDAdoQ+G6UaPK778y+MAiUe2rdzPu/fzzzwgKCkJycjLalPp3vby8PMyZMwfbtm1Dfn4+goKC8MUXX8hdKQCpq8arr76Kw4cPw9bWFhMmTMCKFStgUWI+18OHD+PNN9/E+fPn0bx5cyxatEh+QLAiGJKJiKqnqEh6mO9xY0SnpBi+u5qXJ40dnZFRNkCXfM3IkIbHKy6uXH22to+/O617dXKqXLeP8h5YrMywf0T0ePUuJJsChmQiouqriTGiK6KoSBrirrwgXTJQZ2RIDyBWhoVF+QG6dMh2dpZmSCx5B7mkx/3lgIgqjiFZAQzJREQ1w1C3A0/Pio8RXdOEAO7cMRygDYXr7OzaqWPbNumhRWvr2tk/UUPAkKwAhmQioppjyg+w5edXrNtHZqbUrqiocvvXaB7eiX7cYmtbO+dIZKoYkhXAkExERJVVXAz8+KN0h/hxLCykIfMqQ9ePuiKLvb2yw+eZ8l+MyHTU22mpiYiI6hMzM2DIEKnP8eMeWPzjD2kWxJJ9pR+13L8vzYj4xx/S8jjW1hUP1DU9HjVH9iBjxDvJNYR3komIqKpq+oFFISoXqHNzK1evlZX+A4iPWpydpb8MPO7cObIH1QV2t1AAQzIREVWHkg8s3rtX8UBd2fGoLSyAJk0MB+gmTYA5c6Qh+QzhyB5U0xiSFcCQTERE1WUK/XLz8soOkVfekpVVM8ccPVqaitzFRZop0cVFfzG2mRPJeDEkK4AhmYiISN+DB/ojfZReTp8GEhOrfxyNpmxwNhSmS65r1EjZBxV1TOEvRvUJH9wjIiIixVlZAc2aSYshFZ2KfPRoKdT+9Zc0CYxuycqS+jJrtdKSklLx2tTqioXpkuscHB7dv7qy+MCiceOd5BrCO8lERESVU92pyIuKpMlbSgbn0kG69Odbt6Q73FVhZiY9iFjRu9WP6g7CBxaVwe4WCmBIJiIiqry6mopcRzfyx+OCdOl1lR0BpKTS3UGcnIC9e8vfp0oFeHgAV65IDz7WV0p0NWFIVgBDMhERUdUY21TkhuTnPz5Il/58+7bhO+QVpVJJAVujkbp66N5XdNF9x86uZruJ1ASlupowJCuAIZmIiKjq6uMDbEVFUlAuHa7Dw4GtW+u2Fnv7ygVrQ4u9fc3c2VayqwlDsgIYkomIiKgiKvrA4o4dQMeO0kOJOTkPH1Cs6JKTU/mpzB+nUaPKBevSi60t0K2b1A/dkNoeG5ujWxAREREZqT59KjYVeUhI9YKiEFI3kaoG7JKf8/Olfd67Jy3p6VWv63E1X7sm/avCM8/UzjEqiiGZiIiIqA6Zm0t9b0eOlAKxoQcWP/20+ndSVSrA2lpa3Nyqt6/8fODOnaoF7JLLvXsVO15aWvXqrQkMyURERER1bPhwqTuFoYfXjOmBRR21WloaN67efiIigMDAx7dr2rR6x6kJ7JNcQ9gnmYiIiCqrPj6w+CjVHRu7utgnmYiIiMgEmJsr3/e2LtVVV5OaYGSj5hERERFRfabralJ6uvLmzY1rpkHeSSYiIiKiOjV8OPDCC8bd1YQhmYiIiIjqnLF3NWF3CyIiIiKiUhiSiYiIiIhKYUgmIiIiIiqFIZmIiIiIqBSGZCIiIiKiUhiSiYiIiIhKYUgmIiIiIiqFIZmIiIiIqBSGZCIiIiKiUhiSiYiIiIhK4bTUNUQIAQDQarUKV0JEREREhuhymi63PQpDcg25c+cOAMDT01PhSoiIiIjoUe7cuQMHB4dHtlGJikRpeqzi4mLcvHkT9vb2UKlUtX48rVYLT09PXLt2DRqNptaPR8rjNW94eM0bJl73hofXvO4IIXDnzh14eHjAzOzRvY55J7mGmJmZoXnz5nV+XI1Gw/9BNTC85g0Pr3nDxOve8PCa143H3UHW4YN7RERERESlMCQTEREREZXCkGyi1Go1lixZArVarXQpVEd4zRseXvOGide94eE1N058cI+IiIiIqBTeSSYiIiIiKoUhmYiIiIioFIZkIiIiIqJSGJKJiIiIiEphSDZB69atg7e3N6ytreHn54cTJ04oXRJV0fLly/H000/D3t4erq6uCAkJQXJysl6bvLw8zJgxAy4uLrCzs8OIESOQkZGh1+bq1asIDg5Go0aN4Orqirlz56KwsLAuT4WqaMWKFVCpVAgLC5PX8ZrXPzdu3MDf//53uLi4wMbGBp06dcLJkyfl7UIILF68GE2bNoWNjQ0CAwNx8eJFvX1kZWUhNDQUGo0Gjo6OmDx5MnJzc+v6VKiCioqKsGjRIvj4+MDGxgatWrXC+++/j5LjJfC6GzlBJuW7774TVlZW4l//+pdITEwUU6dOFY6OjiIjI0Pp0qgKgoKCxKZNm8S5c+dEQkKCGDx4sPDy8hK5ublym+nTpwtPT08REREhTp48KXr27Cl69eolby8sLBQdO3YUgYGB4rfffhP79+8XjRs3FgsWLFDilKgSTpw4Iby9vcWTTz4pZs2aJa/nNa9fsrKyRIsWLcTLL78sYmNjxR9//CEOHjwoLl26JLdZsWKFcHBwELt37xanT58Ww4YNEz4+PuL+/ftym4EDB4rOnTuL48ePiyNHjojWrVuLsWPHKnFKVAHLli0TLi4uYu/evSIlJUVs375d2NnZiTVr1shteN2NG0OyienRo4eYMWOG/LmoqEh4eHiI5cuXK1gV1ZTMzEwBQPz6669CCCGys7OFpaWl2L59u9zmwoULAoCIiYkRQgixf/9+YWZmJtLT0+U269evFxqNRuTn59ftCVCF3blzRzzxxBMiPDxc9OvXTw7JvOb1z7x580RAQEC524uLi4W7u7tYvXq1vC47O1uo1Wqxbds2IYQQ58+fFwBEXFyc3Oann34SKpVK3Lhxo/aKpyoLDg4WkyZN0ls3fPhwERoaKoTgdTcF7G5hQh48eID4+HgEBgbK68zMzBAYGIiYmBgFK6OakpOTAwBwdnYGAMTHx6OgoEDvmrdr1w5eXl7yNY+JiUGnTp3g5uYmtwkKCoJWq0ViYmIdVk+VMWPGDAQHB+tdW4DXvD7as2cPunfvjlGjRsHV1RVdu3bFl19+KW9PSUlBenq63jV3cHCAn5+f3jV3dHRE9+7d5TaBgYEwMzNDbGxs3Z0MVVivXr0QERGB33//HQBw+vRpHD16FIMGDQLA624KLJQugCrur7/+QlFRkd5/GAHAzc0NSUlJClVFNaW4uBhhYWHo3bs3OnbsCABIT0+HlZUVHB0d9dq6ubkhPT1dbmPoz4RuGxmf7777DqdOnUJcXFyZbbzm9c8ff/yB9evXY/bs2XjnnXcQFxeHN954A1ZWVpgwYYJ8zQxd05LX3NXVVW+7hYUFnJ2dec2N1Pz586HVatGuXTuYm5ujqKgIy5YtQ2hoKADwupsAhmQiIzFjxgycO3cOR48eVboUqkXXrl3DrFmzEB4eDmtra6XLoTpQXFyM7t2748MPPwQAdO3aFefOncOGDRswYcIEhauj2vLDDz/g22+/xdatW9GhQwckJCQgLCwMHh4evO4mgt0tTEjjxo1hbm5e5in3jIwMuLu7K1QV1YSZM2di7969OHToEJo3by6vd3d3x4MHD5Cdna3XvuQ1d3d3N/hnQreNjEt8fDwyMzPx1FNPwcLCAhYWFvj111+xdu1aWFhYwM3Njde8nmnatCnat2+vt87X1xdXr14F8PCaPer/293d3ZGZmam3vbCwEFlZWbzmRmru3LmYP38+xowZg06dOuGll17Cm2++ieXLlwPgdTcFDMkmxMrKCt26dUNERIS8rri4GBEREfD391ewMqoqIQRmzpyJXbt2ITIyEj4+Pnrbu3XrBktLS71rnpycjKtXr8rX3N/fH2fPntX7P9Lw8HBoNJoy/2Em5fXv3x9nz55FQkKCvHTv3h2hoaHye17z+qV3795lhnb8/fff0aJFCwCAj48P3N3d9a65VqtFbGys3jXPzs5GfHy83CYyMhLFxcXw8/Org7Ogyrp37x7MzPRjlrm5OYqLiwHwupsEpZ8cpMr57rvvhFqtFps3bxbnz58X06ZNE46OjnpPuZPpePXVV4WDg4M4fPiwSEtLk5d79+7JbaZPny68vLxEZGSkOHnypPD39xf+/v7ydt1wYAMGDBAJCQniwIEDokmTJhwOzISUHN1CCF7z+ubEiRPCwsJCLFu2TFy8eFF8++23olGjRuKbb76R26xYsUI4OjqK//73v+LMmTPihRdeMDgUWNeuXUVsbKw4evSoeOKJJzgUmBGbMGGCaNasmTwE3M6dO0Xjxo3F22+/LbfhdTduDMkm6LPPPhNeXl7CyspK9OjRQxw/flzpkqiKABhcNm3aJLe5f/++eO2114STk5No1KiRePHFF0VaWprefq5cuSIGDRokbGxsROPGjcWcOXNEQUFBHZ8NVVXpkMxrXv/8+OOPomPHjkKtVot27dqJjRs36m0vLi4WixYtEm5ubkKtVov+/fuL5ORkvTa3bt0SY8eOFXZ2dkKj0YiJEyeKO3fu1OVpUCVotVoxa9Ys4eXlJaytrUXLli3FwoUL9YZp5HU3biohSkz9QkRERERE7JNMRERERFQaQzIRERERUSkMyUREREREpTAkExERERGVwpBMRERERFQKQzIRERERUSkMyUREREREpTAkExERERGVwpBMRFRHrly5ApVKhYSEBKVLkSUlJaFnz56wtrZGly5dKv19Yzyn6vrqq68wYMAA+fPLL7+MkJCQcttv2LABQ4cOrYPKiKguMSQTUYPx8ssvQ6VSYcWKFXrrd+/eDZVKpVBVylqyZAlsbW2RnJyMiIgIpcvB5s2b4ejoqNjx8/LysGjRIixZsqTC35k0aRJOnTqFI0eO1GJlRFTXGJKJqEGxtrbGypUrcfv2baVLqTEPHjyo8ncvX76MgIAAtGjRAi4uLjVYlbKKiopQXFxc6e/t2LEDGo0GvXv3rvB3rKysMG7cOKxdu7bSxyMi48WQTEQNSmBgINzd3bF8+fJy2yxdurRM14NPP/0U3t7e8mfdP8F/+OGHcHNzg6OjI9577z0UFhZi7ty5cHZ2RvPmzbFp06Yy+09KSkKvXr1gbW2Njh074tdff9Xbfu7cOQwaNAh2dnZwc3PDSy+9hL/++kve/swzz2DmzJkICwtD48aNERQUZPA8iouL8d5776F58+ZQq9Xo0qULDhw4IG9XqVSIj4/He++9B5VKhaVLl5a7n1WrVqF169ZQq9Xw8vLCsmXLDLY1dCe49J3606dP49lnn4W9vT00Gg26deuGkydP4vDhw5g4cSJycnKgUqn0asrPz8dbb72FZs2awdbWFn5+fjh8+HCZ4+7Zswft27eHWq3G1atXcfjwYfTo0QO2trZwdHRE7969kZqaarB2APjuu+8e23UiLi4OTZo0wcqVK+V1Q4cOxZ49e3D//v1HfpeITAdDMhE1KObm5vjwww/x2Wef4fr169XaV2RkJG7evImoqCh8/PHHWLJkCYYMGQInJyfExsZi+vTpeOWVV8ocZ+7cuZgzZw5+++03+Pv7Y+jQobh16xYAIDs7G8899xy6du2KkydP4sCBA8jIyMDo0aP19rFlyxZYWVkhOjoaGzZsMFjfmjVr8NFHH+Ef//gHzpw5g6CgIAwbNgwXL14EAKSlpaFDhw6YM2cO0tLS8NZbbxncz4IFC7BixQosWrQI58+fx9atW+Hm5lbl3y00NBTNmzdHXFwc4uPjMX/+fFhaWqJXr1749NNPodFokJaWplfTzJkzERMTg++++w5nzpzBqFGjMHDgQPlcAODevXtYuXIl/t//+39ITEyEs7MzQkJC0K9fP5w5cwYxMTGYNm3aI7vWHD16FN27dy93e2RkJJ5//nksW7YM8+bNk9d3794dhYWFiI2NrfLvQkRGRhARNRATJkwQL7zwghBCiJ49e4pJkyYJIYTYtWuXKPl/h0uWLBGdO3fW++4nn3wiWrRoobevFi1aiKKiInld27ZtRZ8+feTPhYWFwtbWVmzbtk0IIURKSooAIFasWCG3KSgoEM2bNxcrV64UQgjx/vvviwEDBugd+9q1awKASE5OFkII0a9fP9G1a9fHnq+Hh4dYtmyZ3rqnn35avPbaa/Lnzp07iyVLlpS7D61WK9Rqtfjyyy8Nbted02+//SaEEGLTpk3CwcFBr03p39fe3l5s3rzZ4P4MfT81NVWYm5uLGzdu6K3v37+/WLBggfw9ACIhIUHefuvWLQFAHD58uNzzK+n27dsCgIiKitJbr/tzs3PnTmFnZye+++47g993cnIq97yIyPRYKBfPiYiUs3LlSjz33HPl3j2tiA4dOsDM7OE/yLm5uaFjx47yZ3Nzc7i4uCAzM1Pve/7+/vJ7CwsLdO/eHRcuXAAgdUU4dOgQ7Ozsyhzv8uXLaNOmDQCgW7duj6xNq9Xi5s2bZfrW9u7dG6dPn67gGQIXLlxAfn4++vfvX+HvPM7s2bMxZcoUfP311wgMDMSoUaPQqlWrctufPXsWRUVF8rnr5Ofn6/WjtrKywpNPPil/dnZ2xssvv4ygoCA8//zzCAwMxOjRo9G0aVODx9F1lbC2ti6zLTY2Fnv37sWOHTvKHenCxsYG9+7dK/c8iMi0sLsFETVIffv2RVBQEBYsWFBmm5mZGYQQeusKCgrKtLO0tNT7rFKpDK6rzANkubm5GDp0KBISEvSWixcvom/fvnI7W1vbCu+zOmxsbCrVviK/3dKlS5GYmIjg4GBERkaiffv22LVrV7n7zM3Nhbm5OeLj4/V+kwsXLmDNmjV6tZbuSrFp0ybExMSgV69e+P7779GmTRscP37c4HFcXFygUqkMPtTZqlUrtGvXDv/6178M/lkAgKysLDRp0qTc8yAi08KQTEQN1ooVK/Djjz8iJiZGb32TJk2Qnp6uF/ZqchzgkiGtsLAQ8fHx8PX1BQA89dRTSExMhLe3N1q3bq23VCYYazQaeHh4IDo6Wm99dHQ02rdvX+H9PPHEE7Cxsanw8HBNmjTBnTt3cPfuXXmdod+uTZs2ePPNN/Hzzz9j+PDh8gOOVlZWKCoq0mvbtWtXFBUVITMzs8xv4u7u/tiaunbtigULFuDYsWPo2LEjtm7darCdlZUV2rdvj/Pnz5fZ1rhxY0RGRuLSpUsYPXp0maB8+fJl5OXloWvXro+th4hMA0MyETVYnTp1QmhoaJmhu5555hn8+eefWLVqFS5fvox169bhp59+qrHjrlu3Drt27UJSUhJmzJiB27dvY9KkSQCAGTNmICsrC2PHjkVcXBwuX76MgwcPYuLEiWXC4+PMnTsXK1euxPfff4/k5GTMnz8fCQkJmDVrVoX3YW1tjXnz5uHtt9/Gv//9b1y+fBnHjx/HV199ZbC9n58fGjVqhHfeeQeXL1/G1q1bsXnzZnn7/fv3MXPmTBw+fBipqamIjo5GXFyc/JcEb29v5ObmIiIiAn/99Rfu3buHNm3aIDQ0FOPHj8fOnTuRkpKCEydOYPny5di3b1+5taekpGDBggWIiYlBamoqfv75Z1y8eFE+liFBQUE4evSowW2urq6IjIxEUlISxo4di8LCQnnbkSNH0LJly0d2GyEi08KQTEQN2nvvvVemO4Svry+++OILrFu3Dp07d8aJEyeq1Xe5tBUrVmDFihXo3Lkzjh49ij179qBx48YAIN/9LSoqwoABA9CpUyeEhYXB0dFRr/9zRbzxxhuYPXs25syZg06dOuHAgQPYs2cPnnjiiUrtZ9GiRZgzZw4WL14MX19f/O1vfyvTz1rH2dkZ33zzDfbv349OnTph27ZtekPLmZub49atWxg/fjzatGmD0aNHY9CgQXj33XcBAL169cL06dPxt7/9DU2aNMGqVasASN0mxo8fjzlz5qBt27YICQlBXFwcvLy8yq27UaNGSEpKwogRI9CmTRtMmzYNM2bMwCuvvFLudyZPnoz9+/cjJyfH4HZ3d3dERkbi7NmzCA0Nlf/ism3bNkydOvWRvyMRmRaVKN15jIiIqAEbNWoUnnrqKYP91Q1JTEzEc889h99//x0ODg61XB0R1RXeSSYiIiph9erVBkcXKU9aWhr+/e9/MyAT1TO8k0xEREREVArvJBMRERERlcKQTERERERUCkMyEREREVEpDMlERERERKUwJBMRERERlcKQTERERERUCkMyEREREVEpDMlERERERKUwJBMRERERlfL/AduCXdXx7H/rAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, max_k + 1, step), inertias, 'bo-')\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method For Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_clusters: 901\n",
      "n_clusters: 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1145539/2079289553.py:41: RuntimeWarning: Mean of empty slice.\n",
      "  new_centroids = np.array([data[data[:, -1] == i, :-1].mean(axis=0) for i in range(self.n_clusters)])\n",
      "/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py:121: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = um.true_divide(\n"
     ]
    }
   ],
   "source": [
    "max_k = 10000\n",
    "step = 9099\n",
    "inertias = elbow_method(train_matrix, 901, max_k=10000, step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6542.4006497026885, nan]\n"
     ]
    }
   ],
   "source": [
    "print(inertias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(901, max_k + 2, step), inertias, 'bo-')\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Inertia')\n",
    "plt.title('Elbow Method For Optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agrupar los vectores de características con kmeans con k=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1145539/2079289553.py:41: RuntimeWarning: Mean of empty slice.\n",
      "  new_centroids = np.array([data[data[:, -1] == i, :-1].mean(axis=0) for i in range(self.n_clusters)])\n"
     ]
    }
   ],
   "source": [
    "kmeans = KMeansHNSW(n_clusters=10000)\n",
    "kmeans.fit(train_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcular la representación de bolsa de palabras para cada imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_histograms(kmeans_, all_features):\n",
    "    histograms = []\n",
    "\n",
    "    for image_path in all_features.keys():\n",
    "        features = all_features[image_path]\n",
    "        labels = kmeans_.predict(features)\n",
    "        histogram = np.zeros(kmeans_.n_clusters)\n",
    "        for label in labels:\n",
    "            histogram[label] += 1\n",
    "        histograms.append(histogram)\n",
    "\n",
    "    # Convertir la lista de histogramas en una matriz\n",
    "    histograms_matrix = np.vstack(histograms).astype(int)\n",
    "\n",
    "    return histograms_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_histograms = get_histograms(kmeans, train_features)\n",
    "test_histograms = get_histograms(kmeans, test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bedroom': 100, 'coast': 100, 'forest': 100, 'highway': 100, 'industrial': 100, 'insidecity': 100, 'kitchen': 100, 'livingroom': 100, 'mountain': 100, 'office': 100, 'opencountry': 100, 'store': 100, 'street': 100, 'suburb': 100, 'tallbuilding': 100}\n"
     ]
    }
   ],
   "source": [
    "y_train = np.array(list(train_labels.values()))\n",
    "# Contar cuántas veces aparece cada etiqueta en el conjunto de entrenamiento\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "print(dict(zip(unique, counts)))\n",
    "y_test = np.array(list(test_labels.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the mapping\n",
    "label_mapping = {'bedroom': 0, 'coast': 1, 'forest': 2, 'highway': 3, 'industrial': 4, 'insidecity': 5, 'kitchen': 6, 'livingroom': 7, 'mountain': 8, 'office': 9, 'opencountry': 10, 'store': 11, 'street': 12, 'suburb': 13, 'tallbuilding': 14}\n",
    "\n",
    "# Manually apply the mapping\n",
    "y_train = np.array([label_mapping[label] for label in y_train])\n",
    "y_test = np.array([label_mapping[label] for label in y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenar modelos con vectores de características originales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenar un modelo de gradient boosted trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: xgboost in ./.local/lib/python3.10/site-packages (2.0.3)\n",
      "Requirement already satisfied: scipy in ./.local/lib/python3.10/site-packages (from xgboost) (1.12.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.26.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score\n",
    "\n",
    "def train_xgboost(train_histograms_, y_train_, test_histograms_, y_test_, savename):\n",
    "    # Crear el DMatrix para XGBoost\n",
    "    dtrain = xgb.DMatrix(train_histograms_, label=y_train_)\n",
    "    dtest = xgb.DMatrix(test_histograms_, label=y_test_)\n",
    "\n",
    "    # Model parameters\n",
    "    params = {\n",
    "        'max_depth': 3,\n",
    "        'eta': 0.1,\n",
    "        'objective': 'multi:softmax',  # Use 'multi:softmax' for direct class output\n",
    "        'num_class': 15,  # Number of classes\n",
    "        'eval_metric': 'mlogloss',  # Multiclass logloss\n",
    "        'tree_method': 'hist',  # Use histogram-based algorithm\n",
    "        'device': 'cuda'  # Use GPU\n",
    "    }\n",
    "\n",
    "    # Entrenar el modelo\n",
    "    num_round = 500\n",
    "\n",
    "    evals = [(dtrain, 'train'), (dtest, 'eval')]\n",
    "    bst = xgb.train(params, dtrain, num_round, evals, early_stopping_rounds=25)\n",
    "\n",
    "    # Save the model\n",
    "    model_path = f\"{curr_dir}{savename}.json\"\n",
    "    bst.save_model(model_path)\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "\n",
    "    # Hacer predicciones y evaluar el modelo\n",
    "    y_pred = bst.predict(dtest)\n",
    "    accuracy = accuracy_score(y_test_, y_pred)\n",
    "    \n",
    "    # Calcular la matriz de confusión\n",
    "    conf_matrix = confusion_matrix(y_test_, y_pred)\n",
    "\n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_xgboost_model(model_filename, test_histograms_, y_test_):\n",
    "    # Load the model\n",
    "    bst = xgb.Booster()\n",
    "    bst.load_model(model_filename)\n",
    "    print(f\"Model loaded from {model_filename}\")\n",
    "\n",
    "    # Crear el DMatrix para XGBoost\n",
    "    dtest = xgb.DMatrix(test_histograms_, label=y_test_)\n",
    "\n",
    "    # Hacer predicciones y evaluar el modelo\n",
    "    y_pred = bst.predict(dtest)\n",
    "    accuracy = accuracy_score(y_test_, y_pred)\n",
    "    \n",
    "    # Calcular la matriz de confusión\n",
    "    conf_matrix = confusion_matrix(y_test_, y_pred)\n",
    "\n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leon/.local/lib/python3.10/site-packages/xgboost/core.py:727: FutureWarning: Pass `evals` as keyword args.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.59842\teval-mlogloss:2.65534\n",
      "[1]\ttrain-mlogloss:2.50373\teval-mlogloss:2.61085\n",
      "[2]\ttrain-mlogloss:2.41979\teval-mlogloss:2.57287\n",
      "[3]\ttrain-mlogloss:2.34317\teval-mlogloss:2.54013\n",
      "[4]\ttrain-mlogloss:2.26828\teval-mlogloss:2.50916\n",
      "[5]\ttrain-mlogloss:2.19923\teval-mlogloss:2.47743\n",
      "[6]\ttrain-mlogloss:2.13732\teval-mlogloss:2.44835\n",
      "[7]\ttrain-mlogloss:2.07517\teval-mlogloss:2.42372\n",
      "[8]\ttrain-mlogloss:2.01899\teval-mlogloss:2.40131\n",
      "[9]\ttrain-mlogloss:1.96479\teval-mlogloss:2.37908\n",
      "[10]\ttrain-mlogloss:1.91380\teval-mlogloss:2.36087\n",
      "[11]\ttrain-mlogloss:1.86385\teval-mlogloss:2.33968\n",
      "[12]\ttrain-mlogloss:1.81598\teval-mlogloss:2.32178\n",
      "[13]\ttrain-mlogloss:1.77192\teval-mlogloss:2.30587\n",
      "[14]\ttrain-mlogloss:1.72966\teval-mlogloss:2.29229\n",
      "[15]\ttrain-mlogloss:1.68865\teval-mlogloss:2.27809\n",
      "[16]\ttrain-mlogloss:1.64759\teval-mlogloss:2.26311\n",
      "[17]\ttrain-mlogloss:1.60869\teval-mlogloss:2.24923\n",
      "[18]\ttrain-mlogloss:1.57200\teval-mlogloss:2.23439\n",
      "[19]\ttrain-mlogloss:1.53547\teval-mlogloss:2.22293\n",
      "[20]\ttrain-mlogloss:1.50101\teval-mlogloss:2.21164\n",
      "[21]\ttrain-mlogloss:1.46812\teval-mlogloss:2.20015\n",
      "[22]\ttrain-mlogloss:1.43718\teval-mlogloss:2.18886\n",
      "[23]\ttrain-mlogloss:1.40595\teval-mlogloss:2.17768\n",
      "[24]\ttrain-mlogloss:1.37617\teval-mlogloss:2.16615\n",
      "[25]\ttrain-mlogloss:1.34703\teval-mlogloss:2.15397\n",
      "[26]\ttrain-mlogloss:1.31971\teval-mlogloss:2.14387\n",
      "[27]\ttrain-mlogloss:1.29304\teval-mlogloss:2.13393\n",
      "[28]\ttrain-mlogloss:1.26589\teval-mlogloss:2.12424\n",
      "[29]\ttrain-mlogloss:1.24280\teval-mlogloss:2.11657\n",
      "[30]\ttrain-mlogloss:1.21868\teval-mlogloss:2.10791\n",
      "[31]\ttrain-mlogloss:1.19380\teval-mlogloss:2.09876\n",
      "[32]\ttrain-mlogloss:1.17004\teval-mlogloss:2.08972\n",
      "[33]\ttrain-mlogloss:1.14679\teval-mlogloss:2.08093\n",
      "[34]\ttrain-mlogloss:1.12465\teval-mlogloss:2.07278\n",
      "[35]\ttrain-mlogloss:1.10193\teval-mlogloss:2.06432\n",
      "[36]\ttrain-mlogloss:1.08125\teval-mlogloss:2.05772\n",
      "[37]\ttrain-mlogloss:1.06147\teval-mlogloss:2.05061\n",
      "[38]\ttrain-mlogloss:1.04047\teval-mlogloss:2.04463\n",
      "[39]\ttrain-mlogloss:1.02122\teval-mlogloss:2.03715\n",
      "[40]\ttrain-mlogloss:1.00180\teval-mlogloss:2.03105\n",
      "[41]\ttrain-mlogloss:0.98356\teval-mlogloss:2.02543\n",
      "[42]\ttrain-mlogloss:0.96566\teval-mlogloss:2.01883\n",
      "[43]\ttrain-mlogloss:0.94670\teval-mlogloss:2.01242\n",
      "[44]\ttrain-mlogloss:0.92971\teval-mlogloss:2.00665\n",
      "[45]\ttrain-mlogloss:0.91242\teval-mlogloss:2.00115\n",
      "[46]\ttrain-mlogloss:0.89609\teval-mlogloss:1.99581\n",
      "[47]\ttrain-mlogloss:0.88072\teval-mlogloss:1.98988\n",
      "[48]\ttrain-mlogloss:0.86503\teval-mlogloss:1.98434\n",
      "[49]\ttrain-mlogloss:0.84929\teval-mlogloss:1.97836\n",
      "[50]\ttrain-mlogloss:0.83474\teval-mlogloss:1.97357\n",
      "[51]\ttrain-mlogloss:0.82155\teval-mlogloss:1.96766\n",
      "[52]\ttrain-mlogloss:0.80759\teval-mlogloss:1.96233\n",
      "[53]\ttrain-mlogloss:0.79471\teval-mlogloss:1.95878\n",
      "[54]\ttrain-mlogloss:0.78107\teval-mlogloss:1.95430\n",
      "[55]\ttrain-mlogloss:0.76825\teval-mlogloss:1.94990\n",
      "[56]\ttrain-mlogloss:0.75531\teval-mlogloss:1.94523\n",
      "[57]\ttrain-mlogloss:0.74365\teval-mlogloss:1.94206\n",
      "[58]\ttrain-mlogloss:0.73152\teval-mlogloss:1.93719\n",
      "[59]\ttrain-mlogloss:0.72032\teval-mlogloss:1.93368\n",
      "[60]\ttrain-mlogloss:0.70883\teval-mlogloss:1.92920\n",
      "[61]\ttrain-mlogloss:0.69844\teval-mlogloss:1.92451\n",
      "[62]\ttrain-mlogloss:0.68713\teval-mlogloss:1.92038\n",
      "[63]\ttrain-mlogloss:0.67671\teval-mlogloss:1.91786\n",
      "[64]\ttrain-mlogloss:0.66671\teval-mlogloss:1.91356\n",
      "[65]\ttrain-mlogloss:0.65670\teval-mlogloss:1.90892\n",
      "[66]\ttrain-mlogloss:0.64652\teval-mlogloss:1.90521\n",
      "[67]\ttrain-mlogloss:0.63719\teval-mlogloss:1.90036\n",
      "[68]\ttrain-mlogloss:0.62703\teval-mlogloss:1.89627\n",
      "[69]\ttrain-mlogloss:0.61712\teval-mlogloss:1.89291\n",
      "[70]\ttrain-mlogloss:0.60707\teval-mlogloss:1.88926\n",
      "[71]\ttrain-mlogloss:0.59811\teval-mlogloss:1.88563\n",
      "[72]\ttrain-mlogloss:0.58975\teval-mlogloss:1.88305\n",
      "[73]\ttrain-mlogloss:0.58118\teval-mlogloss:1.87987\n",
      "[74]\ttrain-mlogloss:0.57236\teval-mlogloss:1.87666\n",
      "[75]\ttrain-mlogloss:0.56403\teval-mlogloss:1.87368\n",
      "[76]\ttrain-mlogloss:0.55534\teval-mlogloss:1.87075\n",
      "[77]\ttrain-mlogloss:0.54704\teval-mlogloss:1.86774\n",
      "[78]\ttrain-mlogloss:0.53862\teval-mlogloss:1.86454\n",
      "[79]\ttrain-mlogloss:0.53080\teval-mlogloss:1.86098\n",
      "[80]\ttrain-mlogloss:0.52309\teval-mlogloss:1.85803\n",
      "[81]\ttrain-mlogloss:0.51614\teval-mlogloss:1.85534\n",
      "[82]\ttrain-mlogloss:0.50950\teval-mlogloss:1.85308\n",
      "[83]\ttrain-mlogloss:0.50252\teval-mlogloss:1.85024\n",
      "[84]\ttrain-mlogloss:0.49545\teval-mlogloss:1.84796\n",
      "[85]\ttrain-mlogloss:0.48808\teval-mlogloss:1.84584\n",
      "[86]\ttrain-mlogloss:0.48088\teval-mlogloss:1.84232\n",
      "[87]\ttrain-mlogloss:0.47400\teval-mlogloss:1.83954\n",
      "[88]\ttrain-mlogloss:0.46708\teval-mlogloss:1.83697\n",
      "[89]\ttrain-mlogloss:0.46111\teval-mlogloss:1.83530\n",
      "[90]\ttrain-mlogloss:0.45476\teval-mlogloss:1.83344\n",
      "[91]\ttrain-mlogloss:0.44873\teval-mlogloss:1.83054\n",
      "[92]\ttrain-mlogloss:0.44249\teval-mlogloss:1.82820\n",
      "[93]\ttrain-mlogloss:0.43605\teval-mlogloss:1.82593\n",
      "[94]\ttrain-mlogloss:0.43004\teval-mlogloss:1.82402\n",
      "[95]\ttrain-mlogloss:0.42442\teval-mlogloss:1.82145\n",
      "[96]\ttrain-mlogloss:0.41879\teval-mlogloss:1.81937\n",
      "[97]\ttrain-mlogloss:0.41351\teval-mlogloss:1.81681\n",
      "[98]\ttrain-mlogloss:0.40835\teval-mlogloss:1.81549\n",
      "[99]\ttrain-mlogloss:0.40286\teval-mlogloss:1.81342\n",
      "[100]\ttrain-mlogloss:0.39718\teval-mlogloss:1.81144\n",
      "[101]\ttrain-mlogloss:0.39200\teval-mlogloss:1.81006\n",
      "[102]\ttrain-mlogloss:0.38622\teval-mlogloss:1.80865\n",
      "[103]\ttrain-mlogloss:0.38045\teval-mlogloss:1.80602\n",
      "[104]\ttrain-mlogloss:0.37515\teval-mlogloss:1.80405\n",
      "[105]\ttrain-mlogloss:0.36966\teval-mlogloss:1.80164\n",
      "[106]\ttrain-mlogloss:0.36468\teval-mlogloss:1.80004\n",
      "[107]\ttrain-mlogloss:0.35988\teval-mlogloss:1.79858\n",
      "[108]\ttrain-mlogloss:0.35515\teval-mlogloss:1.79714\n",
      "[109]\ttrain-mlogloss:0.35025\teval-mlogloss:1.79531\n",
      "[110]\ttrain-mlogloss:0.34577\teval-mlogloss:1.79323\n",
      "[111]\ttrain-mlogloss:0.34139\teval-mlogloss:1.79102\n",
      "[112]\ttrain-mlogloss:0.33634\teval-mlogloss:1.78958\n",
      "[113]\ttrain-mlogloss:0.33164\teval-mlogloss:1.78826\n",
      "[114]\ttrain-mlogloss:0.32737\teval-mlogloss:1.78652\n",
      "[115]\ttrain-mlogloss:0.32309\teval-mlogloss:1.78535\n",
      "[116]\ttrain-mlogloss:0.31861\teval-mlogloss:1.78408\n",
      "[117]\ttrain-mlogloss:0.31429\teval-mlogloss:1.78289\n",
      "[118]\ttrain-mlogloss:0.30994\teval-mlogloss:1.78123\n",
      "[119]\ttrain-mlogloss:0.30589\teval-mlogloss:1.77998\n",
      "[120]\ttrain-mlogloss:0.30204\teval-mlogloss:1.77843\n",
      "[121]\ttrain-mlogloss:0.29834\teval-mlogloss:1.77663\n",
      "[122]\ttrain-mlogloss:0.29427\teval-mlogloss:1.77478\n",
      "[123]\ttrain-mlogloss:0.29025\teval-mlogloss:1.77365\n",
      "[124]\ttrain-mlogloss:0.28653\teval-mlogloss:1.77295\n",
      "[125]\ttrain-mlogloss:0.28271\teval-mlogloss:1.77115\n",
      "[126]\ttrain-mlogloss:0.27907\teval-mlogloss:1.76937\n",
      "[127]\ttrain-mlogloss:0.27566\teval-mlogloss:1.76799\n",
      "[128]\ttrain-mlogloss:0.27218\teval-mlogloss:1.76711\n",
      "[129]\ttrain-mlogloss:0.26915\teval-mlogloss:1.76578\n",
      "[130]\ttrain-mlogloss:0.26570\teval-mlogloss:1.76372\n",
      "[131]\ttrain-mlogloss:0.26213\teval-mlogloss:1.76199\n",
      "[132]\ttrain-mlogloss:0.25914\teval-mlogloss:1.76020\n",
      "[133]\ttrain-mlogloss:0.25607\teval-mlogloss:1.75849\n",
      "[134]\ttrain-mlogloss:0.25295\teval-mlogloss:1.75752\n",
      "[135]\ttrain-mlogloss:0.24975\teval-mlogloss:1.75635\n",
      "[136]\ttrain-mlogloss:0.24686\teval-mlogloss:1.75484\n",
      "[137]\ttrain-mlogloss:0.24379\teval-mlogloss:1.75343\n",
      "[138]\ttrain-mlogloss:0.24072\teval-mlogloss:1.75202\n",
      "[139]\ttrain-mlogloss:0.23798\teval-mlogloss:1.75160\n",
      "[140]\ttrain-mlogloss:0.23494\teval-mlogloss:1.75098\n",
      "[141]\ttrain-mlogloss:0.23224\teval-mlogloss:1.75036\n",
      "[142]\ttrain-mlogloss:0.22910\teval-mlogloss:1.74919\n",
      "[143]\ttrain-mlogloss:0.22609\teval-mlogloss:1.74805\n",
      "[144]\ttrain-mlogloss:0.22337\teval-mlogloss:1.74659\n",
      "[145]\ttrain-mlogloss:0.22054\teval-mlogloss:1.74589\n",
      "[146]\ttrain-mlogloss:0.21781\teval-mlogloss:1.74495\n",
      "[147]\ttrain-mlogloss:0.21507\teval-mlogloss:1.74388\n",
      "[148]\ttrain-mlogloss:0.21272\teval-mlogloss:1.74264\n",
      "[149]\ttrain-mlogloss:0.21005\teval-mlogloss:1.74176\n",
      "[150]\ttrain-mlogloss:0.20746\teval-mlogloss:1.74041\n",
      "[151]\ttrain-mlogloss:0.20495\teval-mlogloss:1.73935\n",
      "[152]\ttrain-mlogloss:0.20247\teval-mlogloss:1.73863\n",
      "[153]\ttrain-mlogloss:0.20016\teval-mlogloss:1.73806\n",
      "[154]\ttrain-mlogloss:0.19784\teval-mlogloss:1.73671\n",
      "[155]\ttrain-mlogloss:0.19569\teval-mlogloss:1.73635\n",
      "[156]\ttrain-mlogloss:0.19346\teval-mlogloss:1.73585\n",
      "[157]\ttrain-mlogloss:0.19116\teval-mlogloss:1.73480\n",
      "[158]\ttrain-mlogloss:0.18886\teval-mlogloss:1.73422\n",
      "[159]\ttrain-mlogloss:0.18667\teval-mlogloss:1.73382\n",
      "[160]\ttrain-mlogloss:0.18459\teval-mlogloss:1.73297\n",
      "[161]\ttrain-mlogloss:0.18255\teval-mlogloss:1.73181\n",
      "[162]\ttrain-mlogloss:0.18050\teval-mlogloss:1.73059\n",
      "[163]\ttrain-mlogloss:0.17827\teval-mlogloss:1.72948\n",
      "[164]\ttrain-mlogloss:0.17637\teval-mlogloss:1.72898\n",
      "[165]\ttrain-mlogloss:0.17417\teval-mlogloss:1.72802\n",
      "[166]\ttrain-mlogloss:0.17215\teval-mlogloss:1.72724\n",
      "[167]\ttrain-mlogloss:0.17013\teval-mlogloss:1.72671\n",
      "[168]\ttrain-mlogloss:0.16834\teval-mlogloss:1.72638\n",
      "[169]\ttrain-mlogloss:0.16645\teval-mlogloss:1.72581\n",
      "[170]\ttrain-mlogloss:0.16446\teval-mlogloss:1.72477\n",
      "[171]\ttrain-mlogloss:0.16227\teval-mlogloss:1.72409\n",
      "[172]\ttrain-mlogloss:0.16059\teval-mlogloss:1.72321\n",
      "[173]\ttrain-mlogloss:0.15871\teval-mlogloss:1.72244\n",
      "[174]\ttrain-mlogloss:0.15680\teval-mlogloss:1.72133\n",
      "[175]\ttrain-mlogloss:0.15515\teval-mlogloss:1.72051\n",
      "[176]\ttrain-mlogloss:0.15312\teval-mlogloss:1.71968\n",
      "[177]\ttrain-mlogloss:0.15136\teval-mlogloss:1.71837\n",
      "[178]\ttrain-mlogloss:0.14949\teval-mlogloss:1.71743\n",
      "[179]\ttrain-mlogloss:0.14778\teval-mlogloss:1.71683\n",
      "[180]\ttrain-mlogloss:0.14598\teval-mlogloss:1.71632\n",
      "[181]\ttrain-mlogloss:0.14430\teval-mlogloss:1.71584\n",
      "[182]\ttrain-mlogloss:0.14280\teval-mlogloss:1.71525\n",
      "[183]\ttrain-mlogloss:0.14124\teval-mlogloss:1.71473\n",
      "[184]\ttrain-mlogloss:0.13950\teval-mlogloss:1.71380\n",
      "[185]\ttrain-mlogloss:0.13797\teval-mlogloss:1.71323\n",
      "[186]\ttrain-mlogloss:0.13646\teval-mlogloss:1.71263\n",
      "[187]\ttrain-mlogloss:0.13493\teval-mlogloss:1.71235\n",
      "[188]\ttrain-mlogloss:0.13348\teval-mlogloss:1.71181\n",
      "[189]\ttrain-mlogloss:0.13207\teval-mlogloss:1.71182\n",
      "[190]\ttrain-mlogloss:0.13065\teval-mlogloss:1.71081\n",
      "[191]\ttrain-mlogloss:0.12923\teval-mlogloss:1.71087\n",
      "[192]\ttrain-mlogloss:0.12799\teval-mlogloss:1.70984\n",
      "[193]\ttrain-mlogloss:0.12664\teval-mlogloss:1.70953\n",
      "[194]\ttrain-mlogloss:0.12513\teval-mlogloss:1.70913\n",
      "[195]\ttrain-mlogloss:0.12373\teval-mlogloss:1.70848\n",
      "[196]\ttrain-mlogloss:0.12230\teval-mlogloss:1.70757\n",
      "[197]\ttrain-mlogloss:0.12102\teval-mlogloss:1.70723\n",
      "[198]\ttrain-mlogloss:0.11958\teval-mlogloss:1.70675\n",
      "[199]\ttrain-mlogloss:0.11832\teval-mlogloss:1.70617\n",
      "[200]\ttrain-mlogloss:0.11710\teval-mlogloss:1.70534\n",
      "[201]\ttrain-mlogloss:0.11574\teval-mlogloss:1.70450\n",
      "[202]\ttrain-mlogloss:0.11453\teval-mlogloss:1.70394\n",
      "[203]\ttrain-mlogloss:0.11342\teval-mlogloss:1.70340\n",
      "[204]\ttrain-mlogloss:0.11217\teval-mlogloss:1.70283\n",
      "[205]\ttrain-mlogloss:0.11096\teval-mlogloss:1.70220\n",
      "[206]\ttrain-mlogloss:0.10983\teval-mlogloss:1.70148\n",
      "[207]\ttrain-mlogloss:0.10855\teval-mlogloss:1.70080\n",
      "[208]\ttrain-mlogloss:0.10747\teval-mlogloss:1.70054\n",
      "[209]\ttrain-mlogloss:0.10634\teval-mlogloss:1.69982\n",
      "[210]\ttrain-mlogloss:0.10515\teval-mlogloss:1.69940\n",
      "[211]\ttrain-mlogloss:0.10402\teval-mlogloss:1.69912\n",
      "[212]\ttrain-mlogloss:0.10290\teval-mlogloss:1.69886\n",
      "[213]\ttrain-mlogloss:0.10181\teval-mlogloss:1.69756\n",
      "[214]\ttrain-mlogloss:0.10072\teval-mlogloss:1.69732\n",
      "[215]\ttrain-mlogloss:0.09975\teval-mlogloss:1.69728\n",
      "[216]\ttrain-mlogloss:0.09874\teval-mlogloss:1.69697\n",
      "[217]\ttrain-mlogloss:0.09768\teval-mlogloss:1.69596\n",
      "[218]\ttrain-mlogloss:0.09656\teval-mlogloss:1.69535\n",
      "[219]\ttrain-mlogloss:0.09556\teval-mlogloss:1.69450\n",
      "[220]\ttrain-mlogloss:0.09456\teval-mlogloss:1.69442\n",
      "[221]\ttrain-mlogloss:0.09367\teval-mlogloss:1.69378\n",
      "[222]\ttrain-mlogloss:0.09273\teval-mlogloss:1.69365\n",
      "[223]\ttrain-mlogloss:0.09174\teval-mlogloss:1.69300\n",
      "[224]\ttrain-mlogloss:0.09083\teval-mlogloss:1.69291\n",
      "[225]\ttrain-mlogloss:0.08987\teval-mlogloss:1.69264\n",
      "[226]\ttrain-mlogloss:0.08894\teval-mlogloss:1.69237\n",
      "[227]\ttrain-mlogloss:0.08794\teval-mlogloss:1.69201\n",
      "[228]\ttrain-mlogloss:0.08711\teval-mlogloss:1.69130\n",
      "[229]\ttrain-mlogloss:0.08625\teval-mlogloss:1.69061\n",
      "[230]\ttrain-mlogloss:0.08543\teval-mlogloss:1.69035\n",
      "[231]\ttrain-mlogloss:0.08464\teval-mlogloss:1.69024\n",
      "[232]\ttrain-mlogloss:0.08375\teval-mlogloss:1.69022\n",
      "[233]\ttrain-mlogloss:0.08293\teval-mlogloss:1.69023\n",
      "[234]\ttrain-mlogloss:0.08196\teval-mlogloss:1.68957\n",
      "[235]\ttrain-mlogloss:0.08122\teval-mlogloss:1.68934\n",
      "[236]\ttrain-mlogloss:0.08046\teval-mlogloss:1.68850\n",
      "[237]\ttrain-mlogloss:0.07972\teval-mlogloss:1.68842\n",
      "[238]\ttrain-mlogloss:0.07894\teval-mlogloss:1.68822\n",
      "[239]\ttrain-mlogloss:0.07814\teval-mlogloss:1.68803\n",
      "[240]\ttrain-mlogloss:0.07736\teval-mlogloss:1.68785\n",
      "[241]\ttrain-mlogloss:0.07657\teval-mlogloss:1.68788\n",
      "[242]\ttrain-mlogloss:0.07584\teval-mlogloss:1.68829\n",
      "[243]\ttrain-mlogloss:0.07511\teval-mlogloss:1.68800\n",
      "[244]\ttrain-mlogloss:0.07438\teval-mlogloss:1.68750\n",
      "[245]\ttrain-mlogloss:0.07368\teval-mlogloss:1.68712\n",
      "[246]\ttrain-mlogloss:0.07305\teval-mlogloss:1.68659\n",
      "[247]\ttrain-mlogloss:0.07233\teval-mlogloss:1.68653\n",
      "[248]\ttrain-mlogloss:0.07166\teval-mlogloss:1.68653\n",
      "[249]\ttrain-mlogloss:0.07093\teval-mlogloss:1.68614\n",
      "[250]\ttrain-mlogloss:0.07027\teval-mlogloss:1.68607\n",
      "[251]\ttrain-mlogloss:0.06963\teval-mlogloss:1.68604\n",
      "[252]\ttrain-mlogloss:0.06902\teval-mlogloss:1.68585\n",
      "[253]\ttrain-mlogloss:0.06836\teval-mlogloss:1.68547\n",
      "[254]\ttrain-mlogloss:0.06775\teval-mlogloss:1.68500\n",
      "[255]\ttrain-mlogloss:0.06708\teval-mlogloss:1.68462\n",
      "[256]\ttrain-mlogloss:0.06647\teval-mlogloss:1.68453\n",
      "[257]\ttrain-mlogloss:0.06581\teval-mlogloss:1.68438\n",
      "[258]\ttrain-mlogloss:0.06522\teval-mlogloss:1.68447\n",
      "[259]\ttrain-mlogloss:0.06461\teval-mlogloss:1.68403\n",
      "[260]\ttrain-mlogloss:0.06401\teval-mlogloss:1.68399\n",
      "[261]\ttrain-mlogloss:0.06344\teval-mlogloss:1.68402\n",
      "[262]\ttrain-mlogloss:0.06288\teval-mlogloss:1.68372\n",
      "[263]\ttrain-mlogloss:0.06225\teval-mlogloss:1.68400\n",
      "[264]\ttrain-mlogloss:0.06170\teval-mlogloss:1.68368\n",
      "[265]\ttrain-mlogloss:0.06115\teval-mlogloss:1.68326\n",
      "[266]\ttrain-mlogloss:0.06064\teval-mlogloss:1.68322\n",
      "[267]\ttrain-mlogloss:0.06012\teval-mlogloss:1.68271\n",
      "[268]\ttrain-mlogloss:0.05956\teval-mlogloss:1.68232\n",
      "[269]\ttrain-mlogloss:0.05900\teval-mlogloss:1.68222\n",
      "[270]\ttrain-mlogloss:0.05849\teval-mlogloss:1.68193\n",
      "[271]\ttrain-mlogloss:0.05799\teval-mlogloss:1.68139\n",
      "[272]\ttrain-mlogloss:0.05747\teval-mlogloss:1.68106\n",
      "[273]\ttrain-mlogloss:0.05691\teval-mlogloss:1.68133\n",
      "[274]\ttrain-mlogloss:0.05645\teval-mlogloss:1.68117\n",
      "[275]\ttrain-mlogloss:0.05599\teval-mlogloss:1.68129\n",
      "[276]\ttrain-mlogloss:0.05550\teval-mlogloss:1.68134\n",
      "[277]\ttrain-mlogloss:0.05503\teval-mlogloss:1.68115\n",
      "[278]\ttrain-mlogloss:0.05449\teval-mlogloss:1.68077\n",
      "[279]\ttrain-mlogloss:0.05400\teval-mlogloss:1.68052\n",
      "[280]\ttrain-mlogloss:0.05355\teval-mlogloss:1.68053\n",
      "[281]\ttrain-mlogloss:0.05303\teval-mlogloss:1.68072\n",
      "[282]\ttrain-mlogloss:0.05258\teval-mlogloss:1.68090\n",
      "[283]\ttrain-mlogloss:0.05215\teval-mlogloss:1.68087\n",
      "[284]\ttrain-mlogloss:0.05174\teval-mlogloss:1.68084\n",
      "[285]\ttrain-mlogloss:0.05134\teval-mlogloss:1.68102\n",
      "[286]\ttrain-mlogloss:0.05090\teval-mlogloss:1.68045\n",
      "[287]\ttrain-mlogloss:0.05049\teval-mlogloss:1.68038\n",
      "[288]\ttrain-mlogloss:0.05005\teval-mlogloss:1.68002\n",
      "[289]\ttrain-mlogloss:0.04964\teval-mlogloss:1.68008\n",
      "[290]\ttrain-mlogloss:0.04922\teval-mlogloss:1.68022\n",
      "[291]\ttrain-mlogloss:0.04885\teval-mlogloss:1.67973\n",
      "[292]\ttrain-mlogloss:0.04843\teval-mlogloss:1.67999\n",
      "[293]\ttrain-mlogloss:0.04804\teval-mlogloss:1.68002\n",
      "[294]\ttrain-mlogloss:0.04764\teval-mlogloss:1.67985\n",
      "[295]\ttrain-mlogloss:0.04726\teval-mlogloss:1.67968\n",
      "[296]\ttrain-mlogloss:0.04685\teval-mlogloss:1.67966\n",
      "[297]\ttrain-mlogloss:0.04648\teval-mlogloss:1.67940\n",
      "[298]\ttrain-mlogloss:0.04614\teval-mlogloss:1.67917\n",
      "[299]\ttrain-mlogloss:0.04578\teval-mlogloss:1.67901\n",
      "[300]\ttrain-mlogloss:0.04540\teval-mlogloss:1.67895\n",
      "[301]\ttrain-mlogloss:0.04502\teval-mlogloss:1.67886\n",
      "[302]\ttrain-mlogloss:0.04465\teval-mlogloss:1.67877\n",
      "[303]\ttrain-mlogloss:0.04430\teval-mlogloss:1.67886\n",
      "[304]\ttrain-mlogloss:0.04397\teval-mlogloss:1.67879\n",
      "[305]\ttrain-mlogloss:0.04363\teval-mlogloss:1.67903\n",
      "[306]\ttrain-mlogloss:0.04329\teval-mlogloss:1.67937\n",
      "[307]\ttrain-mlogloss:0.04295\teval-mlogloss:1.67955\n",
      "[308]\ttrain-mlogloss:0.04263\teval-mlogloss:1.67944\n",
      "[309]\ttrain-mlogloss:0.04232\teval-mlogloss:1.67929\n",
      "[310]\ttrain-mlogloss:0.04198\teval-mlogloss:1.67945\n",
      "[311]\ttrain-mlogloss:0.04168\teval-mlogloss:1.67933\n",
      "[312]\ttrain-mlogloss:0.04136\teval-mlogloss:1.67914\n",
      "[313]\ttrain-mlogloss:0.04105\teval-mlogloss:1.67872\n",
      "[314]\ttrain-mlogloss:0.04075\teval-mlogloss:1.67862\n",
      "[315]\ttrain-mlogloss:0.04046\teval-mlogloss:1.67849\n",
      "[316]\ttrain-mlogloss:0.04017\teval-mlogloss:1.67849\n",
      "[317]\ttrain-mlogloss:0.03987\teval-mlogloss:1.67869\n",
      "[318]\ttrain-mlogloss:0.03960\teval-mlogloss:1.67858\n",
      "[319]\ttrain-mlogloss:0.03928\teval-mlogloss:1.67856\n",
      "[320]\ttrain-mlogloss:0.03900\teval-mlogloss:1.67808\n",
      "[321]\ttrain-mlogloss:0.03871\teval-mlogloss:1.67799\n",
      "[322]\ttrain-mlogloss:0.03844\teval-mlogloss:1.67754\n",
      "[323]\ttrain-mlogloss:0.03817\teval-mlogloss:1.67745\n",
      "[324]\ttrain-mlogloss:0.03788\teval-mlogloss:1.67757\n",
      "[325]\ttrain-mlogloss:0.03760\teval-mlogloss:1.67777\n",
      "[326]\ttrain-mlogloss:0.03730\teval-mlogloss:1.67767\n",
      "[327]\ttrain-mlogloss:0.03704\teval-mlogloss:1.67773\n",
      "[328]\ttrain-mlogloss:0.03678\teval-mlogloss:1.67832\n",
      "[329]\ttrain-mlogloss:0.03652\teval-mlogloss:1.67815\n",
      "[330]\ttrain-mlogloss:0.03624\teval-mlogloss:1.67760\n",
      "[331]\ttrain-mlogloss:0.03600\teval-mlogloss:1.67745\n",
      "[332]\ttrain-mlogloss:0.03574\teval-mlogloss:1.67683\n",
      "[333]\ttrain-mlogloss:0.03551\teval-mlogloss:1.67655\n",
      "[334]\ttrain-mlogloss:0.03526\teval-mlogloss:1.67685\n",
      "[335]\ttrain-mlogloss:0.03501\teval-mlogloss:1.67663\n",
      "[336]\ttrain-mlogloss:0.03478\teval-mlogloss:1.67629\n",
      "[337]\ttrain-mlogloss:0.03455\teval-mlogloss:1.67652\n",
      "[338]\ttrain-mlogloss:0.03430\teval-mlogloss:1.67627\n",
      "[339]\ttrain-mlogloss:0.03403\teval-mlogloss:1.67652\n",
      "[340]\ttrain-mlogloss:0.03380\teval-mlogloss:1.67690\n",
      "[341]\ttrain-mlogloss:0.03357\teval-mlogloss:1.67755\n",
      "[342]\ttrain-mlogloss:0.03334\teval-mlogloss:1.67748\n",
      "[343]\ttrain-mlogloss:0.03312\teval-mlogloss:1.67727\n",
      "[344]\ttrain-mlogloss:0.03290\teval-mlogloss:1.67720\n",
      "[345]\ttrain-mlogloss:0.03267\teval-mlogloss:1.67717\n",
      "[346]\ttrain-mlogloss:0.03243\teval-mlogloss:1.67709\n",
      "[347]\ttrain-mlogloss:0.03223\teval-mlogloss:1.67715\n",
      "[348]\ttrain-mlogloss:0.03200\teval-mlogloss:1.67725\n",
      "[349]\ttrain-mlogloss:0.03177\teval-mlogloss:1.67722\n",
      "[350]\ttrain-mlogloss:0.03155\teval-mlogloss:1.67685\n",
      "[351]\ttrain-mlogloss:0.03131\teval-mlogloss:1.67631\n",
      "[352]\ttrain-mlogloss:0.03111\teval-mlogloss:1.67622\n",
      "[353]\ttrain-mlogloss:0.03093\teval-mlogloss:1.67633\n",
      "[354]\ttrain-mlogloss:0.03073\teval-mlogloss:1.67623\n",
      "[355]\ttrain-mlogloss:0.03052\teval-mlogloss:1.67581\n",
      "[356]\ttrain-mlogloss:0.03032\teval-mlogloss:1.67583\n",
      "[357]\ttrain-mlogloss:0.03013\teval-mlogloss:1.67603\n",
      "[358]\ttrain-mlogloss:0.02993\teval-mlogloss:1.67603\n",
      "[359]\ttrain-mlogloss:0.02974\teval-mlogloss:1.67617\n",
      "[360]\ttrain-mlogloss:0.02955\teval-mlogloss:1.67608\n",
      "[361]\ttrain-mlogloss:0.02936\teval-mlogloss:1.67584\n",
      "[362]\ttrain-mlogloss:0.02918\teval-mlogloss:1.67610\n",
      "[363]\ttrain-mlogloss:0.02900\teval-mlogloss:1.67624\n",
      "[364]\ttrain-mlogloss:0.02881\teval-mlogloss:1.67609\n",
      "[365]\ttrain-mlogloss:0.02865\teval-mlogloss:1.67625\n",
      "[366]\ttrain-mlogloss:0.02846\teval-mlogloss:1.67640\n",
      "[367]\ttrain-mlogloss:0.02829\teval-mlogloss:1.67636\n",
      "[368]\ttrain-mlogloss:0.02813\teval-mlogloss:1.67605\n",
      "[369]\ttrain-mlogloss:0.02794\teval-mlogloss:1.67614\n",
      "[370]\ttrain-mlogloss:0.02776\teval-mlogloss:1.67635\n",
      "[371]\ttrain-mlogloss:0.02761\teval-mlogloss:1.67636\n",
      "[372]\ttrain-mlogloss:0.02746\teval-mlogloss:1.67650\n",
      "[373]\ttrain-mlogloss:0.02730\teval-mlogloss:1.67687\n",
      "[374]\ttrain-mlogloss:0.02713\teval-mlogloss:1.67724\n",
      "[375]\ttrain-mlogloss:0.02697\teval-mlogloss:1.67716\n",
      "[376]\ttrain-mlogloss:0.02682\teval-mlogloss:1.67739\n",
      "[377]\ttrain-mlogloss:0.02667\teval-mlogloss:1.67713\n",
      "[378]\ttrain-mlogloss:0.02650\teval-mlogloss:1.67712\n",
      "[379]\ttrain-mlogloss:0.02634\teval-mlogloss:1.67738\n",
      "Model saved to 2024-II/Aprendizaje/Tarea4/xgboost_model.json\n",
      "Accuracy: 0.44\n",
      "Confusion Matrix:\n",
      "[[ 35   8   1   2   9   4  20  15   4   5   2   3   0   4   4]\n",
      " [  8 168   3  34   0   0   1   2   7   0  32   1   0   3   1]\n",
      " [  0   0 182   0   3   0   0   0  20   0  11   5   1   5   1]\n",
      " [  7  23   1  70   8   5   0   1   5   0  21   2   7   7   3]\n",
      " [ 16   6   0   9  48  13  19  18  13  10  15  15  16   7   6]\n",
      " [ 11   3   2   3  18  91  12   5   1   9   2  20  13   3  15]\n",
      " [  9   1   0   2   6   7  42  10   0  24   0   4   1   2   2]\n",
      " [ 28   1   1   2  13   4  21  70   3  14   0   5   6  14   7]\n",
      " [ 12  15  25  17  11   0   0   4 102   1  50   7  11  18   1]\n",
      " [ 14   0   0   0   4   9  19  12   0  52   0   3   0   0   2]\n",
      " [  4  54  39  24   7   1   0   4  47   0 113   3   8   2   4]\n",
      " [  5   1  13   1  27  22  14   7   8   7   3  71  16  13   7]\n",
      " [  8   3   3   7  17  17   0   3  12   2  18  30  56   5  11]\n",
      " [  1   0   3   1   4   1   1  10   7   2   5   5   4  94   3]\n",
      " [  6  10   2   4  26  24   7   6   6  10   2   6   6  10 131]]\n"
     ]
    }
   ],
   "source": [
    "train_xgboost(train_histograms, y_train, test_histograms, y_test, 'xgboost_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenar un modelo de Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "\n",
    "def train_random_forest(train_histograms_, y_train_, test_histograms_, y_test_, savename):\n",
    "    # Create and train the Random Forest model\n",
    "    rf = RandomForestClassifier(n_estimators=5000, max_depth=None, random_state=42)\n",
    "    rf.fit(train_histograms_, y_train_)\n",
    "\n",
    "    # Save the model with timestamp\n",
    "    model_path = f\"{curr_dir}{savename}.joblib\"\n",
    "    joblib.dump(rf, model_path)\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "\n",
    "    # Make predictions and evaluate the model\n",
    "    y_pred = rf.predict(test_histograms_)\n",
    "    accuracy = accuracy_score(y_test_, y_pred)\n",
    "\n",
    "    # Calculate and print the confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test_, y_pred)\n",
    "\n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_random_forest_model(model_filename, test_histograms_, y_test_):\n",
    "    # Load the model\n",
    "    rf = joblib.load(model_filename)\n",
    "    print(f\"Model loaded from {model_filename}\")\n",
    "\n",
    "    # Make predictions and evaluate the model\n",
    "    y_pred = rf.predict(test_histograms_)\n",
    "    accuracy = accuracy_score(y_test_, y_pred)\n",
    "    \n",
    "    # Calculate and print the confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test_, y_pred)\n",
    "\n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to 2024-II/Aprendizaje/Tarea4/random_forest_model.joblib\n",
      "Accuracy: 0.45\n",
      "Confusion Matrix:\n",
      "[[ 13  15   7   2   0   2  39  17   1  12   2   0   1   2   3]\n",
      " [  2 220   9  14   0   0   0   1   2   0  10   0   0   2   0]\n",
      " [  0   2 220   0   0   0   0   0   3   0   1   0   0   2   0]\n",
      " [  3  54   8  73   0   2   3   2   0   1   5   0   0   6   3]\n",
      " [ 10  31   9   3   6  22  44  14   4  14   6  14   7  21   6]\n",
      " [  3   6   3   3   0 104  34   1   0  18   1  14   5   3  13]\n",
      " [  2   3   0   0   0   5  73   4   0  22   0   1   0   0   0]\n",
      " [ 14   4   0   0   1   5  32  64   1  43   0   4   2  15   4]\n",
      " [  5  43  66  16   0   0   4   1  77   0  32   0   1  29   0]\n",
      " [  2   0   0   0   0   2  30   3   0  78   0   0   0   0   0]\n",
      " [  0  85  88  24   0   0   2   2  16   0  81   0   0  11   1]\n",
      " [  2   3  41   2   1  23  29   5   0  17   3  62   1  20   6]\n",
      " [  0   9  15  11   4  23  20   3   8   7  20  13  29  13  17]\n",
      " [  0   0   7   2   0   2   1   2   1   8   0   0   0 117   1]\n",
      " [  1  28   7   6   0  21  15   3   1  16   0   3   4  16 135]]\n"
     ]
    }
   ],
   "source": [
    "train_random_forest(train_histograms, y_train, test_histograms, y_test, savename='random_forest_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenar un modelo de SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "def train_svm(train_histograms_, y_train_, test_histograms_, y_test_, savename):\n",
    "    # Create and train the SVM model\n",
    "    svm = SVC(kernel='rbf', C=3, random_state=42)     # 0.51 accuracy\n",
    "    svm.fit(train_histograms_, y_train_)\n",
    "\n",
    "    # Save the model\n",
    "    model_path = f\"{curr_dir}{savename}.joblib\"\n",
    "    joblib.dump(svm, model_path)\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "\n",
    "    # Make predictions and evaluate the model\n",
    "    y_pred = svm.predict(test_histograms_)\n",
    "    accuracy = accuracy_score(y_test_, y_pred)\n",
    "\n",
    "    # Calculate and print the confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test_, y_pred)\n",
    "\n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_svm_model(model_filename, test_histograms_, y_test_):\n",
    "    # Load the model\n",
    "    svm = joblib.load(model_filename)\n",
    "    print(f\"Model loaded from {model_filename}\")\n",
    "\n",
    "    # Make predictions and evaluate the model\n",
    "    y_pred = svm.predict(test_histograms_)\n",
    "    accuracy = accuracy_score(y_test_, y_pred)\n",
    "    \n",
    "    # Calculate and print the confusion matrix\n",
    "    conf_matrix = confusion_matrix(y_test_, y_pred)\n",
    "\n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "    print('Confusion Matrix:')\n",
    "    print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to 2024-II/Aprendizaje/Tarea4/svm_model.joblib\n",
      "Accuracy: 0.51\n",
      "Confusion Matrix:\n",
      "[[ 37   6   0   5   5   3  22  14   6   3   1   3   3   4   4]\n",
      " [  4 182   6  28   1   0   1   0  11   0  26   0   0   0   1]\n",
      " [  0   0 190   0   0   0   0   0  13   0  19   1   1   4   0]\n",
      " [  6  24   2  90   4   3   1   2   1   0   8   1   9   6   3]\n",
      " [ 19   6   2   8  45  16  13  26   9   8   7  14  24   7   7]\n",
      " [  9   3   0   2  13 105  13   4   2   5   2  25  11   4  10]\n",
      " [ 12   2   0   0   6   7  54   9   0  18   0   1   1   0   0]\n",
      " [ 36   1   0   1   4   3  13  78   2  22   0  10   5  11   3]\n",
      " [ 11  21  19  13   3   0   0   3 125   1  43   3   9  22   1]\n",
      " [  7   0   0   0   1   4  27   7   0  66   0   2   1   0   0]\n",
      " [  2  53  39  27   0   0   0   0  48   0 125   1   6   8   1]\n",
      " [ 10   1   6   2  13  15  10  10   5   9   4 106   8   9   7]\n",
      " [  6   1   3   5  17  15   2   5  18   5  13  17  75   5   5]\n",
      " [  0   0   3   2   2   3   0   6   6   2   0   4   1 111   1]\n",
      " [  5   6   1   5  14  28  10  12   4   6   1  13  13   9 129]]\n"
     ]
    }
   ],
   "source": [
    "train_svm(train_histograms, y_train, test_histograms, y_test, savename='svm_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenar modelos reduciendo las dimensiones de los vectores de características"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilzar un autoencoder para reducir la dimensionalidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 843ms/step - loss: 0.2963 - val_loss: 0.1568\n",
      "Epoch 2/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 358ms/step - loss: 0.1725 - val_loss: 0.1568\n",
      "Epoch 3/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 354ms/step - loss: 0.1611 - val_loss: 0.1566\n",
      "Epoch 4/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 357ms/step - loss: 0.1646 - val_loss: 0.1564\n",
      "Epoch 5/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 355ms/step - loss: 0.1668 - val_loss: 0.1563\n",
      "Epoch 6/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 349ms/step - loss: 0.1646 - val_loss: 0.1560\n",
      "Epoch 7/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 355ms/step - loss: 0.1588 - val_loss: 0.1558\n",
      "Epoch 8/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 354ms/step - loss: 0.1675 - val_loss: 0.1556\n",
      "Epoch 9/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 358ms/step - loss: 0.1720 - val_loss: 0.1555\n",
      "Epoch 10/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 348ms/step - loss: 0.1698 - val_loss: 0.1553\n",
      "Epoch 11/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 358ms/step - loss: 0.1744 - val_loss: 0.1552\n",
      "Epoch 12/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 356ms/step - loss: 0.1722 - val_loss: 0.1551\n",
      "Epoch 13/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 365ms/step - loss: 0.1663 - val_loss: 0.1550\n",
      "Epoch 14/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 359ms/step - loss: 0.1663 - val_loss: 0.1549\n",
      "Epoch 15/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 350ms/step - loss: 0.1601 - val_loss: 0.1548\n",
      "Epoch 16/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 355ms/step - loss: 0.1722 - val_loss: 0.1548\n",
      "Epoch 17/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 359ms/step - loss: 0.1548 - val_loss: 0.1547\n",
      "Epoch 18/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 354ms/step - loss: 0.1605 - val_loss: 0.1546\n",
      "Epoch 19/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 355ms/step - loss: 0.1607 - val_loss: 0.1545\n",
      "Epoch 20/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 357ms/step - loss: 0.1728 - val_loss: 0.1544\n",
      "Epoch 21/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 351ms/step - loss: 0.1542 - val_loss: 0.1544\n",
      "Epoch 22/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 364ms/step - loss: 0.1536 - val_loss: 0.1543\n",
      "Epoch 23/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 347ms/step - loss: 0.1655 - val_loss: 0.1542\n",
      "Epoch 24/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 351ms/step - loss: 0.1670 - val_loss: 0.1541\n",
      "Epoch 25/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 350ms/step - loss: 0.1554 - val_loss: 0.1541\n",
      "Epoch 26/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 352ms/step - loss: 0.1685 - val_loss: 0.1540\n",
      "Epoch 27/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 358ms/step - loss: 0.1644 - val_loss: 0.1540\n",
      "Epoch 28/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 359ms/step - loss: 0.1731 - val_loss: 0.1539\n",
      "Epoch 29/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 360ms/step - loss: 0.1691 - val_loss: 0.1538\n",
      "Epoch 30/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 362ms/step - loss: 0.1632 - val_loss: 0.1537\n",
      "Epoch 31/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 353ms/step - loss: 0.1612 - val_loss: 0.1537\n",
      "Epoch 32/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 335ms/step - loss: 0.1683 - val_loss: 0.1536\n",
      "Epoch 33/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 350ms/step - loss: 0.1558 - val_loss: 0.1536\n",
      "Epoch 34/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 363ms/step - loss: 0.1648 - val_loss: 0.1535\n",
      "Epoch 35/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 350ms/step - loss: 0.1586 - val_loss: 0.1535\n",
      "Epoch 36/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 346ms/step - loss: 0.1654 - val_loss: 0.1534\n",
      "Epoch 37/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 352ms/step - loss: 0.1569 - val_loss: 0.1533\n",
      "Epoch 38/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 344ms/step - loss: 0.1628 - val_loss: 0.1533\n",
      "Epoch 39/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 361ms/step - loss: 0.1602 - val_loss: 0.1532\n",
      "Epoch 40/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 361ms/step - loss: 0.1580 - val_loss: 0.1532\n",
      "Epoch 41/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 352ms/step - loss: 0.1661 - val_loss: 0.1531\n",
      "Epoch 42/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 358ms/step - loss: 0.1594 - val_loss: 0.1531\n",
      "Epoch 43/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 366ms/step - loss: 0.1543 - val_loss: 0.1530\n",
      "Epoch 44/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 368ms/step - loss: 0.1541 - val_loss: 0.1530\n",
      "Epoch 45/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 349ms/step - loss: 0.1522 - val_loss: 0.1529\n",
      "Epoch 46/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 352ms/step - loss: 0.1672 - val_loss: 0.1529\n",
      "Epoch 47/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 353ms/step - loss: 0.1552 - val_loss: 0.1528\n",
      "Epoch 48/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 365ms/step - loss: 0.1591 - val_loss: 0.1528\n",
      "Epoch 49/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 347ms/step - loss: 0.1620 - val_loss: 0.1527\n",
      "Epoch 50/50\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 357ms/step - loss: 0.1642 - val_loss: 0.1527\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step\n",
      "Original shape: (1500, 10000)\n",
      "Reduced shape: (1500, 1000)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Define the autoencoder model\n",
    "input_dim = train_histograms.shape[1]\n",
    "encoding_dim = 1000\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoder = Dense(encoding_dim, activation=\"relu\")(input_layer)\n",
    "decoder = Dense(input_dim, activation=\"sigmoid\")(encoder)\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "\n",
    "# Compile and train the autoencoder\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "autoencoder.fit(train_histograms, train_histograms, epochs=50, batch_size=256, shuffle=True, validation_data=(test_histograms, test_histograms))\n",
    "\n",
    "# Use the encoder to reduce the dimensionality\n",
    "encoder_model = Model(inputs=input_layer, outputs=encoder)\n",
    "train_histograms_encoded = encoder_model.predict(train_histograms)\n",
    "test_histograms_encoded = encoder_model.predict(test_histograms)\n",
    "\n",
    "print(\"Original shape:\", train_histograms.shape)\n",
    "print(\"Reduced shape:\", train_histograms_encoded.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizar el PCA para reducción de dimensionalidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components to explain 95% variance: 1087\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Fit PCA\n",
    "pca = PCA().fit(train_histograms)\n",
    "\n",
    "# Plot the cumulative variance explained\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "n_components = np.argmax(cumulative_variance >= 0.95) + 1\n",
    "\n",
    "print(f'Number of components to explain 95% variance: {n_components}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (1500, 10000)\n",
      "Reduced shape: (1500, 1087)\n"
     ]
    }
   ],
   "source": [
    "# Apply PCA to reduce dimensionality to 50 components\n",
    "pca = PCA(n_components=n_components)\n",
    "train_histograms_pca = pca.fit_transform(train_histograms)\n",
    "test_histograms_pca = pca.transform(test_histograms)\n",
    "\n",
    "print(\"Original shape:\", train_histograms.shape)\n",
    "print(\"Reduced shape:\", train_histograms_pca.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenar los modelos con los vectores reducidos por el autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.56611\teval-mlogloss:2.64579\n",
      "[1]\ttrain-mlogloss:2.44683\teval-mlogloss:2.59118\n",
      "[2]\ttrain-mlogloss:2.34196\teval-mlogloss:2.54653\n",
      "[3]\ttrain-mlogloss:2.24743\teval-mlogloss:2.50367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leon/.local/lib/python3.10/site-packages/xgboost/core.py:727: FutureWarning: Pass `evals` as keyword args.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4]\ttrain-mlogloss:2.16003\teval-mlogloss:2.46670\n",
      "[5]\ttrain-mlogloss:2.08103\teval-mlogloss:2.43300\n",
      "[6]\ttrain-mlogloss:2.00808\teval-mlogloss:2.39947\n",
      "[7]\ttrain-mlogloss:1.94218\teval-mlogloss:2.37002\n",
      "[8]\ttrain-mlogloss:1.87485\teval-mlogloss:2.34312\n",
      "[9]\ttrain-mlogloss:1.81488\teval-mlogloss:2.31742\n",
      "[10]\ttrain-mlogloss:1.75747\teval-mlogloss:2.29325\n",
      "[11]\ttrain-mlogloss:1.70206\teval-mlogloss:2.27085\n",
      "[12]\ttrain-mlogloss:1.64939\teval-mlogloss:2.24892\n",
      "[13]\ttrain-mlogloss:1.59952\teval-mlogloss:2.22799\n",
      "[14]\ttrain-mlogloss:1.55116\teval-mlogloss:2.20922\n",
      "[15]\ttrain-mlogloss:1.50696\teval-mlogloss:2.19264\n",
      "[16]\ttrain-mlogloss:1.46252\teval-mlogloss:2.17448\n",
      "[17]\ttrain-mlogloss:1.42191\teval-mlogloss:2.15701\n",
      "[18]\ttrain-mlogloss:1.38352\teval-mlogloss:2.14113\n",
      "[19]\ttrain-mlogloss:1.34672\teval-mlogloss:2.12576\n",
      "[20]\ttrain-mlogloss:1.31046\teval-mlogloss:2.11327\n",
      "[21]\ttrain-mlogloss:1.27639\teval-mlogloss:2.09946\n",
      "[22]\ttrain-mlogloss:1.24215\teval-mlogloss:2.08556\n",
      "[23]\ttrain-mlogloss:1.20924\teval-mlogloss:2.07216\n",
      "[24]\ttrain-mlogloss:1.17584\teval-mlogloss:2.06025\n",
      "[25]\ttrain-mlogloss:1.14520\teval-mlogloss:2.04755\n",
      "[26]\ttrain-mlogloss:1.11727\teval-mlogloss:2.03605\n",
      "[27]\ttrain-mlogloss:1.08995\teval-mlogloss:2.02601\n",
      "[28]\ttrain-mlogloss:1.06202\teval-mlogloss:2.01444\n",
      "[29]\ttrain-mlogloss:1.03679\teval-mlogloss:2.00487\n",
      "[30]\ttrain-mlogloss:1.00977\teval-mlogloss:1.99631\n",
      "[31]\ttrain-mlogloss:0.98554\teval-mlogloss:1.98711\n",
      "[32]\ttrain-mlogloss:0.96258\teval-mlogloss:1.97762\n",
      "[33]\ttrain-mlogloss:0.93963\teval-mlogloss:1.97076\n",
      "[34]\ttrain-mlogloss:0.91687\teval-mlogloss:1.96201\n",
      "[35]\ttrain-mlogloss:0.89555\teval-mlogloss:1.95403\n",
      "[36]\ttrain-mlogloss:0.87421\teval-mlogloss:1.94639\n",
      "[37]\ttrain-mlogloss:0.85515\teval-mlogloss:1.93909\n",
      "[38]\ttrain-mlogloss:0.83486\teval-mlogloss:1.93356\n",
      "[39]\ttrain-mlogloss:0.81503\teval-mlogloss:1.92637\n",
      "[40]\ttrain-mlogloss:0.79636\teval-mlogloss:1.91991\n",
      "[41]\ttrain-mlogloss:0.77843\teval-mlogloss:1.91344\n",
      "[42]\ttrain-mlogloss:0.76042\teval-mlogloss:1.90663\n",
      "[43]\ttrain-mlogloss:0.74254\teval-mlogloss:1.90063\n",
      "[44]\ttrain-mlogloss:0.72600\teval-mlogloss:1.89557\n",
      "[45]\ttrain-mlogloss:0.70963\teval-mlogloss:1.89121\n",
      "[46]\ttrain-mlogloss:0.69341\teval-mlogloss:1.88824\n",
      "[47]\ttrain-mlogloss:0.67754\teval-mlogloss:1.88239\n",
      "[48]\ttrain-mlogloss:0.66216\teval-mlogloss:1.87871\n",
      "[49]\ttrain-mlogloss:0.64737\teval-mlogloss:1.87448\n",
      "[50]\ttrain-mlogloss:0.63362\teval-mlogloss:1.87146\n",
      "[51]\ttrain-mlogloss:0.61853\teval-mlogloss:1.86554\n",
      "[52]\ttrain-mlogloss:0.60490\teval-mlogloss:1.86081\n",
      "[53]\ttrain-mlogloss:0.59177\teval-mlogloss:1.85738\n",
      "[54]\ttrain-mlogloss:0.57885\teval-mlogloss:1.85426\n",
      "[55]\ttrain-mlogloss:0.56709\teval-mlogloss:1.84952\n",
      "[56]\ttrain-mlogloss:0.55423\teval-mlogloss:1.84618\n",
      "[57]\ttrain-mlogloss:0.54229\teval-mlogloss:1.84383\n",
      "[58]\ttrain-mlogloss:0.53102\teval-mlogloss:1.84064\n",
      "[59]\ttrain-mlogloss:0.51972\teval-mlogloss:1.83633\n",
      "[60]\ttrain-mlogloss:0.50804\teval-mlogloss:1.83243\n",
      "[61]\ttrain-mlogloss:0.49647\teval-mlogloss:1.82941\n",
      "[62]\ttrain-mlogloss:0.48612\teval-mlogloss:1.82578\n",
      "[63]\ttrain-mlogloss:0.47642\teval-mlogloss:1.82533\n",
      "[64]\ttrain-mlogloss:0.46687\teval-mlogloss:1.82279\n",
      "[65]\ttrain-mlogloss:0.45691\teval-mlogloss:1.81994\n",
      "[66]\ttrain-mlogloss:0.44799\teval-mlogloss:1.81832\n",
      "[67]\ttrain-mlogloss:0.43842\teval-mlogloss:1.81542\n",
      "[68]\ttrain-mlogloss:0.42980\teval-mlogloss:1.81339\n",
      "[69]\ttrain-mlogloss:0.42082\teval-mlogloss:1.81134\n",
      "[70]\ttrain-mlogloss:0.41285\teval-mlogloss:1.80941\n",
      "[71]\ttrain-mlogloss:0.40429\teval-mlogloss:1.80732\n",
      "[72]\ttrain-mlogloss:0.39669\teval-mlogloss:1.80664\n",
      "[73]\ttrain-mlogloss:0.38843\teval-mlogloss:1.80500\n",
      "[74]\ttrain-mlogloss:0.38070\teval-mlogloss:1.80394\n",
      "[75]\ttrain-mlogloss:0.37208\teval-mlogloss:1.80101\n",
      "[76]\ttrain-mlogloss:0.36434\teval-mlogloss:1.79881\n",
      "[77]\ttrain-mlogloss:0.35651\teval-mlogloss:1.79661\n",
      "[78]\ttrain-mlogloss:0.34985\teval-mlogloss:1.79473\n",
      "[79]\ttrain-mlogloss:0.34301\teval-mlogloss:1.79266\n",
      "[80]\ttrain-mlogloss:0.33583\teval-mlogloss:1.79090\n",
      "[81]\ttrain-mlogloss:0.32888\teval-mlogloss:1.78883\n",
      "[82]\ttrain-mlogloss:0.32265\teval-mlogloss:1.78683\n",
      "[83]\ttrain-mlogloss:0.31604\teval-mlogloss:1.78539\n",
      "[84]\ttrain-mlogloss:0.31002\teval-mlogloss:1.78325\n",
      "[85]\ttrain-mlogloss:0.30398\teval-mlogloss:1.78285\n",
      "[86]\ttrain-mlogloss:0.29768\teval-mlogloss:1.78162\n",
      "[87]\ttrain-mlogloss:0.29184\teval-mlogloss:1.78038\n",
      "[88]\ttrain-mlogloss:0.28549\teval-mlogloss:1.77975\n",
      "[89]\ttrain-mlogloss:0.27874\teval-mlogloss:1.77799\n",
      "[90]\ttrain-mlogloss:0.27323\teval-mlogloss:1.77513\n",
      "[91]\ttrain-mlogloss:0.26774\teval-mlogloss:1.77318\n",
      "[92]\ttrain-mlogloss:0.26212\teval-mlogloss:1.77264\n",
      "[93]\ttrain-mlogloss:0.25702\teval-mlogloss:1.77144\n",
      "[94]\ttrain-mlogloss:0.25192\teval-mlogloss:1.77070\n",
      "[95]\ttrain-mlogloss:0.24724\teval-mlogloss:1.77002\n",
      "[96]\ttrain-mlogloss:0.24241\teval-mlogloss:1.76843\n",
      "[97]\ttrain-mlogloss:0.23772\teval-mlogloss:1.76910\n",
      "[98]\ttrain-mlogloss:0.23281\teval-mlogloss:1.76792\n",
      "[99]\ttrain-mlogloss:0.22837\teval-mlogloss:1.76788\n",
      "[100]\ttrain-mlogloss:0.22355\teval-mlogloss:1.76619\n",
      "[101]\ttrain-mlogloss:0.21892\teval-mlogloss:1.76506\n",
      "[102]\ttrain-mlogloss:0.21481\teval-mlogloss:1.76513\n",
      "[103]\ttrain-mlogloss:0.21038\teval-mlogloss:1.76425\n",
      "[104]\ttrain-mlogloss:0.20587\teval-mlogloss:1.76275\n",
      "[105]\ttrain-mlogloss:0.20222\teval-mlogloss:1.76218\n",
      "[106]\ttrain-mlogloss:0.19790\teval-mlogloss:1.76110\n",
      "[107]\ttrain-mlogloss:0.19375\teval-mlogloss:1.76002\n",
      "[108]\ttrain-mlogloss:0.18976\teval-mlogloss:1.76053\n",
      "[109]\ttrain-mlogloss:0.18592\teval-mlogloss:1.76000\n",
      "[110]\ttrain-mlogloss:0.18213\teval-mlogloss:1.75998\n",
      "[111]\ttrain-mlogloss:0.17861\teval-mlogloss:1.75916\n",
      "[112]\ttrain-mlogloss:0.17496\teval-mlogloss:1.75797\n",
      "[113]\ttrain-mlogloss:0.17158\teval-mlogloss:1.75589\n",
      "[114]\ttrain-mlogloss:0.16812\teval-mlogloss:1.75490\n",
      "[115]\ttrain-mlogloss:0.16471\teval-mlogloss:1.75470\n",
      "[116]\ttrain-mlogloss:0.16130\teval-mlogloss:1.75390\n",
      "[117]\ttrain-mlogloss:0.15802\teval-mlogloss:1.75565\n",
      "[118]\ttrain-mlogloss:0.15487\teval-mlogloss:1.75540\n",
      "[119]\ttrain-mlogloss:0.15169\teval-mlogloss:1.75630\n",
      "[120]\ttrain-mlogloss:0.14842\teval-mlogloss:1.75647\n",
      "[121]\ttrain-mlogloss:0.14537\teval-mlogloss:1.75592\n",
      "[122]\ttrain-mlogloss:0.14251\teval-mlogloss:1.75598\n",
      "[123]\ttrain-mlogloss:0.14004\teval-mlogloss:1.75735\n",
      "[124]\ttrain-mlogloss:0.13717\teval-mlogloss:1.75643\n",
      "[125]\ttrain-mlogloss:0.13454\teval-mlogloss:1.75617\n",
      "[126]\ttrain-mlogloss:0.13187\teval-mlogloss:1.75468\n",
      "[127]\ttrain-mlogloss:0.12913\teval-mlogloss:1.75479\n",
      "[128]\ttrain-mlogloss:0.12679\teval-mlogloss:1.75388\n",
      "[129]\ttrain-mlogloss:0.12437\teval-mlogloss:1.75382\n",
      "[130]\ttrain-mlogloss:0.12187\teval-mlogloss:1.75439\n",
      "[131]\ttrain-mlogloss:0.11950\teval-mlogloss:1.75445\n",
      "[132]\ttrain-mlogloss:0.11730\teval-mlogloss:1.75420\n",
      "[133]\ttrain-mlogloss:0.11504\teval-mlogloss:1.75374\n",
      "[134]\ttrain-mlogloss:0.11268\teval-mlogloss:1.75358\n",
      "[135]\ttrain-mlogloss:0.11049\teval-mlogloss:1.75439\n",
      "[136]\ttrain-mlogloss:0.10842\teval-mlogloss:1.75443\n",
      "[137]\ttrain-mlogloss:0.10635\teval-mlogloss:1.75477\n",
      "[138]\ttrain-mlogloss:0.10433\teval-mlogloss:1.75500\n",
      "[139]\ttrain-mlogloss:0.10233\teval-mlogloss:1.75419\n",
      "[140]\ttrain-mlogloss:0.10045\teval-mlogloss:1.75423\n",
      "[141]\ttrain-mlogloss:0.09869\teval-mlogloss:1.75425\n",
      "[142]\ttrain-mlogloss:0.09697\teval-mlogloss:1.75408\n",
      "[143]\ttrain-mlogloss:0.09516\teval-mlogloss:1.75464\n",
      "[144]\ttrain-mlogloss:0.09343\teval-mlogloss:1.75512\n",
      "[145]\ttrain-mlogloss:0.09178\teval-mlogloss:1.75559\n",
      "[146]\ttrain-mlogloss:0.09016\teval-mlogloss:1.75612\n",
      "[147]\ttrain-mlogloss:0.08844\teval-mlogloss:1.75627\n",
      "[148]\ttrain-mlogloss:0.08667\teval-mlogloss:1.75504\n",
      "[149]\ttrain-mlogloss:0.08501\teval-mlogloss:1.75408\n",
      "[150]\ttrain-mlogloss:0.08345\teval-mlogloss:1.75446\n",
      "[151]\ttrain-mlogloss:0.08186\teval-mlogloss:1.75444\n",
      "[152]\ttrain-mlogloss:0.08034\teval-mlogloss:1.75501\n",
      "[153]\ttrain-mlogloss:0.07892\teval-mlogloss:1.75542\n",
      "[154]\ttrain-mlogloss:0.07754\teval-mlogloss:1.75466\n",
      "[155]\ttrain-mlogloss:0.07609\teval-mlogloss:1.75560\n",
      "[156]\ttrain-mlogloss:0.07480\teval-mlogloss:1.75493\n",
      "[157]\ttrain-mlogloss:0.07349\teval-mlogloss:1.75592\n",
      "[158]\ttrain-mlogloss:0.07221\teval-mlogloss:1.75730\n",
      "Model saved to 2024-II/Aprendizaje/Tarea4/xgboost_model_encoded.json\n",
      "Accuracy: 0.41\n",
      "Confusion Matrix:\n",
      "[[ 20   5   1   3   9   8  22  11   2   7   0   2  12  12   2]\n",
      " [  3 123   3  40   8   2   1   2   3   1  58   0  10   4   2]\n",
      " [  0   0 179   3   0   0   0   0   8   0  21   3  10   4   0]\n",
      " [  1   9   1  72  10   2   3   0   8   1  11   1  31   8   2]\n",
      " [ 10   2   4  13  33   4  19  17   2  17  12  20  48   9   1]\n",
      " [  4   1   0   6  21  51  20   8   1   6   1  25  48  12   4]\n",
      " [  7   0   0   0   7   8  49   8   0  22   0   3   5   1   0]\n",
      " [ 19   0   0   0  18   5  16  54   1  26   0  10  18  21   1]\n",
      " [  5  10  19  17   8   0   1   5  80   2  50   6  44  26   1]\n",
      " [  7   0   0   0   5   5  29  10   0  54   0   4   1   0   0]\n",
      " [  2  22  33  27   4   1   1   1  39   0 115   3  45  16   1]\n",
      " [  2   1   9   1  12   6   9   6   2   9   2  91  40  20   5]\n",
      " [  0   0   3  12  14   1   3   2   8   0   3  21 119   5   1]\n",
      " [  0   0   2   1   6   1   1   3   4   1   1   4   8 109   0]\n",
      " [  3   4   2   9  26  24  16  12   0   6   5  18  32  10  89]]\n",
      "Model saved to 2024-II/Aprendizaje/Tarea4/random_forest_model_encoded.joblib\n",
      "Accuracy: 0.35\n",
      "Confusion Matrix:\n",
      "[[  1   8   1   2   0   4  41  17   0   3   0   5  17  17   0]\n",
      " [  1 140   4  41   0   0   5  10   3   0  21   1  23  11   0]\n",
      " [  0   3 174   0   0   0   0   0   4   0  22   2  10  13   0]\n",
      " [  0  19   1  55   0   0  11   4   1   1   3   2  45  17   1]\n",
      " [  2   4   2  11   2   3  46  21   0  13   0  21  67  18   1]\n",
      " [  0   2   0   8   0  35  45   8   0   2   2  31  50  24   1]\n",
      " [  0   0   0   0   0   5  68   8   0  15   0   4   8   2   0]\n",
      " [  0   0   0   0   0   1  20  66   0  32   0  12  19  38   1]\n",
      " [  1  13  23  17   0   1   5  10  32   1  32   8  64  67   0]\n",
      " [  0   1   0   0   1   3  36   8   0  59   0   4   2   1   0]\n",
      " [  0  35  48  35   1   0   3   3  13   0  66   9  61  36   0]\n",
      " [  0   2  12   1   0   5  11   6   0   7   2  59  55  51   4]\n",
      " [  0   1   1   7   1   0  15   0   1   1   3  25 122  15   0]\n",
      " [  0   0   2   1   1   0   0  11   0   0   0   9  12 105   0]\n",
      " [  0  15   5  12   0  17  34   6   0   7   4  20  56  26  54]]\n",
      "Model saved to 2024-II/Aprendizaje/Tarea4/svm_model_encoded.joblib\n",
      "Accuracy: 0.49\n",
      "Confusion Matrix:\n",
      "[[ 24   4   2   3   7   3  30  12   2   8   0   2  11   7   1]\n",
      " [  1 168   4  37   1   0   1   1   6   0  36   0   3   2   0]\n",
      " [  0   2 197   0   0   0   0   0   6   0  16   0   4   3   0]\n",
      " [  1  14   2 103   4   1   3   0   2   0   9   1  12   7   1]\n",
      " [  3   4   2  15  31   9  30  21   2  15   4  19  44  11   1]\n",
      " [  3   2   0   4  15  72  27   3   0   5   0  36  31   7   3]\n",
      " [  6   0   0   0   5   6  60   7   0  20   0   4   2   0   0]\n",
      " [ 22   0   0   1  14   3  13  66   2  32   1  15   7  12   1]\n",
      " [  4  16  27  20   4   1   0   1  95   1  64   0  25  16   0]\n",
      " [  3   1   0   0   2   1  28   6   0  69   0   5   0   0   0]\n",
      " [  1  36  41  34   2   0   0   0  30   0 149   0   9   8   0]\n",
      " [  1   1   7   1  12   5  11   2   1  10   1 114  29  16   4]\n",
      " [  0   0   5   5  19   4   5   0   5   2   4  18 119   6   0]\n",
      " [  0   0   1   2   3   2   0   2   4   1   0   4   7 115   0]\n",
      " [  4   9   2   6  28  25  18   8   4   6   5  16  27  13  85]]\n"
     ]
    }
   ],
   "source": [
    "train_xgboost(train_histograms_encoded, y_train, test_histograms_encoded, y_test, 'xgboost_model_encoded')\n",
    "train_random_forest(train_histograms_encoded, y_train, test_histograms_encoded, y_test, savename='random_forest_model_encoded')\n",
    "train_svm(train_histograms_encoded, y_train, test_histograms_encoded, y_test, savename='svm_model_encoded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenar los modelos con los vectores reducidos por el PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.56370\teval-mlogloss:2.63136\n",
      "[1]\ttrain-mlogloss:2.44486\teval-mlogloss:2.57427\n",
      "[2]\ttrain-mlogloss:2.34441\teval-mlogloss:2.52432\n",
      "[3]\ttrain-mlogloss:2.25472\teval-mlogloss:2.48239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leon/.local/lib/python3.10/site-packages/xgboost/core.py:727: FutureWarning: Pass `evals` as keyword args.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4]\ttrain-mlogloss:2.17356\teval-mlogloss:2.44531\n",
      "[5]\ttrain-mlogloss:2.09930\teval-mlogloss:2.41344\n",
      "[6]\ttrain-mlogloss:2.02727\teval-mlogloss:2.38218\n",
      "[7]\ttrain-mlogloss:1.96469\teval-mlogloss:2.35273\n",
      "[8]\ttrain-mlogloss:1.90372\teval-mlogloss:2.32821\n",
      "[9]\ttrain-mlogloss:1.84734\teval-mlogloss:2.30581\n",
      "[10]\ttrain-mlogloss:1.79385\teval-mlogloss:2.28692\n",
      "[11]\ttrain-mlogloss:1.74127\teval-mlogloss:2.26994\n",
      "[12]\ttrain-mlogloss:1.69136\teval-mlogloss:2.25555\n",
      "[13]\ttrain-mlogloss:1.64399\teval-mlogloss:2.23949\n",
      "[14]\ttrain-mlogloss:1.59631\teval-mlogloss:2.22464\n",
      "[15]\ttrain-mlogloss:1.55312\teval-mlogloss:2.21102\n",
      "[16]\ttrain-mlogloss:1.51053\teval-mlogloss:2.19819\n",
      "[17]\ttrain-mlogloss:1.47122\teval-mlogloss:2.18416\n",
      "[18]\ttrain-mlogloss:1.43240\teval-mlogloss:2.17427\n",
      "[19]\ttrain-mlogloss:1.39666\teval-mlogloss:2.16108\n",
      "[20]\ttrain-mlogloss:1.35934\teval-mlogloss:2.15090\n",
      "[21]\ttrain-mlogloss:1.32645\teval-mlogloss:2.14125\n",
      "[22]\ttrain-mlogloss:1.29144\teval-mlogloss:2.13206\n",
      "[23]\ttrain-mlogloss:1.25904\teval-mlogloss:2.12325\n",
      "[24]\ttrain-mlogloss:1.22855\teval-mlogloss:2.11533\n",
      "[25]\ttrain-mlogloss:1.19639\teval-mlogloss:2.10905\n",
      "[26]\ttrain-mlogloss:1.16764\teval-mlogloss:2.10155\n",
      "[27]\ttrain-mlogloss:1.13981\teval-mlogloss:2.09597\n",
      "[28]\ttrain-mlogloss:1.11228\teval-mlogloss:2.08998\n",
      "[29]\ttrain-mlogloss:1.08619\teval-mlogloss:2.08306\n",
      "[30]\ttrain-mlogloss:1.06048\teval-mlogloss:2.07581\n",
      "[31]\ttrain-mlogloss:1.03456\teval-mlogloss:2.07091\n",
      "[32]\ttrain-mlogloss:1.00952\teval-mlogloss:2.06588\n",
      "[33]\ttrain-mlogloss:0.98561\teval-mlogloss:2.06061\n",
      "[34]\ttrain-mlogloss:0.96289\teval-mlogloss:2.05669\n",
      "[35]\ttrain-mlogloss:0.94114\teval-mlogloss:2.05157\n",
      "[36]\ttrain-mlogloss:0.91848\teval-mlogloss:2.04680\n",
      "[37]\ttrain-mlogloss:0.89681\teval-mlogloss:2.04408\n",
      "[38]\ttrain-mlogloss:0.87577\teval-mlogloss:2.04057\n",
      "[39]\ttrain-mlogloss:0.85470\teval-mlogloss:2.03675\n",
      "[40]\ttrain-mlogloss:0.83490\teval-mlogloss:2.03243\n",
      "[41]\ttrain-mlogloss:0.81577\teval-mlogloss:2.02906\n",
      "[42]\ttrain-mlogloss:0.79621\teval-mlogloss:2.02599\n",
      "[43]\ttrain-mlogloss:0.77728\teval-mlogloss:2.02220\n",
      "[44]\ttrain-mlogloss:0.76112\teval-mlogloss:2.01920\n",
      "[45]\ttrain-mlogloss:0.74576\teval-mlogloss:2.01432\n",
      "[46]\ttrain-mlogloss:0.72803\teval-mlogloss:2.01368\n",
      "[47]\ttrain-mlogloss:0.71055\teval-mlogloss:2.01200\n",
      "[48]\ttrain-mlogloss:0.69461\teval-mlogloss:2.00831\n",
      "[49]\ttrain-mlogloss:0.67896\teval-mlogloss:2.00636\n",
      "[50]\ttrain-mlogloss:0.66427\teval-mlogloss:2.00563\n",
      "[51]\ttrain-mlogloss:0.64927\teval-mlogloss:2.00350\n",
      "[52]\ttrain-mlogloss:0.63406\teval-mlogloss:2.00299\n",
      "[53]\ttrain-mlogloss:0.61934\teval-mlogloss:2.00114\n",
      "[54]\ttrain-mlogloss:0.60403\teval-mlogloss:1.99911\n",
      "[55]\ttrain-mlogloss:0.59236\teval-mlogloss:1.99788\n",
      "[56]\ttrain-mlogloss:0.57895\teval-mlogloss:1.99735\n",
      "[57]\ttrain-mlogloss:0.56605\teval-mlogloss:1.99608\n",
      "[58]\ttrain-mlogloss:0.55261\teval-mlogloss:1.99517\n",
      "[59]\ttrain-mlogloss:0.54061\teval-mlogloss:1.99318\n",
      "[60]\ttrain-mlogloss:0.52831\teval-mlogloss:1.99039\n",
      "[61]\ttrain-mlogloss:0.51532\teval-mlogloss:1.98929\n",
      "[62]\ttrain-mlogloss:0.50367\teval-mlogloss:1.98825\n",
      "[63]\ttrain-mlogloss:0.49327\teval-mlogloss:1.98721\n",
      "[64]\ttrain-mlogloss:0.48202\teval-mlogloss:1.98733\n",
      "[65]\ttrain-mlogloss:0.47204\teval-mlogloss:1.98748\n",
      "[66]\ttrain-mlogloss:0.46171\teval-mlogloss:1.98765\n",
      "[67]\ttrain-mlogloss:0.45083\teval-mlogloss:1.98586\n",
      "[68]\ttrain-mlogloss:0.44121\teval-mlogloss:1.98399\n",
      "[69]\ttrain-mlogloss:0.43110\teval-mlogloss:1.98417\n",
      "[70]\ttrain-mlogloss:0.42100\teval-mlogloss:1.98404\n",
      "[71]\ttrain-mlogloss:0.41153\teval-mlogloss:1.98405\n",
      "[72]\ttrain-mlogloss:0.40190\teval-mlogloss:1.98276\n",
      "[73]\ttrain-mlogloss:0.39238\teval-mlogloss:1.98124\n",
      "[74]\ttrain-mlogloss:0.38382\teval-mlogloss:1.98108\n",
      "[75]\ttrain-mlogloss:0.37536\teval-mlogloss:1.98162\n",
      "[76]\ttrain-mlogloss:0.36609\teval-mlogloss:1.98097\n",
      "[77]\ttrain-mlogloss:0.35759\teval-mlogloss:1.97971\n",
      "[78]\ttrain-mlogloss:0.35031\teval-mlogloss:1.97938\n",
      "[79]\ttrain-mlogloss:0.34304\teval-mlogloss:1.97887\n",
      "[80]\ttrain-mlogloss:0.33526\teval-mlogloss:1.97910\n",
      "[81]\ttrain-mlogloss:0.32760\teval-mlogloss:1.97988\n",
      "[82]\ttrain-mlogloss:0.32051\teval-mlogloss:1.97957\n",
      "[83]\ttrain-mlogloss:0.31298\teval-mlogloss:1.97928\n",
      "[84]\ttrain-mlogloss:0.30555\teval-mlogloss:1.97803\n",
      "[85]\ttrain-mlogloss:0.29879\teval-mlogloss:1.97843\n",
      "[86]\ttrain-mlogloss:0.29273\teval-mlogloss:1.97958\n",
      "[87]\ttrain-mlogloss:0.28626\teval-mlogloss:1.97879\n",
      "[88]\ttrain-mlogloss:0.27968\teval-mlogloss:1.97930\n",
      "[89]\ttrain-mlogloss:0.27338\teval-mlogloss:1.97981\n",
      "[90]\ttrain-mlogloss:0.26711\teval-mlogloss:1.98066\n",
      "[91]\ttrain-mlogloss:0.26127\teval-mlogloss:1.98015\n",
      "[92]\ttrain-mlogloss:0.25543\teval-mlogloss:1.97827\n",
      "[93]\ttrain-mlogloss:0.24903\teval-mlogloss:1.97882\n",
      "[94]\ttrain-mlogloss:0.24370\teval-mlogloss:1.97939\n",
      "[95]\ttrain-mlogloss:0.23818\teval-mlogloss:1.98047\n",
      "[96]\ttrain-mlogloss:0.23355\teval-mlogloss:1.97970\n",
      "[97]\ttrain-mlogloss:0.22864\teval-mlogloss:1.98057\n",
      "[98]\ttrain-mlogloss:0.22362\teval-mlogloss:1.98167\n",
      "[99]\ttrain-mlogloss:0.21880\teval-mlogloss:1.98268\n",
      "[100]\ttrain-mlogloss:0.21371\teval-mlogloss:1.98158\n",
      "[101]\ttrain-mlogloss:0.20903\teval-mlogloss:1.98195\n",
      "[102]\ttrain-mlogloss:0.20450\teval-mlogloss:1.98279\n",
      "[103]\ttrain-mlogloss:0.20022\teval-mlogloss:1.98495\n",
      "[104]\ttrain-mlogloss:0.19562\teval-mlogloss:1.98521\n",
      "[105]\ttrain-mlogloss:0.19130\teval-mlogloss:1.98632\n",
      "[106]\ttrain-mlogloss:0.18707\teval-mlogloss:1.98606\n",
      "[107]\ttrain-mlogloss:0.18294\teval-mlogloss:1.98711\n",
      "[108]\ttrain-mlogloss:0.17854\teval-mlogloss:1.98802\n",
      "Model saved to 2024-II/Aprendizaje/Tarea4/xgboost_model_pca.json\n",
      "Accuracy: 0.36\n",
      "Confusion Matrix:\n",
      "[[ 25   5   3   7   3   0  28  12   0  18   4   1   1   2   7]\n",
      " [ 11 181   7  35   0   1   8   1   3   2   8   0   0   1   2]\n",
      " [  1   3 194   3   0   0   0   0  10   1  11   0   0   1   4]\n",
      " [  5  33   2  86   1   2   2   2   3   3  12   0   1   1   7]\n",
      " [ 19  15   3  32  10   9  38  10   4  27  14   2   2  13  13]\n",
      " [ 10   5   0  14   6  50  29   1   2  30   5  10   3   6  37]\n",
      " [  9   2   0   8   1   1  52   4   1  29   0   0   0   1   2]\n",
      " [ 26   1   0   5   1   1  25  47   2  54   2   3   0  14   8]\n",
      " [ 18  35  25  43   1   1   7   5  60   9  38   2   0  26   4]\n",
      " [  7   0   0   1   1   2  32   8   0  63   0   0   0   1   0]\n",
      " [ 10  81  42  49   3   2   4   6  28   9  55   0   2  10   9]\n",
      " [ 14   4  17   7   7  12  24   5  11  33   6  27   5  22  21]\n",
      " [  7  11   3  32   5  13  17   1  16  29  14   2  17   7  18]\n",
      " [  4   1   6  10   0   1   6   6   6  12   4   0   1  82   2]\n",
      " [  3  15   2  14   3  16  20  11   2  15   7   1   6  15 126]]\n",
      "Model saved to 2024-II/Aprendizaje/Tarea4/random_forest_model_pca.joblib\n",
      "Accuracy: 0.29\n",
      "Confusion Matrix:\n",
      "[[ 21  25   3   3   0   0  42   2   0  17   0   0   0   0   3]\n",
      " [  1 249   5   0   0   0   2   0   0   1   0   0   0   0   2]\n",
      " [  0  27 189   3   0   0   2   0   1   0   0   0   0   2   4]\n",
      " [  1 121   1  20   0   0   7   0   0   3   1   0   0   0   6]\n",
      " [  3  85   2   7   0   4  55   4   0  30   0   1   0   3  17]\n",
      " [  5  36   0   1   0  13  89   2   0  22   0   0   0   1  39]\n",
      " [  3  10   0   0   0   0  76   0   0  20   0   0   0   1   0]\n",
      " [ 26  18   0   1   0   1  42  23   0  67   0   0   0   6   5]\n",
      " [  9 160  24   7   0   0  35   1   9   6   1   0   0  11  11]\n",
      " [  2   8   0   0   0   0  48   1   0  55   0   0   0   1   0]\n",
      " [  3 225  41  10   0   0  12   1   0   8   1   0   0   4   5]\n",
      " [  4  29  16   0   1   3  80   1   0  34   1   2   0  13  31]\n",
      " [  3  82   3  12   0   5  46   0   0  25   0   0   1   2  13]\n",
      " [  3  13   6   5   0   2  13   3   0  29   0   0   0  62   5]\n",
      " [  6  50   1   5   0   6  35   1   0  17   0   0   0   3 132]]\n",
      "Model saved to 2024-II/Aprendizaje/Tarea4/svm_model_pca.joblib\n",
      "Accuracy: 0.46\n",
      "Confusion Matrix:\n",
      "[[ 28   6   0   4   2   2  27  10   6  22   2   1   5   0   1]\n",
      " [  4 156   5  64   0   1   1   1   7   1  20   0   0   0   0]\n",
      " [  0   0 175   0   0   0   0   0  21   0  27   1   3   1   0]\n",
      " [  4  22   0 106   5   2   4   0   2   1   5   1   5   2   1]\n",
      " [ 17   5   1  19  29  17  23  15   8  29   7  10  28   1   2]\n",
      " [  5   4   0   5  10  97  27   3   2  18   3  20  12   1   1]\n",
      " [  5   2   0   1   1   4  62   5   0  29   0   0   1   0   0]\n",
      " [ 25   1   0   4   1   3  16  45   2  70   0   8   6   8   0]\n",
      " [ 10  16  16  39   3   0   1   4 106   2  49   2   8  16   2]\n",
      " [  4   0   0   0   0   0  21   4   0  85   0   1   0   0   0]\n",
      " [  2  42  25  53   0   0   0   2  40   0 132   1   7   6   0]\n",
      " [  6   1   5   2   9  13  15   2   7  38   5  83  18   6   5]\n",
      " [  3   1   1  19  11  18   6   3  11  13  12  14  77   3   0]\n",
      " [  0   0   4  10   0   1   2   6   8  17   1   5   3  84   0]\n",
      " [  2   5   2  13  17  35  11   9   3  21   3  16  18   5  96]]\n"
     ]
    }
   ],
   "source": [
    "train_xgboost(train_histograms_pca, y_train, test_histograms_pca, y_test, savename='xgboost_model_pca')\n",
    "train_random_forest(train_histograms_pca, y_train, test_histograms_pca, y_test, savename='random_forest_model_pca')\n",
    "train_svm(train_histograms_pca, y_train, test_histograms_pca, y_test, savename='svm_model_pca')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenar modelos reduciendo las bolsas de características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature presence matrix shape: (1500, 10000)\n",
      "Feature presence counts: [ 71  44  29 ...  72 142  86]\n"
     ]
    }
   ],
   "source": [
    "feature_presence = (train_histograms > 0).astype(int)\n",
    "print(\"Feature presence matrix shape:\", feature_presence.shape)\n",
    "\n",
    "feature_presence_counts = feature_presence.sum(axis=0)\n",
    "print(\"Feature presence counts:\", feature_presence_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 75.0\n",
      "Common features to remove: [   3    4    5 ... 9994 9998 9999]\n",
      "Number of common features: 3398\n"
     ]
    }
   ],
   "source": [
    "# Definir un umbral para eliminar características comunes (por ejemplo, presentes en más del 90% de las bolsas)\n",
    "threshold = 0.05 * train_histograms.shape[0]\n",
    "print(\"Threshold:\", threshold)\n",
    "\n",
    "# Identificar las características comunes\n",
    "common_features = np.where(feature_presence_counts > threshold)[0]\n",
    "print(\"Common features to remove:\", common_features)\n",
    "print(\"Number of common features:\", len(common_features))\n",
    "\n",
    "# Eliminar las características comunes de todas las bolsas de características\n",
    "def remove_common_features(features, common_features):\n",
    "    return np.delete(features, common_features, axis=1)\n",
    "\n",
    "reduced_bag_of_features_train = remove_common_features(train_histograms, common_features)\n",
    "\n",
    "# use same feautures for test\n",
    "reduced_bag_of_features_test = remove_common_features(test_histograms, common_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenar modelos con bolsa de características reducida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.66168\teval-mlogloss:2.68917\n",
      "[1]\ttrain-mlogloss:2.61729\teval-mlogloss:2.67258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leon/.local/lib/python3.10/site-packages/xgboost/core.py:727: FutureWarning: Pass `evals` as keyword args.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\ttrain-mlogloss:2.57607\teval-mlogloss:2.65894\n",
      "[3]\ttrain-mlogloss:2.53873\teval-mlogloss:2.64707\n",
      "[4]\ttrain-mlogloss:2.50281\teval-mlogloss:2.63421\n",
      "[5]\ttrain-mlogloss:2.46712\teval-mlogloss:2.62449\n",
      "[6]\ttrain-mlogloss:2.43372\teval-mlogloss:2.61559\n",
      "[7]\ttrain-mlogloss:2.40187\teval-mlogloss:2.60634\n",
      "[8]\ttrain-mlogloss:2.37134\teval-mlogloss:2.59823\n",
      "[9]\ttrain-mlogloss:2.34120\teval-mlogloss:2.59101\n",
      "[10]\ttrain-mlogloss:2.31227\teval-mlogloss:2.58324\n",
      "[11]\ttrain-mlogloss:2.28340\teval-mlogloss:2.57550\n",
      "[12]\ttrain-mlogloss:2.25564\teval-mlogloss:2.56904\n",
      "[13]\ttrain-mlogloss:2.22847\teval-mlogloss:2.56275\n",
      "[14]\ttrain-mlogloss:2.20271\teval-mlogloss:2.55771\n",
      "[15]\ttrain-mlogloss:2.17680\teval-mlogloss:2.55192\n",
      "[16]\ttrain-mlogloss:2.15197\teval-mlogloss:2.54563\n",
      "[17]\ttrain-mlogloss:2.12687\teval-mlogloss:2.53991\n",
      "[18]\ttrain-mlogloss:2.10309\teval-mlogloss:2.53504\n",
      "[19]\ttrain-mlogloss:2.07827\teval-mlogloss:2.52917\n",
      "[20]\ttrain-mlogloss:2.05500\teval-mlogloss:2.52231\n",
      "[21]\ttrain-mlogloss:2.03266\teval-mlogloss:2.51705\n",
      "[22]\ttrain-mlogloss:2.00932\teval-mlogloss:2.51299\n",
      "[23]\ttrain-mlogloss:1.98766\teval-mlogloss:2.50869\n",
      "[24]\ttrain-mlogloss:1.96555\teval-mlogloss:2.50427\n",
      "[25]\ttrain-mlogloss:1.94440\teval-mlogloss:2.49970\n",
      "[26]\ttrain-mlogloss:1.92292\teval-mlogloss:2.49622\n",
      "[27]\ttrain-mlogloss:1.90232\teval-mlogloss:2.49200\n",
      "[28]\ttrain-mlogloss:1.88176\teval-mlogloss:2.48772\n",
      "[29]\ttrain-mlogloss:1.86223\teval-mlogloss:2.48419\n",
      "[30]\ttrain-mlogloss:1.84336\teval-mlogloss:2.48063\n",
      "[31]\ttrain-mlogloss:1.82420\teval-mlogloss:2.47612\n",
      "[32]\ttrain-mlogloss:1.80606\teval-mlogloss:2.47347\n",
      "[33]\ttrain-mlogloss:1.78869\teval-mlogloss:2.47006\n",
      "[34]\ttrain-mlogloss:1.77172\teval-mlogloss:2.46695\n",
      "[35]\ttrain-mlogloss:1.75430\teval-mlogloss:2.46319\n",
      "[36]\ttrain-mlogloss:1.73576\teval-mlogloss:2.46009\n",
      "[37]\ttrain-mlogloss:1.71942\teval-mlogloss:2.45673\n",
      "[38]\ttrain-mlogloss:1.70262\teval-mlogloss:2.45356\n",
      "[39]\ttrain-mlogloss:1.68521\teval-mlogloss:2.45098\n",
      "[40]\ttrain-mlogloss:1.66911\teval-mlogloss:2.44863\n",
      "[41]\ttrain-mlogloss:1.65376\teval-mlogloss:2.44495\n",
      "[42]\ttrain-mlogloss:1.63891\teval-mlogloss:2.44219\n",
      "[43]\ttrain-mlogloss:1.62351\teval-mlogloss:2.43911\n",
      "[44]\ttrain-mlogloss:1.60834\teval-mlogloss:2.43651\n",
      "[45]\ttrain-mlogloss:1.59352\teval-mlogloss:2.43446\n",
      "[46]\ttrain-mlogloss:1.57922\teval-mlogloss:2.43185\n",
      "[47]\ttrain-mlogloss:1.56388\teval-mlogloss:2.42976\n",
      "[48]\ttrain-mlogloss:1.54955\teval-mlogloss:2.42655\n",
      "[49]\ttrain-mlogloss:1.53569\teval-mlogloss:2.42443\n",
      "[50]\ttrain-mlogloss:1.52196\teval-mlogloss:2.42204\n",
      "[51]\ttrain-mlogloss:1.50907\teval-mlogloss:2.41935\n",
      "[52]\ttrain-mlogloss:1.49558\teval-mlogloss:2.41671\n",
      "[53]\ttrain-mlogloss:1.48205\teval-mlogloss:2.41494\n",
      "[54]\ttrain-mlogloss:1.46814\teval-mlogloss:2.41200\n",
      "[55]\ttrain-mlogloss:1.45592\teval-mlogloss:2.40943\n",
      "[56]\ttrain-mlogloss:1.44299\teval-mlogloss:2.40697\n",
      "[57]\ttrain-mlogloss:1.42975\teval-mlogloss:2.40518\n",
      "[58]\ttrain-mlogloss:1.41688\teval-mlogloss:2.40311\n",
      "[59]\ttrain-mlogloss:1.40451\teval-mlogloss:2.40026\n",
      "[60]\ttrain-mlogloss:1.39193\teval-mlogloss:2.39867\n",
      "[61]\ttrain-mlogloss:1.37991\teval-mlogloss:2.39683\n",
      "[62]\ttrain-mlogloss:1.36841\teval-mlogloss:2.39485\n",
      "[63]\ttrain-mlogloss:1.35688\teval-mlogloss:2.39291\n",
      "[64]\ttrain-mlogloss:1.34530\teval-mlogloss:2.39142\n",
      "[65]\ttrain-mlogloss:1.33411\teval-mlogloss:2.38961\n",
      "[66]\ttrain-mlogloss:1.32273\teval-mlogloss:2.38759\n",
      "[67]\ttrain-mlogloss:1.31153\teval-mlogloss:2.38635\n",
      "[68]\ttrain-mlogloss:1.30060\teval-mlogloss:2.38437\n",
      "[69]\ttrain-mlogloss:1.28984\teval-mlogloss:2.38233\n",
      "[70]\ttrain-mlogloss:1.27882\teval-mlogloss:2.38047\n",
      "[71]\ttrain-mlogloss:1.26841\teval-mlogloss:2.37981\n",
      "[72]\ttrain-mlogloss:1.25784\teval-mlogloss:2.37873\n",
      "[73]\ttrain-mlogloss:1.24696\teval-mlogloss:2.37730\n",
      "[74]\ttrain-mlogloss:1.23696\teval-mlogloss:2.37549\n",
      "[75]\ttrain-mlogloss:1.22650\teval-mlogloss:2.37342\n",
      "[76]\ttrain-mlogloss:1.21612\teval-mlogloss:2.37229\n",
      "[77]\ttrain-mlogloss:1.20577\teval-mlogloss:2.37116\n",
      "[78]\ttrain-mlogloss:1.19554\teval-mlogloss:2.36995\n",
      "[79]\ttrain-mlogloss:1.18636\teval-mlogloss:2.36829\n",
      "[80]\ttrain-mlogloss:1.17619\teval-mlogloss:2.36673\n",
      "[81]\ttrain-mlogloss:1.16644\teval-mlogloss:2.36587\n",
      "[82]\ttrain-mlogloss:1.15724\teval-mlogloss:2.36436\n",
      "[83]\ttrain-mlogloss:1.14773\teval-mlogloss:2.36338\n",
      "[84]\ttrain-mlogloss:1.13826\teval-mlogloss:2.36189\n",
      "[85]\ttrain-mlogloss:1.12895\teval-mlogloss:2.36038\n",
      "[86]\ttrain-mlogloss:1.12027\teval-mlogloss:2.35878\n",
      "[87]\ttrain-mlogloss:1.11169\teval-mlogloss:2.35760\n",
      "[88]\ttrain-mlogloss:1.10303\teval-mlogloss:2.35613\n",
      "[89]\ttrain-mlogloss:1.09513\teval-mlogloss:2.35505\n",
      "[90]\ttrain-mlogloss:1.08678\teval-mlogloss:2.35392\n",
      "[91]\ttrain-mlogloss:1.07857\teval-mlogloss:2.35261\n",
      "[92]\ttrain-mlogloss:1.07059\teval-mlogloss:2.35111\n",
      "[93]\ttrain-mlogloss:1.06200\teval-mlogloss:2.34995\n",
      "[94]\ttrain-mlogloss:1.05415\teval-mlogloss:2.34870\n",
      "[95]\ttrain-mlogloss:1.04580\teval-mlogloss:2.34776\n",
      "[96]\ttrain-mlogloss:1.03761\teval-mlogloss:2.34763\n",
      "[97]\ttrain-mlogloss:1.02931\teval-mlogloss:2.34619\n",
      "[98]\ttrain-mlogloss:1.02145\teval-mlogloss:2.34555\n",
      "[99]\ttrain-mlogloss:1.01413\teval-mlogloss:2.34446\n",
      "[100]\ttrain-mlogloss:1.00630\teval-mlogloss:2.34340\n",
      "[101]\ttrain-mlogloss:0.99898\teval-mlogloss:2.34213\n",
      "[102]\ttrain-mlogloss:0.99163\teval-mlogloss:2.34065\n",
      "[103]\ttrain-mlogloss:0.98385\teval-mlogloss:2.33889\n",
      "[104]\ttrain-mlogloss:0.97671\teval-mlogloss:2.33782\n",
      "[105]\ttrain-mlogloss:0.96976\teval-mlogloss:2.33636\n",
      "[106]\ttrain-mlogloss:0.96277\teval-mlogloss:2.33451\n",
      "[107]\ttrain-mlogloss:0.95587\teval-mlogloss:2.33327\n",
      "[108]\ttrain-mlogloss:0.94887\teval-mlogloss:2.33239\n",
      "[109]\ttrain-mlogloss:0.94168\teval-mlogloss:2.33143\n",
      "[110]\ttrain-mlogloss:0.93513\teval-mlogloss:2.33061\n",
      "[111]\ttrain-mlogloss:0.92817\teval-mlogloss:2.32966\n",
      "[112]\ttrain-mlogloss:0.92152\teval-mlogloss:2.32915\n",
      "[113]\ttrain-mlogloss:0.91520\teval-mlogloss:2.32816\n",
      "[114]\ttrain-mlogloss:0.90861\teval-mlogloss:2.32766\n",
      "[115]\ttrain-mlogloss:0.90216\teval-mlogloss:2.32640\n",
      "[116]\ttrain-mlogloss:0.89582\teval-mlogloss:2.32514\n",
      "[117]\ttrain-mlogloss:0.88972\teval-mlogloss:2.32450\n",
      "[118]\ttrain-mlogloss:0.88381\teval-mlogloss:2.32384\n",
      "[119]\ttrain-mlogloss:0.87793\teval-mlogloss:2.32340\n",
      "[120]\ttrain-mlogloss:0.87162\teval-mlogloss:2.32268\n",
      "[121]\ttrain-mlogloss:0.86539\teval-mlogloss:2.32185\n",
      "[122]\ttrain-mlogloss:0.85944\teval-mlogloss:2.32103\n",
      "[123]\ttrain-mlogloss:0.85336\teval-mlogloss:2.32006\n",
      "[124]\ttrain-mlogloss:0.84734\teval-mlogloss:2.31916\n",
      "[125]\ttrain-mlogloss:0.84135\teval-mlogloss:2.31811\n",
      "[126]\ttrain-mlogloss:0.83565\teval-mlogloss:2.31770\n",
      "[127]\ttrain-mlogloss:0.82988\teval-mlogloss:2.31674\n",
      "[128]\ttrain-mlogloss:0.82431\teval-mlogloss:2.31605\n",
      "[129]\ttrain-mlogloss:0.81814\teval-mlogloss:2.31559\n",
      "[130]\ttrain-mlogloss:0.81286\teval-mlogloss:2.31481\n",
      "[131]\ttrain-mlogloss:0.80735\teval-mlogloss:2.31388\n",
      "[132]\ttrain-mlogloss:0.80206\teval-mlogloss:2.31276\n",
      "[133]\ttrain-mlogloss:0.79680\teval-mlogloss:2.31158\n",
      "[134]\ttrain-mlogloss:0.79176\teval-mlogloss:2.31037\n",
      "[135]\ttrain-mlogloss:0.78648\teval-mlogloss:2.31018\n",
      "[136]\ttrain-mlogloss:0.78114\teval-mlogloss:2.30968\n",
      "[137]\ttrain-mlogloss:0.77614\teval-mlogloss:2.30915\n",
      "[138]\ttrain-mlogloss:0.77137\teval-mlogloss:2.30826\n",
      "[139]\ttrain-mlogloss:0.76619\teval-mlogloss:2.30676\n",
      "[140]\ttrain-mlogloss:0.76088\teval-mlogloss:2.30611\n",
      "[141]\ttrain-mlogloss:0.75580\teval-mlogloss:2.30493\n",
      "[142]\ttrain-mlogloss:0.75086\teval-mlogloss:2.30413\n",
      "[143]\ttrain-mlogloss:0.74603\teval-mlogloss:2.30340\n",
      "[144]\ttrain-mlogloss:0.74135\teval-mlogloss:2.30242\n",
      "[145]\ttrain-mlogloss:0.73640\teval-mlogloss:2.30182\n",
      "[146]\ttrain-mlogloss:0.73156\teval-mlogloss:2.30069\n",
      "[147]\ttrain-mlogloss:0.72704\teval-mlogloss:2.30033\n",
      "[148]\ttrain-mlogloss:0.72224\teval-mlogloss:2.29959\n",
      "[149]\ttrain-mlogloss:0.71786\teval-mlogloss:2.29879\n",
      "[150]\ttrain-mlogloss:0.71356\teval-mlogloss:2.29774\n",
      "[151]\ttrain-mlogloss:0.70891\teval-mlogloss:2.29738\n",
      "[152]\ttrain-mlogloss:0.70442\teval-mlogloss:2.29657\n",
      "[153]\ttrain-mlogloss:0.70003\teval-mlogloss:2.29604\n",
      "[154]\ttrain-mlogloss:0.69570\teval-mlogloss:2.29466\n",
      "[155]\ttrain-mlogloss:0.69160\teval-mlogloss:2.29373\n",
      "[156]\ttrain-mlogloss:0.68726\teval-mlogloss:2.29250\n",
      "[157]\ttrain-mlogloss:0.68315\teval-mlogloss:2.29242\n",
      "[158]\ttrain-mlogloss:0.67904\teval-mlogloss:2.29199\n",
      "[159]\ttrain-mlogloss:0.67500\teval-mlogloss:2.29151\n",
      "[160]\ttrain-mlogloss:0.67080\teval-mlogloss:2.29112\n",
      "[161]\ttrain-mlogloss:0.66683\teval-mlogloss:2.29051\n",
      "[162]\ttrain-mlogloss:0.66276\teval-mlogloss:2.28937\n",
      "[163]\ttrain-mlogloss:0.65905\teval-mlogloss:2.28874\n",
      "[164]\ttrain-mlogloss:0.65496\teval-mlogloss:2.28810\n",
      "[165]\ttrain-mlogloss:0.65101\teval-mlogloss:2.28741\n",
      "[166]\ttrain-mlogloss:0.64692\teval-mlogloss:2.28711\n",
      "[167]\ttrain-mlogloss:0.64303\teval-mlogloss:2.28657\n",
      "[168]\ttrain-mlogloss:0.63883\teval-mlogloss:2.28611\n",
      "[169]\ttrain-mlogloss:0.63506\teval-mlogloss:2.28562\n",
      "[170]\ttrain-mlogloss:0.63147\teval-mlogloss:2.28550\n",
      "[171]\ttrain-mlogloss:0.62773\teval-mlogloss:2.28483\n",
      "[172]\ttrain-mlogloss:0.62424\teval-mlogloss:2.28459\n",
      "[173]\ttrain-mlogloss:0.62028\teval-mlogloss:2.28378\n",
      "[174]\ttrain-mlogloss:0.61638\teval-mlogloss:2.28338\n",
      "[175]\ttrain-mlogloss:0.61270\teval-mlogloss:2.28280\n",
      "[176]\ttrain-mlogloss:0.60906\teval-mlogloss:2.28240\n",
      "[177]\ttrain-mlogloss:0.60564\teval-mlogloss:2.28169\n",
      "[178]\ttrain-mlogloss:0.60210\teval-mlogloss:2.28091\n",
      "[179]\ttrain-mlogloss:0.59880\teval-mlogloss:2.28054\n",
      "[180]\ttrain-mlogloss:0.59536\teval-mlogloss:2.27984\n",
      "[181]\ttrain-mlogloss:0.59202\teval-mlogloss:2.27974\n",
      "[182]\ttrain-mlogloss:0.58855\teval-mlogloss:2.27889\n",
      "[183]\ttrain-mlogloss:0.58518\teval-mlogloss:2.27874\n",
      "[184]\ttrain-mlogloss:0.58183\teval-mlogloss:2.27839\n",
      "[185]\ttrain-mlogloss:0.57859\teval-mlogloss:2.27735\n",
      "[186]\ttrain-mlogloss:0.57518\teval-mlogloss:2.27687\n",
      "[187]\ttrain-mlogloss:0.57187\teval-mlogloss:2.27625\n",
      "[188]\ttrain-mlogloss:0.56844\teval-mlogloss:2.27609\n",
      "[189]\ttrain-mlogloss:0.56527\teval-mlogloss:2.27506\n",
      "[190]\ttrain-mlogloss:0.56181\teval-mlogloss:2.27417\n",
      "[191]\ttrain-mlogloss:0.55863\teval-mlogloss:2.27388\n",
      "[192]\ttrain-mlogloss:0.55547\teval-mlogloss:2.27320\n",
      "[193]\ttrain-mlogloss:0.55216\teval-mlogloss:2.27300\n",
      "[194]\ttrain-mlogloss:0.54903\teval-mlogloss:2.27258\n",
      "[195]\ttrain-mlogloss:0.54595\teval-mlogloss:2.27235\n",
      "[196]\ttrain-mlogloss:0.54299\teval-mlogloss:2.27207\n",
      "[197]\ttrain-mlogloss:0.53978\teval-mlogloss:2.27118\n",
      "[198]\ttrain-mlogloss:0.53688\teval-mlogloss:2.27063\n",
      "[199]\ttrain-mlogloss:0.53378\teval-mlogloss:2.26982\n",
      "[200]\ttrain-mlogloss:0.53073\teval-mlogloss:2.26937\n",
      "[201]\ttrain-mlogloss:0.52773\teval-mlogloss:2.26910\n",
      "[202]\ttrain-mlogloss:0.52480\teval-mlogloss:2.26880\n",
      "[203]\ttrain-mlogloss:0.52176\teval-mlogloss:2.26834\n",
      "[204]\ttrain-mlogloss:0.51874\teval-mlogloss:2.26769\n",
      "[205]\ttrain-mlogloss:0.51593\teval-mlogloss:2.26721\n",
      "[206]\ttrain-mlogloss:0.51311\teval-mlogloss:2.26614\n",
      "[207]\ttrain-mlogloss:0.51017\teval-mlogloss:2.26545\n",
      "[208]\ttrain-mlogloss:0.50728\teval-mlogloss:2.26515\n",
      "[209]\ttrain-mlogloss:0.50466\teval-mlogloss:2.26463\n",
      "[210]\ttrain-mlogloss:0.50198\teval-mlogloss:2.26444\n",
      "[211]\ttrain-mlogloss:0.49912\teval-mlogloss:2.26373\n",
      "[212]\ttrain-mlogloss:0.49632\teval-mlogloss:2.26369\n",
      "[213]\ttrain-mlogloss:0.49337\teval-mlogloss:2.26344\n",
      "[214]\ttrain-mlogloss:0.49064\teval-mlogloss:2.26271\n",
      "[215]\ttrain-mlogloss:0.48787\teval-mlogloss:2.26190\n",
      "[216]\ttrain-mlogloss:0.48523\teval-mlogloss:2.26166\n",
      "[217]\ttrain-mlogloss:0.48252\teval-mlogloss:2.26125\n",
      "[218]\ttrain-mlogloss:0.47980\teval-mlogloss:2.26126\n",
      "[219]\ttrain-mlogloss:0.47695\teval-mlogloss:2.26039\n",
      "[220]\ttrain-mlogloss:0.47445\teval-mlogloss:2.25989\n",
      "[221]\ttrain-mlogloss:0.47189\teval-mlogloss:2.25973\n",
      "[222]\ttrain-mlogloss:0.46936\teval-mlogloss:2.25901\n",
      "[223]\ttrain-mlogloss:0.46680\teval-mlogloss:2.25805\n",
      "[224]\ttrain-mlogloss:0.46422\teval-mlogloss:2.25761\n",
      "[225]\ttrain-mlogloss:0.46162\teval-mlogloss:2.25725\n",
      "[226]\ttrain-mlogloss:0.45903\teval-mlogloss:2.25688\n",
      "[227]\ttrain-mlogloss:0.45657\teval-mlogloss:2.25734\n",
      "[228]\ttrain-mlogloss:0.45411\teval-mlogloss:2.25653\n",
      "[229]\ttrain-mlogloss:0.45165\teval-mlogloss:2.25638\n",
      "[230]\ttrain-mlogloss:0.44936\teval-mlogloss:2.25599\n",
      "[231]\ttrain-mlogloss:0.44702\teval-mlogloss:2.25557\n",
      "[232]\ttrain-mlogloss:0.44455\teval-mlogloss:2.25536\n",
      "[233]\ttrain-mlogloss:0.44223\teval-mlogloss:2.25530\n",
      "[234]\ttrain-mlogloss:0.44003\teval-mlogloss:2.25506\n",
      "[235]\ttrain-mlogloss:0.43781\teval-mlogloss:2.25457\n",
      "[236]\ttrain-mlogloss:0.43561\teval-mlogloss:2.25418\n",
      "[237]\ttrain-mlogloss:0.43328\teval-mlogloss:2.25392\n",
      "[238]\ttrain-mlogloss:0.43099\teval-mlogloss:2.25375\n",
      "[239]\ttrain-mlogloss:0.42844\teval-mlogloss:2.25298\n",
      "[240]\ttrain-mlogloss:0.42618\teval-mlogloss:2.25252\n",
      "[241]\ttrain-mlogloss:0.42390\teval-mlogloss:2.25232\n",
      "[242]\ttrain-mlogloss:0.42179\teval-mlogloss:2.25157\n",
      "[243]\ttrain-mlogloss:0.41957\teval-mlogloss:2.25151\n",
      "[244]\ttrain-mlogloss:0.41728\teval-mlogloss:2.25131\n",
      "[245]\ttrain-mlogloss:0.41503\teval-mlogloss:2.25120\n",
      "[246]\ttrain-mlogloss:0.41291\teval-mlogloss:2.25071\n",
      "[247]\ttrain-mlogloss:0.41084\teval-mlogloss:2.25044\n",
      "[248]\ttrain-mlogloss:0.40865\teval-mlogloss:2.25013\n",
      "[249]\ttrain-mlogloss:0.40623\teval-mlogloss:2.24991\n",
      "[250]\ttrain-mlogloss:0.40398\teval-mlogloss:2.24988\n",
      "[251]\ttrain-mlogloss:0.40181\teval-mlogloss:2.24952\n",
      "[252]\ttrain-mlogloss:0.39969\teval-mlogloss:2.24942\n",
      "[253]\ttrain-mlogloss:0.39769\teval-mlogloss:2.24951\n",
      "[254]\ttrain-mlogloss:0.39569\teval-mlogloss:2.24929\n",
      "[255]\ttrain-mlogloss:0.39370\teval-mlogloss:2.24917\n",
      "[256]\ttrain-mlogloss:0.39162\teval-mlogloss:2.24914\n",
      "[257]\ttrain-mlogloss:0.38958\teval-mlogloss:2.24889\n",
      "[258]\ttrain-mlogloss:0.38751\teval-mlogloss:2.24830\n",
      "[259]\ttrain-mlogloss:0.38539\teval-mlogloss:2.24812\n",
      "[260]\ttrain-mlogloss:0.38333\teval-mlogloss:2.24798\n",
      "[261]\ttrain-mlogloss:0.38132\teval-mlogloss:2.24739\n",
      "[262]\ttrain-mlogloss:0.37939\teval-mlogloss:2.24711\n",
      "[263]\ttrain-mlogloss:0.37743\teval-mlogloss:2.24733\n",
      "[264]\ttrain-mlogloss:0.37547\teval-mlogloss:2.24687\n",
      "[265]\ttrain-mlogloss:0.37361\teval-mlogloss:2.24694\n",
      "[266]\ttrain-mlogloss:0.37167\teval-mlogloss:2.24696\n",
      "[267]\ttrain-mlogloss:0.36982\teval-mlogloss:2.24672\n",
      "[268]\ttrain-mlogloss:0.36787\teval-mlogloss:2.24656\n",
      "[269]\ttrain-mlogloss:0.36582\teval-mlogloss:2.24653\n",
      "[270]\ttrain-mlogloss:0.36398\teval-mlogloss:2.24614\n",
      "[271]\ttrain-mlogloss:0.36203\teval-mlogloss:2.24578\n",
      "[272]\ttrain-mlogloss:0.36020\teval-mlogloss:2.24496\n",
      "[273]\ttrain-mlogloss:0.35837\teval-mlogloss:2.24485\n",
      "[274]\ttrain-mlogloss:0.35663\teval-mlogloss:2.24466\n",
      "[275]\ttrain-mlogloss:0.35485\teval-mlogloss:2.24452\n",
      "[276]\ttrain-mlogloss:0.35306\teval-mlogloss:2.24439\n",
      "[277]\ttrain-mlogloss:0.35138\teval-mlogloss:2.24403\n",
      "[278]\ttrain-mlogloss:0.34967\teval-mlogloss:2.24342\n",
      "[279]\ttrain-mlogloss:0.34786\teval-mlogloss:2.24298\n",
      "[280]\ttrain-mlogloss:0.34614\teval-mlogloss:2.24294\n",
      "[281]\ttrain-mlogloss:0.34450\teval-mlogloss:2.24247\n",
      "[282]\ttrain-mlogloss:0.34288\teval-mlogloss:2.24242\n",
      "[283]\ttrain-mlogloss:0.34115\teval-mlogloss:2.24188\n",
      "[284]\ttrain-mlogloss:0.33926\teval-mlogloss:2.24134\n",
      "[285]\ttrain-mlogloss:0.33748\teval-mlogloss:2.24076\n",
      "[286]\ttrain-mlogloss:0.33577\teval-mlogloss:2.24049\n",
      "[287]\ttrain-mlogloss:0.33407\teval-mlogloss:2.24041\n",
      "[288]\ttrain-mlogloss:0.33232\teval-mlogloss:2.24004\n",
      "[289]\ttrain-mlogloss:0.33063\teval-mlogloss:2.23988\n",
      "[290]\ttrain-mlogloss:0.32892\teval-mlogloss:2.23979\n",
      "[291]\ttrain-mlogloss:0.32716\teval-mlogloss:2.23969\n",
      "[292]\ttrain-mlogloss:0.32558\teval-mlogloss:2.23957\n",
      "[293]\ttrain-mlogloss:0.32405\teval-mlogloss:2.23963\n",
      "[294]\ttrain-mlogloss:0.32256\teval-mlogloss:2.23929\n",
      "[295]\ttrain-mlogloss:0.32096\teval-mlogloss:2.23921\n",
      "[296]\ttrain-mlogloss:0.31933\teval-mlogloss:2.23914\n",
      "[297]\ttrain-mlogloss:0.31769\teval-mlogloss:2.23922\n",
      "[298]\ttrain-mlogloss:0.31610\teval-mlogloss:2.23889\n",
      "[299]\ttrain-mlogloss:0.31460\teval-mlogloss:2.23878\n",
      "[300]\ttrain-mlogloss:0.31298\teval-mlogloss:2.23872\n",
      "[301]\ttrain-mlogloss:0.31152\teval-mlogloss:2.23848\n",
      "[302]\ttrain-mlogloss:0.31000\teval-mlogloss:2.23833\n",
      "[303]\ttrain-mlogloss:0.30846\teval-mlogloss:2.23780\n",
      "[304]\ttrain-mlogloss:0.30688\teval-mlogloss:2.23754\n",
      "[305]\ttrain-mlogloss:0.30540\teval-mlogloss:2.23729\n",
      "[306]\ttrain-mlogloss:0.30393\teval-mlogloss:2.23730\n",
      "[307]\ttrain-mlogloss:0.30243\teval-mlogloss:2.23731\n",
      "[308]\ttrain-mlogloss:0.30094\teval-mlogloss:2.23706\n",
      "[309]\ttrain-mlogloss:0.29940\teval-mlogloss:2.23685\n",
      "[310]\ttrain-mlogloss:0.29799\teval-mlogloss:2.23682\n",
      "[311]\ttrain-mlogloss:0.29658\teval-mlogloss:2.23693\n",
      "[312]\ttrain-mlogloss:0.29519\teval-mlogloss:2.23648\n",
      "[313]\ttrain-mlogloss:0.29371\teval-mlogloss:2.23666\n",
      "[314]\ttrain-mlogloss:0.29230\teval-mlogloss:2.23685\n",
      "[315]\ttrain-mlogloss:0.29086\teval-mlogloss:2.23670\n",
      "[316]\ttrain-mlogloss:0.28936\teval-mlogloss:2.23657\n",
      "[317]\ttrain-mlogloss:0.28792\teval-mlogloss:2.23680\n",
      "[318]\ttrain-mlogloss:0.28650\teval-mlogloss:2.23655\n",
      "[319]\ttrain-mlogloss:0.28518\teval-mlogloss:2.23656\n",
      "[320]\ttrain-mlogloss:0.28383\teval-mlogloss:2.23650\n",
      "[321]\ttrain-mlogloss:0.28251\teval-mlogloss:2.23638\n",
      "[322]\ttrain-mlogloss:0.28123\teval-mlogloss:2.23603\n",
      "[323]\ttrain-mlogloss:0.27983\teval-mlogloss:2.23609\n",
      "[324]\ttrain-mlogloss:0.27840\teval-mlogloss:2.23594\n",
      "[325]\ttrain-mlogloss:0.27706\teval-mlogloss:2.23564\n",
      "[326]\ttrain-mlogloss:0.27565\teval-mlogloss:2.23557\n",
      "[327]\ttrain-mlogloss:0.27429\teval-mlogloss:2.23536\n",
      "[328]\ttrain-mlogloss:0.27299\teval-mlogloss:2.23511\n",
      "[329]\ttrain-mlogloss:0.27165\teval-mlogloss:2.23472\n",
      "[330]\ttrain-mlogloss:0.27037\teval-mlogloss:2.23422\n",
      "[331]\ttrain-mlogloss:0.26904\teval-mlogloss:2.23450\n",
      "[332]\ttrain-mlogloss:0.26773\teval-mlogloss:2.23422\n",
      "[333]\ttrain-mlogloss:0.26638\teval-mlogloss:2.23381\n",
      "[334]\ttrain-mlogloss:0.26503\teval-mlogloss:2.23361\n",
      "[335]\ttrain-mlogloss:0.26379\teval-mlogloss:2.23359\n",
      "[336]\ttrain-mlogloss:0.26247\teval-mlogloss:2.23351\n",
      "[337]\ttrain-mlogloss:0.26117\teval-mlogloss:2.23353\n",
      "[338]\ttrain-mlogloss:0.25989\teval-mlogloss:2.23353\n",
      "[339]\ttrain-mlogloss:0.25869\teval-mlogloss:2.23344\n",
      "[340]\ttrain-mlogloss:0.25741\teval-mlogloss:2.23361\n",
      "[341]\ttrain-mlogloss:0.25624\teval-mlogloss:2.23373\n",
      "[342]\ttrain-mlogloss:0.25512\teval-mlogloss:2.23339\n",
      "[343]\ttrain-mlogloss:0.25386\teval-mlogloss:2.23310\n",
      "[344]\ttrain-mlogloss:0.25256\teval-mlogloss:2.23304\n",
      "[345]\ttrain-mlogloss:0.25139\teval-mlogloss:2.23290\n",
      "[346]\ttrain-mlogloss:0.25016\teval-mlogloss:2.23251\n",
      "[347]\ttrain-mlogloss:0.24910\teval-mlogloss:2.23270\n",
      "[348]\ttrain-mlogloss:0.24792\teval-mlogloss:2.23251\n",
      "[349]\ttrain-mlogloss:0.24677\teval-mlogloss:2.23229\n",
      "[350]\ttrain-mlogloss:0.24566\teval-mlogloss:2.23228\n",
      "[351]\ttrain-mlogloss:0.24450\teval-mlogloss:2.23191\n",
      "[352]\ttrain-mlogloss:0.24337\teval-mlogloss:2.23207\n",
      "[353]\ttrain-mlogloss:0.24227\teval-mlogloss:2.23209\n",
      "[354]\ttrain-mlogloss:0.24116\teval-mlogloss:2.23188\n",
      "[355]\ttrain-mlogloss:0.24007\teval-mlogloss:2.23178\n",
      "[356]\ttrain-mlogloss:0.23898\teval-mlogloss:2.23148\n",
      "[357]\ttrain-mlogloss:0.23781\teval-mlogloss:2.23144\n",
      "[358]\ttrain-mlogloss:0.23673\teval-mlogloss:2.23133\n",
      "[359]\ttrain-mlogloss:0.23561\teval-mlogloss:2.23112\n",
      "[360]\ttrain-mlogloss:0.23453\teval-mlogloss:2.23082\n",
      "[361]\ttrain-mlogloss:0.23347\teval-mlogloss:2.23055\n",
      "[362]\ttrain-mlogloss:0.23241\teval-mlogloss:2.23042\n",
      "[363]\ttrain-mlogloss:0.23138\teval-mlogloss:2.23019\n",
      "[364]\ttrain-mlogloss:0.23034\teval-mlogloss:2.22983\n",
      "[365]\ttrain-mlogloss:0.22930\teval-mlogloss:2.22977\n",
      "[366]\ttrain-mlogloss:0.22826\teval-mlogloss:2.22991\n",
      "[367]\ttrain-mlogloss:0.22717\teval-mlogloss:2.23016\n",
      "[368]\ttrain-mlogloss:0.22618\teval-mlogloss:2.22994\n",
      "[369]\ttrain-mlogloss:0.22518\teval-mlogloss:2.23000\n",
      "[370]\ttrain-mlogloss:0.22421\teval-mlogloss:2.22968\n",
      "[371]\ttrain-mlogloss:0.22323\teval-mlogloss:2.23007\n",
      "[372]\ttrain-mlogloss:0.22222\teval-mlogloss:2.23008\n",
      "[373]\ttrain-mlogloss:0.22123\teval-mlogloss:2.23012\n",
      "[374]\ttrain-mlogloss:0.22024\teval-mlogloss:2.23007\n",
      "[375]\ttrain-mlogloss:0.21920\teval-mlogloss:2.22997\n",
      "[376]\ttrain-mlogloss:0.21822\teval-mlogloss:2.22980\n",
      "[377]\ttrain-mlogloss:0.21720\teval-mlogloss:2.22965\n",
      "[378]\ttrain-mlogloss:0.21620\teval-mlogloss:2.22948\n",
      "[379]\ttrain-mlogloss:0.21522\teval-mlogloss:2.22940\n",
      "[380]\ttrain-mlogloss:0.21423\teval-mlogloss:2.22956\n",
      "[381]\ttrain-mlogloss:0.21328\teval-mlogloss:2.22945\n",
      "[382]\ttrain-mlogloss:0.21233\teval-mlogloss:2.22945\n",
      "[383]\ttrain-mlogloss:0.21139\teval-mlogloss:2.22971\n",
      "[384]\ttrain-mlogloss:0.21047\teval-mlogloss:2.22931\n",
      "[385]\ttrain-mlogloss:0.20954\teval-mlogloss:2.22923\n",
      "[386]\ttrain-mlogloss:0.20865\teval-mlogloss:2.22927\n",
      "[387]\ttrain-mlogloss:0.20784\teval-mlogloss:2.22912\n",
      "[388]\ttrain-mlogloss:0.20692\teval-mlogloss:2.22871\n",
      "[389]\ttrain-mlogloss:0.20608\teval-mlogloss:2.22833\n",
      "[390]\ttrain-mlogloss:0.20513\teval-mlogloss:2.22799\n",
      "[391]\ttrain-mlogloss:0.20424\teval-mlogloss:2.22790\n",
      "[392]\ttrain-mlogloss:0.20337\teval-mlogloss:2.22751\n",
      "[393]\ttrain-mlogloss:0.20245\teval-mlogloss:2.22761\n",
      "[394]\ttrain-mlogloss:0.20157\teval-mlogloss:2.22764\n",
      "[395]\ttrain-mlogloss:0.20070\teval-mlogloss:2.22782\n",
      "[396]\ttrain-mlogloss:0.19984\teval-mlogloss:2.22793\n",
      "[397]\ttrain-mlogloss:0.19901\teval-mlogloss:2.22800\n",
      "[398]\ttrain-mlogloss:0.19821\teval-mlogloss:2.22798\n",
      "[399]\ttrain-mlogloss:0.19739\teval-mlogloss:2.22785\n",
      "[400]\ttrain-mlogloss:0.19655\teval-mlogloss:2.22766\n",
      "[401]\ttrain-mlogloss:0.19571\teval-mlogloss:2.22752\n",
      "[402]\ttrain-mlogloss:0.19477\teval-mlogloss:2.22735\n",
      "[403]\ttrain-mlogloss:0.19394\teval-mlogloss:2.22737\n",
      "[404]\ttrain-mlogloss:0.19310\teval-mlogloss:2.22696\n",
      "[405]\ttrain-mlogloss:0.19221\teval-mlogloss:2.22674\n",
      "[406]\ttrain-mlogloss:0.19136\teval-mlogloss:2.22689\n",
      "[407]\ttrain-mlogloss:0.19057\teval-mlogloss:2.22706\n",
      "[408]\ttrain-mlogloss:0.18977\teval-mlogloss:2.22675\n",
      "[409]\ttrain-mlogloss:0.18898\teval-mlogloss:2.22659\n",
      "[410]\ttrain-mlogloss:0.18819\teval-mlogloss:2.22642\n",
      "[411]\ttrain-mlogloss:0.18735\teval-mlogloss:2.22626\n",
      "[412]\ttrain-mlogloss:0.18654\teval-mlogloss:2.22641\n",
      "[413]\ttrain-mlogloss:0.18576\teval-mlogloss:2.22655\n",
      "[414]\ttrain-mlogloss:0.18501\teval-mlogloss:2.22679\n",
      "[415]\ttrain-mlogloss:0.18424\teval-mlogloss:2.22689\n",
      "[416]\ttrain-mlogloss:0.18346\teval-mlogloss:2.22679\n",
      "[417]\ttrain-mlogloss:0.18269\teval-mlogloss:2.22685\n",
      "[418]\ttrain-mlogloss:0.18197\teval-mlogloss:2.22656\n",
      "[419]\ttrain-mlogloss:0.18119\teval-mlogloss:2.22692\n",
      "[420]\ttrain-mlogloss:0.18044\teval-mlogloss:2.22675\n",
      "[421]\ttrain-mlogloss:0.17967\teval-mlogloss:2.22664\n",
      "[422]\ttrain-mlogloss:0.17889\teval-mlogloss:2.22672\n",
      "[423]\ttrain-mlogloss:0.17815\teval-mlogloss:2.22699\n",
      "[424]\ttrain-mlogloss:0.17739\teval-mlogloss:2.22697\n",
      "[425]\ttrain-mlogloss:0.17665\teval-mlogloss:2.22681\n",
      "[426]\ttrain-mlogloss:0.17596\teval-mlogloss:2.22694\n",
      "[427]\ttrain-mlogloss:0.17524\teval-mlogloss:2.22701\n",
      "[428]\ttrain-mlogloss:0.17453\teval-mlogloss:2.22685\n",
      "[429]\ttrain-mlogloss:0.17383\teval-mlogloss:2.22701\n",
      "[430]\ttrain-mlogloss:0.17309\teval-mlogloss:2.22687\n",
      "[431]\ttrain-mlogloss:0.17237\teval-mlogloss:2.22717\n",
      "[432]\ttrain-mlogloss:0.17165\teval-mlogloss:2.22724\n",
      "[433]\ttrain-mlogloss:0.17098\teval-mlogloss:2.22709\n",
      "[434]\ttrain-mlogloss:0.17023\teval-mlogloss:2.22710\n",
      "[435]\ttrain-mlogloss:0.16956\teval-mlogloss:2.22703\n",
      "[436]\ttrain-mlogloss:0.16886\teval-mlogloss:2.22681\n",
      "Model saved to 2024-II/Aprendizaje/Tarea4/xgboost_model_rbc.json\n",
      "Accuracy: 0.29\n",
      "Confusion Matrix:\n",
      "[[ 17   5   0  10   6   3  21  15   3  12   5   3   8   4   4]\n",
      " [  9 125   3  44   7   2   3   0  14   2  28   3   9   2   9]\n",
      " [  3   3 115   2   7   0   1   0  26   0  40  12   8   7   4]\n",
      " [ 12  29   1  54   3   4   7   6   7   2  17   3   9   0   6]\n",
      " [ 20  26   3   5  34  21  28   5  11   5  11   9  19   8   6]\n",
      " [ 11   8   2  12  11  61  19   6   1  31   6  10  11   1  18]\n",
      " [ 11   5   0   3  10   8  35   5   3  21   1   3   1   0   4]\n",
      " [ 35  11   0   6  17  15  24  31   5  31   1   4   6   0   3]\n",
      " [ 24  30  18  19  22   4   4   1  41   2  57   7  20   9  16]\n",
      " [ 12   2   0   1   9   9  20  12   1  41   1   3   3   0   1]\n",
      " [ 10  68  34  36  13   1  10   1  30   0  74   3  18   3   9]\n",
      " [ 11   4  18   6  21  29  18   5   7  11   8  38  22   1  16]\n",
      " [ 16   6   0  20  23  10   9   6  18   4  25   5  33   3  14]\n",
      " [  5   4  16  10   7   3   8   5  11  13  12   3   6  33   5]\n",
      " [  7   7   3   6  18  27  15   3   7   6  10   6  11   5 125]]\n"
     ]
    }
   ],
   "source": [
    "train_xgboost(reduced_bag_of_features_train, y_train, reduced_bag_of_features_test, y_test, savename='xgboost_model_rbc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to 2024-II/Aprendizaje/Tarea4/random_forest_model_rbc.joblib\n",
      "Accuracy: 0.32\n",
      "Confusion Matrix:\n",
      "[[ 15  33   7   4   0   5  13   2   0  21   3   0   2   1  10]\n",
      " [  1 226   9   8   0   0   0   0   1   0   7   0   0   0   8]\n",
      " [  0   2 213   1   0   0   0   0   1   0  10   0   0   0   1]\n",
      " [  1  84   5  43   0   1   1   1   0   2  11   0   1   0  10]\n",
      " [  7  66  21   5   6  27  19   3   2  19   5   2   9   1  19]\n",
      " [  3  17   8   5   0  61  14   0   1  56   6   2   4   1  30]\n",
      " [  5  23   2   0   2   8  30   1   0  35   2   0   0   0   2]\n",
      " [ 20  24   1   5   3  12  31  18   1  63   1   1   1   0   8]\n",
      " [  1  88  71  16   0   0   1   0  35   1  43   0   4   2  12]\n",
      " [  3   9   0   1   0   7  29   2   0  64   0   0   0   0   0]\n",
      " [  0 129  94  21   0   0   0   0  11   0  44   0   0   0  11]\n",
      " [  8  20  61   3   2  34  16   3   6  23   4  12   2   0  21]\n",
      " [  3  28  34  17   5  16  11   0   5   9  17   2  12   1  32]\n",
      " [  1   4  45   3   2   7   7   2   7  22   5   0   0  25  11]\n",
      " [  0  33  15   5   3  27  10   1   1   5   4   0   2   2 148]]\n"
     ]
    }
   ],
   "source": [
    "train_random_forest(reduced_bag_of_features_train, y_train, reduced_bag_of_features_test, y_test, savename='random_forest_model_rbc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to 2024-II/Aprendizaje/Tarea4/svm_model_rbc.joblib\n",
      "Accuracy: 0.40\n",
      "Confusion Matrix:\n",
      "[[ 26  12   0   2   7   2  19  15   4   0   0   8   5  12   4]\n",
      " [  6 158   3  29   2   0   0   5  14   0  32   1   5   5   0]\n",
      " [  0   3 167   5   0   0   0   0  11   0  17   4   0  21   0]\n",
      " [  2  33   1  64   4   0   2   3  11   0  18   0   7  13   2]\n",
      " [ 12  16   3  10  43   7  21  18   2   7   8  22  20  20   2]\n",
      " [  4   2   0   4  18  55  33   8   3   8   3  33   8  17  12]\n",
      " [  9   4   0   0  10   3  52   5   0  13   2   7   2   1   2]\n",
      " [ 23   1   0   2  10   3  18  62   1  11   0  16   2  35   5]\n",
      " [  4  15  22  25   5   0   0   4  82   0  50   4  12  51   0]\n",
      " [  7   2   0   0   4   6  26  14   0  45   0   7   0   4   0]\n",
      " [  3  63  37  25   1   1   0   3  52   0  89   3  13  19   1]\n",
      " [  5   2   2   1  20  19   9   8   6   4   2  91  12  32   2]\n",
      " [  4   3   0   9  31  11   8   7   7   0   6  26  58  14   8]\n",
      " [  1   0   2   0   3   1   0   4   6   2   0   3   2 113   4]\n",
      " [  5  18   3  10  21  15  14   6   5   2   3  13  10  28 103]]\n"
     ]
    }
   ],
   "source": [
    "train_svm(reduced_bag_of_features_train, y_train, reduced_bag_of_features_test, y_test, savename='svm_model_rbc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
